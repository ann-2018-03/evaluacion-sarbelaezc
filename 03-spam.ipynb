{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n3lnWjvI83ix"
   },
   "source": [
    "# Filtado de mensajes spam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descripción del problema real"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La recepción de publicidad no deseada a traves mensajes de texto usando SMS (Short Message Service) es un problema que afecta a muchos usuarios de teléfonos móviles. El problema radica en que los usuarios deben pagar por los mesajes recibidos, y por este motivo resulta muy importante que las compañías prestadoras del servicio puedan filtrar mensajes indeseados antes de enviarlos a su destinatario final. Los mensajes tienen una longitud máxima de 160 caracteres, por lo que el texto resulta poco para realizar la clasificación, en comparación con textos más largos (como los emails). Adicionalmente, los errores de digitación dificultan el proceso de detección automática."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descripción del problema en términos de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se tiene una muestra contiene 5574 mensajes en inglés, no codificados y clasificados como legítimos (ham) o spam (http://www.dt.fee.unicamp.br/~tiago/smsspamcollection/). La información está almacenada en el archivo `datos/spam-sms.zip`.El problema en términos de los datos consiste en clasificar si un mensaje SMS es legítico o spam, a partir del análisis de las palabras que contiente, partiendo del supuesto de que ciertas palabras que son más frecuentes dependiendo del tipo de mensaje. Esto implica que en la fase de preparación de los datos se deben extraer las palabras que contiene cada mensaje para poder realizar el análsis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aproximaciones posibles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, se desea comparar los resultados de un modelo de redes neuronales artificiales y otras técnicas estadísticas para realizar la clasificación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requerimientos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usted debe:\n",
    "\n",
    "* Preprocesar los datos para representarlos usando bag-of-words.\n",
    "\n",
    "\n",
    "* Construir un modelo de regresión logística como punto base para la comparación con otros modelos más complejos.\n",
    "\n",
    "\n",
    "* Construir un modelo de redes neuronales artificiales. Asimismo, debe determinar el número de neuronas en la capa o capas ocultas.\n",
    "\n",
    "\n",
    "* Utiizar una técnica como crossvalidation u otra similar para establecer la robustez del modelo.\n",
    "\n",
    "\n",
    "* Presentar métricas de desempeño para establecer las bondades y falencias de cada clasificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import string\n",
    "\n",
    "import glob\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns = ['label', 'content'])\n",
    "\n",
    "folders = glob.glob(\"./datos/spam-filter/*\")\n",
    "for folder_aux in folders:\n",
    "    folder_name = folder_aux + \"/*\"\n",
    "    folder = glob.glob(folder_name)\n",
    "    for file in folder:\n",
    "        try:\n",
    "            with open(file, encoding='utf-8') as f:\n",
    "                content = f.read()\n",
    "        except UnicodeDecodeError:\n",
    "            with open(file, 'rb') as f:\n",
    "                content = f.read()\n",
    "        df = df.append({'label': 0 if 'ham' in folder_name else 1, \n",
    "                        'content': str(content).replace('\\\\n', '\\n')}, ignore_index=True)\n",
    "        \n",
    "df.to_csv(r'datos/spam-filter/dataFrame.csv')\n",
    "\n",
    "def remove_header(cols):\n",
    "    array_first = cols[1].replace('\\\\n', '\\n').split('\\n')\n",
    "    index_remove = 0\n",
    "    pattern = r'^[A-Za-z-]*: [a-zA-Z 0-9@.[\\]\\(\\)-]*'\n",
    "    for index, element in enumerate(array_first):\n",
    "        if re.search(pattern, element):\n",
    "            index_remove = index\n",
    "    return '\\n'.join(array_first[index_remove + 1:]).strip()\n",
    "\n",
    "def remove_tags_HTML(cols):\n",
    "    content = cols[1]\n",
    "    TAG_RE = re.compile(r'<[^>]+>')\n",
    "    TAG_REX = re.compile(r\"\\s+\")\n",
    "    content = TAG_RE.sub('', content)\n",
    "    content = TAG_REX.sub(' ', content)\n",
    "    return content\n",
    "\n",
    "def remove_spaces_tab(cols):\n",
    "    content = cols[1]\n",
    "    return content.replace(\"\\n\",\"\").strip(\"\\t\")\n",
    "\n",
    "def remove_web(cols):\n",
    "    content = cols[1]\n",
    "    TAG_RE = re.compile(r'https?:\\/\\/.*[\\n]*')\n",
    "    return TAG_RE.sub('', content)\n",
    "\n",
    "def remove_numbers(cols):\n",
    "    content = cols[1]\n",
    "    TAG_RE = re.compile(r'[0-9]*')\n",
    "    return TAG_RE.sub('', content)\n",
    "\n",
    "df['content'] = df.apply(remove_header, axis=1)\n",
    "df['content'] = df.apply(remove_tags_HTML, axis=1)\n",
    "df['content'] = df.apply(remove_spaces_tab, axis=1)\n",
    "df['content'] = df.apply(remove_numbers, axis=1)\n",
    "df['content'] = df.apply(remove_web, axis=1)\n",
    "\n",
    "X = df['content']\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procesando el lenguaje natural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\santi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "stemmer = SnowballStemmer(\"english\")\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def cleanText(message):    \n",
    "    message = message.translate(str.maketrans('', '', string.punctuation))\n",
    "    words = [stemmer.stem(word) for word in message.split() if word.lower() not in stopwords.words(\"english\")]\n",
    "    return \" \".join(words)\n",
    "    \n",
    "X = list(map(cleanText, X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diccionario de palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6299, 60982)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(X)\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X.toarray()\n",
    "\n",
    "X[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se relaiza una regresión logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1297,   23],\n",
       "       [  80,  490]], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=y.astype('int')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y , stratify = y, test_size = 0.3,random_state=101)\n",
    "\n",
    "clf = LogisticRegression(solver='lbfgs')\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9455026455026455\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96      1320\n",
      "           1       0.96      0.86      0.90       570\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      1890\n",
      "   macro avg       0.95      0.92      0.93      1890\n",
      "weighted avg       0.95      0.95      0.94      1890\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificación por medio de redes neuronales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se busca el número de capas ideal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "4409/4409 [==============================] - 36s 8ms/step - loss: 0.6549 - acc: 0.6938\n",
      "Epoch 2/30\n",
      "4409/4409 [==============================] - 18s 4ms/step - loss: 0.4483 - acc: 0.7437\n",
      "Epoch 3/30\n",
      "4409/4409 [==============================] - 7s 2ms/step - loss: 0.2580 - acc: 0.9401\n",
      "Epoch 4/30\n",
      "4409/4409 [==============================] - 6s 1ms/step - loss: 0.1501 - acc: 0.9619\n",
      "Epoch 5/30\n",
      "4409/4409 [==============================] - 7s 2ms/step - loss: 0.1037 - acc: 0.9712\n",
      "Epoch 6/30\n",
      "4409/4409 [==============================] - 8s 2ms/step - loss: 0.0794 - acc: 0.9782\n",
      "Epoch 7/30\n",
      "4409/4409 [==============================] - 7s 2ms/step - loss: 0.0643 - acc: 0.9823\n",
      "Epoch 8/30\n",
      "4409/4409 [==============================] - 8s 2ms/step - loss: 0.0534 - acc: 0.9848\n",
      "Epoch 9/30\n",
      "4409/4409 [==============================] - 8s 2ms/step - loss: 0.0453 - acc: 0.9864\n",
      "Epoch 10/30\n",
      "4409/4409 [==============================] - 8s 2ms/step - loss: 0.0398 - acc: 0.9878\n",
      "Epoch 11/30\n",
      "4409/4409 [==============================] - 7s 2ms/step - loss: 0.0354 - acc: 0.9884\n",
      "Epoch 12/30\n",
      "4409/4409 [==============================] - 7s 1ms/step - loss: 0.0321 - acc: 0.9896\n",
      "Epoch 13/30\n",
      "4409/4409 [==============================] - 7s 2ms/step - loss: 0.0294 - acc: 0.9896\n",
      "Epoch 14/30\n",
      "4409/4409 [==============================] - 7s 2ms/step - loss: 0.0271 - acc: 0.9909\n",
      "Epoch 15/30\n",
      "4409/4409 [==============================] - 6s 1ms/step - loss: 0.0253 - acc: 0.9914\n",
      "Epoch 16/30\n",
      "4409/4409 [==============================] - 8s 2ms/step - loss: 0.0239 - acc: 0.9914\n",
      "Epoch 17/30\n",
      "4409/4409 [==============================] - 6s 1ms/step - loss: 0.0227 - acc: 0.9916\n",
      "Epoch 18/30\n",
      "4409/4409 [==============================] - 6s 1ms/step - loss: 0.0216 - acc: 0.9918\n",
      "Epoch 19/30\n",
      "4409/4409 [==============================] - 87s 20ms/step - loss: 0.0164 - acc: 0.9943\n",
      "Epoch 29/30\n",
      "4409/4409 [==============================] - 21s 5ms/step - loss: 0.0161 - acc: 0.9943\n",
      "Epoch 30/30\n",
      "4409/4409 [==============================] - 11s 3ms/step - loss: 0.0159 - acc: 0.9943\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 5)                 304915    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 304,951\n",
      "Trainable params: 304,951\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1890/1890 [==============================] - 77s 41ms/step\n",
      "Epoch 1/30\n",
      "4409/4409 [==============================] - 58s 13ms/step - loss: 0.6833 - acc: 0.6986\n",
      "Epoch 2/30\n",
      "4409/4409 [==============================] - 20s 5ms/step - loss: 0.5795 - acc: 0.6986\n",
      "Epoch 3/30\n",
      "4409/4409 [==============================] - 17s 4ms/step - loss: 0.3628 - acc: 0.6986\n",
      "Epoch 4/30\n",
      "4409/4409 [==============================] - 13s 3ms/step - loss: 0.2706 - acc: 0.7376\n",
      "Epoch 5/30\n",
      "4409/4409 [==============================] - 23s 5ms/step - loss: 0.2389 - acc: 0.9714\n",
      "Epoch 6/30\n",
      "4409/4409 [==============================] - 14s 3ms/step - loss: 0.2192 - acc: 0.9814\n",
      "Epoch 7/30\n",
      "4409/4409 [==============================] - 10s 2ms/step - loss: 0.2035 - acc: 0.9853\n",
      "Epoch 8/30\n",
      "4409/4409 [==============================] - 9s 2ms/step - loss: 0.1905 - acc: 0.9866\n",
      "Epoch 9/30\n",
      "4409/4409 [==============================] - 11s 2ms/step - loss: 0.1788 - acc: 0.9882: 5s - loss: 0.1964 \n",
      "Epoch 10/30\n",
      "4409/4409 [==============================] - 10s 2ms/step - loss: 0.1683 - acc: 0.9905\n",
      "Epoch 11/30\n",
      "4409/4409 [==============================] - 15s 3ms/step - loss: 0.1588 - acc: 0.9909: 3s - loss: 0.1640 - ETA: 1s - loss: 0.1602 - acc:\n",
      "Epoch 12/30\n",
      "4409/4409 [==============================] - 36s 8ms/step - loss: 0.1502 - acc: 0.9916\n",
      "Epoch 13/30\n",
      "4409/4409 [==============================] - 95s 22ms/step - loss: 0.1423 - acc: 0.9921\n",
      "Epoch 14/30\n",
      "4409/4409 [==============================] - 52s 12ms/step - loss: 0.1350 - acc: 0.9927\n",
      "Epoch 15/30\n",
      "4409/4409 [==============================] - 12s 3ms/step - loss: 0.1284 - acc: 0.9930\n",
      "Epoch 16/30\n",
      "4409/4409 [==============================] - 7s 2ms/step - loss: 0.1225 - acc: 0.9930\n",
      "Epoch 17/30\n",
      "4409/4409 [==============================] - 6s 1ms/step - loss: 0.1168 - acc: 0.9930\n",
      "Epoch 18/30\n",
      "4409/4409 [==============================] - 6s 1ms/step - loss: 0.1113 - acc: 0.9932\n",
      "Epoch 19/30\n",
      "4409/4409 [==============================] - 7s 2ms/step - loss: 0.1067 - acc: 0.9930\n",
      "Epoch 20/30\n",
      "4409/4409 [==============================] - 6s 1ms/step - loss: 0.1020 - acc: 0.9932\n",
      "Epoch 21/30\n",
      "4409/4409 [==============================] - 7s 2ms/step - loss: 0.0978 - acc: 0.9932\n",
      "Epoch 22/30\n",
      "4409/4409 [==============================] - 6s 1ms/step - loss: 0.0938 - acc: 0.9932\n",
      "Epoch 23/30\n",
      "4409/4409 [==============================] - 7s 2ms/step - loss: 0.0899 - acc: 0.9932\n",
      "Epoch 24/30\n",
      "4409/4409 [==============================] - 7s 2ms/step - loss: 0.0868 - acc: 0.9932\n",
      "Epoch 25/30\n",
      "4409/4409 [==============================] - 7s 2ms/step - loss: 0.0834 - acc: 0.9932\n",
      "Epoch 26/30\n",
      "4409/4409 [==============================] - 6s 1ms/step - loss: 0.0803 - acc: 0.9932\n",
      "Epoch 27/30\n",
      "4409/4409 [==============================] - 6s 1ms/step - loss: 0.0774 - acc: 0.9932\n",
      "Epoch 28/30\n",
      "4409/4409 [==============================] - 7s 2ms/step - loss: 0.0748 - acc: 0.9932\n",
      "Epoch 29/30\n",
      "4409/4409 [==============================] - 6s 1ms/step - loss: 0.0721 - acc: 0.9932\n",
      "Epoch 30/30\n",
      "4409/4409 [==============================] - 7s 2ms/step - loss: 0.0697 - acc: 0.9932\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 5)                 304915    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 305,041\n",
      "Trainable params: 305,041\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1890/1890 [==============================] - 5s 2ms/step\n",
      "Epoch 1/30\n",
      "4409/4409 [==============================] - 41s 9ms/step - loss: 0.6832 - acc: 0.6986\n",
      "Epoch 2/30\n",
      "4409/4409 [==============================] - 18s 4ms/step - loss: 0.6465 - acc: 0.6986\n",
      "Epoch 3/30\n",
      "4409/4409 [==============================] - 11s 3ms/step - loss: 0.4880 - acc: 0.6986\n",
      "Epoch 4/30\n",
      "4409/4409 [==============================] - 6s 1ms/step - loss: 0.2987 - acc: 0.6986\n",
      "Epoch 5/30\n",
      "4409/4409 [==============================] - 8s 2ms/step - loss: 0.2394 - acc: 0.8905\n",
      "Epoch 6/30\n",
      "4409/4409 [==============================] - 7s 2ms/step - loss: 0.2031 - acc: 0.9814\n",
      "Epoch 7/30\n",
      "4409/4409 [==============================] - 7s 2ms/step - loss: 0.1641 - acc: 0.9884\n",
      "Epoch 8/30\n",
      "4409/4409 [==============================] - 7s 2ms/step - loss: 0.1325 - acc: 0.9898\n",
      "Epoch 9/30\n",
      "4409/4409 [==============================] - 7s 2ms/step - loss: 0.1087 - acc: 0.9900A: 1s - l\n",
      "Epoch 10/30\n",
      "4409/4409 [==============================] - 7s 2ms/step - loss: 0.0896 - acc: 0.9916\n",
      "Epoch 11/30\n",
      "4409/4409 [==============================] - 6s 1ms/step - loss: 0.0755 - acc: 0.9914\n",
      "Epoch 12/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4409/4409 [==============================] - 7s 2ms/step - loss: 0.0651 - acc: 0.9923\n",
      "Epoch 13/30\n",
      "4409/4409 [==============================] - 6s 1ms/step - loss: 0.0579 - acc: 0.9921\n",
      "Epoch 14/30\n",
      "4409/4409 [==============================] - 6s 1ms/step - loss: 0.0523 - acc: 0.9918\n",
      "Epoch 15/30\n",
      "4409/4409 [==============================] - 7s 1ms/step - loss: 0.0484 - acc: 0.9923\n",
      "Epoch 16/30\n",
      "4409/4409 [==============================] - 7s 1ms/step - loss: 0.0443 - acc: 0.9923\n",
      "Epoch 17/30\n",
      "4409/4409 [==============================] - 7s 2ms/step - loss: 0.0422 - acc: 0.9921\n",
      "Epoch 18/30\n",
      "4409/4409 [==============================] - 7s 2ms/step - loss: 0.0393 - acc: 0.9921A: \n",
      "Epoch 19/30\n",
      "4409/4409 [==============================] - 7s 2ms/step - loss: 0.0384 - acc: 0.9921\n",
      "Epoch 20/30\n",
      "4409/4409 [==============================] - 7s 2ms/step - loss: 0.0364 - acc: 0.9918\n",
      "Epoch 21/30\n",
      "4409/4409 [==============================] - 7s 2ms/step - loss: 0.0355 - acc: 0.9923\n",
      "Epoch 22/30\n",
      "4409/4409 [==============================] - 7s 2ms/step - loss: 0.0351 - acc: 0.9916\n",
      "Epoch 23/30\n",
      "4409/4409 [==============================] - 8s 2ms/step - loss: 0.0341 - acc: 0.9923A: 0s - loss: 0.0349 - ac\n",
      "Epoch 24/30\n",
      "4409/4409 [==============================] - 7s 2ms/step - loss: 0.0328 - acc: 0.9921\n",
      "Epoch 25/30\n",
      "4409/4409 [==============================] - 7s 1ms/step - loss: 0.0329 - acc: 0.9923\n",
      "Epoch 26/30\n",
      "4409/4409 [==============================] - 7s 2ms/step - loss: 0.0326 - acc: 0.9921\n",
      "Epoch 27/30\n",
      "4409/4409 [==============================] - 7s 2ms/step - loss: 0.0324 - acc: 0.9923\n",
      "Epoch 28/30\n",
      "4409/4409 [==============================] - 7s 2ms/step - loss: 0.0326 - acc: 0.9918\n",
      "Epoch 29/30\n",
      "4409/4409 [==============================] - 7s 2ms/step - loss: 0.0322 - acc: 0.9918\n",
      "Epoch 30/30\n",
      "4409/4409 [==============================] - 6s 1ms/step - loss: 0.0306 - acc: 0.9923\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 5)                 304915    \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 305,131\n",
      "Trainable params: 305,131\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1890/1890 [==============================] - 7s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "def grid_layers(capas):\n",
    "    param = []\n",
    "\n",
    "    for i in range(len(capas)):\n",
    "        classifier = Sequential()\n",
    "\n",
    "        classifier.add(Dense(units = 5, kernel_initializer = 'uniform', activation = 'relu', input_dim = 60982))\n",
    "\n",
    "        for j in range(capas[i]-1):\n",
    "            classifier.add(Dense(units = 5, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "\n",
    "        classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "        classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "        classifier.fit(X_train, y_train, batch_size = 50, epochs = 30)\n",
    "\n",
    "        y_pred = classifier.predict(X_test)\n",
    "        y_pred = (y_pred > 0.5)\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "        param.append([classifier.summary(),cm,classifier.evaluate(X_test, y_test)])\n",
    "\n",
    "    return param\n",
    "\n",
    "layers = [2,5,8]\n",
    "\n",
    "resultado = grid_layers(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[None, array([[1293,   27],\n",
       "         [  61,  509]], dtype=int64), [0.1924540517533878,\n",
       "   0.9534391534391534]],\n",
       " [None, array([[1294,   26],\n",
       "         [  73,  497]], dtype=int64), [0.27616665547158087,\n",
       "   0.9476190476190476]],\n",
       " [None, array([[1291,   29],\n",
       "         [  56,  514]], dtype=int64), [0.22601457802626274,\n",
       "   0.955026455026455]]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 3 artists>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "precision = [i[2][1] for i in resultado]\n",
    "\n",
    "plt.bar([\"2 Capas\",\"5 Capas\",\"8 Capas\"],precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego de ver las capas qeu se deben usar se busca el númeor de neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "4409/4409 [==============================] - 54s 12ms/step - loss: 0.5381 - acc: 0.7804\n",
      "Epoch 2/30\n",
      "4409/4409 [==============================] - 9s 2ms/step - loss: 0.1922 - acc: 0.9478\n",
      "Epoch 3/30\n",
      "4409/4409 [==============================] - 8s 2ms/step - loss: 0.0987 - acc: 0.9698\n",
      "Epoch 4/30\n",
      "4409/4409 [==============================] - 9s 2ms/step - loss: 0.0674 - acc: 0.9814\n",
      "Epoch 5/30\n",
      "4409/4409 [==============================] - 12s 3ms/step - loss: 0.0510 - acc: 0.9868\n",
      "Epoch 6/30\n",
      "4409/4409 [==============================] - 10s 2ms/step - loss: 0.0413 - acc: 0.9880\n",
      "Epoch 7/30\n",
      "4409/4409 [==============================] - 10s 2ms/step - loss: 0.0350 - acc: 0.9896\n",
      "Epoch 8/30\n",
      "4409/4409 [==============================] - 8s 2ms/step - loss: 0.0308 - acc: 0.9907\n",
      "Epoch 9/30\n",
      "4409/4409 [==============================] - 10s 2ms/step - loss: 0.0277 - acc: 0.9918\n",
      "Epoch 10/30\n",
      "4409/4409 [==============================] - 13s 3ms/step - loss: 0.0256 - acc: 0.9918\n",
      "Epoch 11/30\n",
      "4409/4409 [==============================] - 8s 2ms/step - loss: 0.0239 - acc: 0.9925\n",
      "Epoch 12/30\n",
      "4409/4409 [==============================] - 7s 2ms/step - loss: 0.0226 - acc: 0.9927\n",
      "Epoch 13/30\n",
      "4409/4409 [==============================] - 9s 2ms/step - loss: 0.0217 - acc: 0.9934\n",
      "Epoch 14/30\n",
      "4409/4409 [==============================] - 9s 2ms/step - loss: 0.0209 - acc: 0.9939\n",
      "Epoch 15/30\n",
      "4409/4409 [==============================] - 9s 2ms/step - loss: 0.0202 - acc: 0.9941\n",
      "Epoch 16/30\n",
      "4409/4409 [==============================] - 10s 2ms/step - loss: 0.0197 - acc: 0.9943\n",
      "Epoch 17/30\n",
      "4409/4409 [==============================] - 21s 5ms/step - loss: 0.0193 - acc: 0.9946\n",
      "Epoch 18/30\n",
      "4409/4409 [==============================] - 23s 5ms/step - loss: 0.0189 - acc: 0.9943\n",
      "Epoch 19/30\n",
      "4409/4409 [==============================] - 37s 8ms/step - loss: 0.0187 - acc: 0.9943\n",
      "Epoch 20/30\n",
      "4409/4409 [==============================] - 23s 5ms/step - loss: 0.0184 - acc: 0.9946\n",
      "Epoch 21/30\n",
      "4409/4409 [==============================] - 15s 3ms/step - loss: 0.0183 - acc: 0.9941\n",
      "Epoch 22/30\n",
      "4409/4409 [==============================] - 8s 2ms/step - loss: 0.0182 - acc: 0.9946\n",
      "Epoch 23/30\n",
      "4409/4409 [==============================] - 8s 2ms/step - loss: 0.0180 - acc: 0.9943\n",
      "Epoch 24/30\n",
      "4409/4409 [==============================] - 8s 2ms/step - loss: 0.0180 - acc: 0.9943\n",
      "Epoch 25/30\n",
      "4409/4409 [==============================] - 8s 2ms/step - loss: 0.0178 - acc: 0.9943\n",
      "Epoch 26/30\n",
      "4409/4409 [==============================] - 8s 2ms/step - loss: 0.0177 - acc: 0.9943\n",
      "Epoch 27/30\n",
      "4409/4409 [==============================] - 8s 2ms/step - loss: 0.0176 - acc: 0.9941\n",
      "Epoch 28/30\n",
      "4409/4409 [==============================] - 8s 2ms/step - loss: 0.0175 - acc: 0.9946\n",
      "Epoch 29/30\n",
      "4409/4409 [==============================] - 8s 2ms/step - loss: 0.0175 - acc: 0.9946\n",
      "Epoch 30/30\n",
      "4409/4409 [==============================] - 8s 2ms/step - loss: 0.0175 - acc: 0.9946\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_19 (Dense)             (None, 8)                 487864    \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 487,945\n",
      "Trainable params: 487,945\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1890/1890 [==============================] - 6s 3ms/step\n",
      "Epoch 1/30\n",
      "4409/4409 [==============================] - 81s 18ms/step - loss: 0.4764 - acc: 0.8199\n",
      "Epoch 2/30\n",
      "4409/4409 [==============================] - 24s 5ms/step - loss: 0.1347 - acc: 0.9612\n",
      "Epoch 3/30\n",
      "4409/4409 [==============================] - 51s 11ms/step - loss: 0.0756 - acc: 0.9803\n",
      "Epoch 4/30\n",
      "4409/4409 [==============================] - 21s 5ms/step - loss: 0.0562 - acc: 0.9866\n",
      "Epoch 5/30\n",
      "4409/4409 [==============================] - 11s 2ms/step - loss: 0.0448 - acc: 0.9880\n",
      "Epoch 6/30\n",
      "4409/4409 [==============================] - 11s 3ms/step - loss: 0.0375 - acc: 0.9896: 1s - loss: 0\n",
      "Epoch 7/30\n",
      "4409/4409 [==============================] - 13s 3ms/step - loss: 0.0322 - acc: 0.9912\n",
      "Epoch 8/30\n",
      "4409/4409 [==============================] - 17s 4ms/step - loss: 0.0287 - acc: 0.9921\n",
      "Epoch 9/30\n",
      "4409/4409 [==============================] - 11s 2ms/step - loss: 0.0262 - acc: 0.9923\n",
      "Epoch 10/30\n",
      "4409/4409 [==============================] - 10s 2ms/step - loss: 0.0243 - acc: 0.9925\n",
      "Epoch 11/30\n",
      "4409/4409 [==============================] - 11s 2ms/step - loss: 0.0230 - acc: 0.9939\n",
      "Epoch 12/30\n",
      "4409/4409 [==============================] - 12s 3ms/step - loss: 0.0219 - acc: 0.9936\n",
      "Epoch 13/30\n",
      "4409/4409 [==============================] - 11s 2ms/step - loss: 0.0210 - acc: 0.9943\n",
      "Epoch 14/30\n",
      "4409/4409 [==============================] - 10s 2ms/step - loss: 0.0204 - acc: 0.9943\n",
      "Epoch 15/30\n",
      "4409/4409 [==============================] - 10s 2ms/step - loss: 0.0198 - acc: 0.9943\n",
      "Epoch 16/30\n",
      "4409/4409 [==============================] - 11s 2ms/step - loss: 0.0193 - acc: 0.9943\n",
      "Epoch 17/30\n",
      "4409/4409 [==============================] - 11s 2ms/step - loss: 0.0191 - acc: 0.9941\n",
      "Epoch 18/30\n",
      "4409/4409 [==============================] - 11s 2ms/step - loss: 0.0187 - acc: 0.9943\n",
      "Epoch 19/30\n",
      "4409/4409 [==============================] - 10s 2ms/step - loss: 0.0184 - acc: 0.9941\n",
      "Epoch 20/30\n",
      "4409/4409 [==============================] - 11s 2ms/step - loss: 0.0183 - acc: 0.9941\n",
      "Epoch 21/30\n",
      "4409/4409 [==============================] - 11s 2ms/step - loss: 0.0181 - acc: 0.9939\n",
      "Epoch 22/30\n",
      "4409/4409 [==============================] - 12s 3ms/step - loss: 0.0179 - acc: 0.9941\n",
      "Epoch 23/30\n",
      "4409/4409 [==============================] - 11s 2ms/step - loss: 0.0178 - acc: 0.9943\n",
      "Epoch 24/30\n",
      "4409/4409 [==============================] - 10s 2ms/step - loss: 0.0176 - acc: 0.9941\n",
      "Epoch 25/30\n",
      "4409/4409 [==============================] - 10s 2ms/step - loss: 0.0174 - acc: 0.9946\n",
      "Epoch 26/30\n",
      "4409/4409 [==============================] - 10s 2ms/step - loss: 0.0176 - acc: 0.9946\n",
      "Epoch 27/30\n",
      "4409/4409 [==============================] - 10s 2ms/step - loss: 0.0173 - acc: 0.9943\n",
      "Epoch 28/30\n",
      "4409/4409 [==============================] - 11s 3ms/step - loss: 0.0174 - acc: 0.9943\n",
      "Epoch 29/30\n",
      "4409/4409 [==============================] - 11s 3ms/step - loss: 0.0173 - acc: 0.9946: 2s -\n",
      "Epoch 30/30\n",
      "4409/4409 [==============================] - 11s 2ms/step - loss: 0.0173 - acc: 0.9941\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_22 (Dense)             (None, 16)                975728    \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 976,017\n",
      "Trainable params: 976,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1890/1890 [==============================] - 8s 4ms/step\n",
      "Epoch 1/30\n",
      "4409/4409 [==============================] - 83s 19ms/step - loss: 0.4217 - acc: 0.8315\n",
      "Epoch 2/30\n",
      "4409/4409 [==============================] - 30s 7ms/step - loss: 0.1029 - acc: 0.9716\n",
      "Epoch 3/30\n",
      "4409/4409 [==============================] - 15s 3ms/step - loss: 0.0514 - acc: 0.9866\n",
      "Epoch 4/30\n",
      "4409/4409 [==============================] - 15s 3ms/step - loss: 0.0355 - acc: 0.9896\n",
      "Epoch 5/30\n",
      "4409/4409 [==============================] - 14s 3ms/step - loss: 0.0283 - acc: 0.9918\n",
      "Epoch 6/30\n",
      "4409/4409 [==============================] - 16s 4ms/step - loss: 0.0251 - acc: 0.9930\n",
      "Epoch 7/30\n",
      "4409/4409 [==============================] - 15s 3ms/step - loss: 0.0238 - acc: 0.9939\n",
      "Epoch 8/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4409/4409 [==============================] - 15s 3ms/step - loss: 0.0228 - acc: 0.9936\n",
      "Epoch 9/30\n",
      "4409/4409 [==============================] - 15s 3ms/step - loss: 0.0221 - acc: 0.9946\n",
      "Epoch 10/30\n",
      "4409/4409 [==============================] - 15s 3ms/step - loss: 0.0220 - acc: 0.9941\n",
      "Epoch 11/30\n",
      "4409/4409 [==============================] - 14s 3ms/step - loss: 0.0216 - acc: 0.9941\n",
      "Epoch 12/30\n",
      "4409/4409 [==============================] - 14s 3ms/step - loss: 0.0216 - acc: 0.9943\n",
      "Epoch 13/30\n",
      "4409/4409 [==============================] - 15s 3ms/step - loss: 0.0214 - acc: 0.9943\n",
      "Epoch 14/30\n",
      "4409/4409 [==============================] - 15s 3ms/step - loss: 0.0214 - acc: 0.9939\n",
      "Epoch 15/30\n",
      "4409/4409 [==============================] - 15s 3ms/step - loss: 0.0210 - acc: 0.9943\n",
      "Epoch 16/30\n",
      "4409/4409 [==============================] - 15s 3ms/step - loss: 0.0219 - acc: 0.9939\n",
      "Epoch 17/30\n",
      "4409/4409 [==============================] - 15s 3ms/step - loss: 0.0213 - acc: 0.9936\n",
      "Epoch 18/30\n",
      "4409/4409 [==============================] - 15s 3ms/step - loss: 0.0212 - acc: 0.9939\n",
      "Epoch 19/30\n",
      "4409/4409 [==============================] - 15s 3ms/step - loss: 0.0209 - acc: 0.9941\n",
      "Epoch 20/30\n",
      "4409/4409 [==============================] - 14s 3ms/step - loss: 0.0211 - acc: 0.9941\n",
      "Epoch 21/30\n",
      "4409/4409 [==============================] - 15s 3ms/step - loss: 0.0211 - acc: 0.9939\n",
      "Epoch 22/30\n",
      "4409/4409 [==============================] - 15s 3ms/step - loss: 0.0208 - acc: 0.9943\n",
      "Epoch 23/30\n",
      "  64/4409 [..............................] - ETA: 2:40 - loss: 0.0052 - acc: 1.0000   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.156851). Check your callbacks.\n",
      "  % delta_t_median)\n",
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.101875). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4409/4409 [==============================] - 17s 4ms/step - loss: 0.0208 - acc: 0.9943\n",
      "Epoch 24/30\n",
      "4409/4409 [==============================] - 15s 4ms/step - loss: 0.0212 - acc: 0.9943\n",
      "Epoch 25/30\n",
      "4409/4409 [==============================] - 16s 4ms/step - loss: 0.0209 - acc: 0.9941\n",
      "Epoch 26/30\n",
      "4409/4409 [==============================] - 15s 3ms/step - loss: 0.0210 - acc: 0.9941\n",
      "Epoch 27/30\n",
      "4409/4409 [==============================] - 17s 4ms/step - loss: 0.0210 - acc: 0.9939\n",
      "Epoch 28/30\n",
      "4409/4409 [==============================] - 14s 3ms/step - loss: 0.0202 - acc: 0.9941\n",
      "Epoch 29/30\n",
      "4409/4409 [==============================] - 15s 3ms/step - loss: 0.0211 - acc: 0.9941\n",
      "Epoch 30/30\n",
      "4409/4409 [==============================] - 14s 3ms/step - loss: 0.0209 - acc: 0.9941\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 32)                1951456   \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,952,545\n",
      "Trainable params: 1,952,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1890/1890 [==============================] - 7s 4ms/step\n",
      "Epoch 1/30\n",
      "4409/4409 [==============================] - 86s 19ms/step - loss: 0.3538 - acc: 0.8662\n",
      "Epoch 2/30\n",
      "4409/4409 [==============================] - 29s 7ms/step - loss: 0.0728 - acc: 0.9796\n",
      "Epoch 3/30\n",
      "4409/4409 [==============================] - 22s 5ms/step - loss: 0.0421 - acc: 0.9891\n",
      "Epoch 4/30\n",
      "4409/4409 [==============================] - 22s 5ms/step - loss: 0.0498 - acc: 0.9900\n",
      "Epoch 5/30\n",
      "4409/4409 [==============================] - 24s 5ms/step - loss: 0.0330 - acc: 0.9930\n",
      "Epoch 6/30\n",
      "4409/4409 [==============================] - 23s 5ms/step - loss: 0.0312 - acc: 0.9932: 4s - \n",
      "Epoch 7/30\n",
      "4409/4409 [==============================] - 30s 7ms/step - loss: 0.0300 - acc: 0.9939: 5s\n",
      "Epoch 8/30\n",
      "4409/4409 [==============================] - 33s 8ms/step - loss: 0.0295 - acc: 0.9936\n",
      "Epoch 9/30\n",
      "4409/4409 [==============================] - 141s 32ms/step - loss: 0.0291 - acc: 0.9939\n",
      "Epoch 10/30\n",
      "4409/4409 [==============================] - 113s 26ms/step - loss: 0.0288 - acc: 0.9934\n",
      "Epoch 11/30\n",
      "4409/4409 [==============================] - 47s 11ms/step - loss: 0.0287 - acc: 0.9934\n",
      "Epoch 12/30\n",
      "  64/4409 [..............................] - ETA: 5:37 - loss: 0.0064 - acc: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.262357). Check your callbacks.\n",
      "  % delta_t_median)\n",
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.139174). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4409/4409 [==============================] - 223s 51ms/step - loss: 0.0286 - acc: 0.9934\n",
      "Epoch 14/30\n",
      "4409/4409 [==============================] - 37s 8ms/step - loss: 0.0285 - acc: 0.9939\n",
      "Epoch 15/30\n",
      "4409/4409 [==============================] - 26s 6ms/step - loss: 0.0287 - acc: 0.9936\n",
      "Epoch 16/30\n",
      "4409/4409 [==============================] - 22s 5ms/step - loss: 0.0288 - acc: 0.9934\n",
      "Epoch 17/30\n",
      "4409/4409 [==============================] - 23s 5ms/step - loss: 0.0285 - acc: 0.9939\n",
      "Epoch 18/30\n",
      "4409/4409 [==============================] - 22s 5ms/step - loss: 0.0289 - acc: 0.9936\n",
      "Epoch 19/30\n",
      "4409/4409 [==============================] - 22s 5ms/step - loss: 0.0283 - acc: 0.9936\n",
      "Epoch 20/30\n",
      "4409/4409 [==============================] - 22s 5ms/step - loss: 0.0286 - acc: 0.9936\n",
      "Epoch 21/30\n",
      "4409/4409 [==============================] - 22s 5ms/step - loss: 0.0282 - acc: 0.9932\n",
      "Epoch 22/30\n",
      "4409/4409 [==============================] - 22s 5ms/step - loss: 0.0286 - acc: 0.9936\n",
      "Epoch 23/30\n",
      "4409/4409 [==============================] - 23s 5ms/step - loss: 0.0282 - acc: 0.9936\n",
      "Epoch 24/30\n",
      "4409/4409 [==============================] - 23s 5ms/step - loss: 0.0283 - acc: 0.9939\n",
      "Epoch 25/30\n",
      "4409/4409 [==============================] - 23s 5ms/step - loss: 0.0287 - acc: 0.9936\n",
      "Epoch 26/30\n",
      "4409/4409 [==============================] - 23s 5ms/step - loss: 0.0283 - acc: 0.9939\n",
      "Epoch 27/30\n",
      "4409/4409 [==============================] - 23s 5ms/step - loss: 0.0284 - acc: 0.9934\n",
      "Epoch 28/30\n",
      "4409/4409 [==============================] - 23s 5ms/step - loss: 0.0284 - acc: 0.9939\n",
      "Epoch 29/30\n",
      "4409/4409 [==============================] - 23s 5ms/step - loss: 0.0287 - acc: 0.9936\n",
      "Epoch 30/30\n",
      "4409/4409 [==============================] - 23s 5ms/step - loss: 0.0286 - acc: 0.9934\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_28 (Dense)             (None, 64)                3902912   \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 3,907,137\n",
      "Trainable params: 3,907,137\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1890/1890 [==============================] - 6s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "def grid_neurons(neuronas):\n",
    "    param = []\n",
    "  \n",
    "    for i in range(len(neuronas)):\n",
    "        classifier = Sequential()\n",
    "\n",
    "        classifier.add(Dense(units = neuronas[i], kernel_initializer = 'uniform', activation = 'relu', input_dim = 60982))\n",
    "        classifier.add(Dense(units = neuronas[i], kernel_initializer = 'uniform', activation = 'relu'))\n",
    "        classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "        classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "        classifier.fit(X_train, y_train, batch_size = 32, epochs = 30)\n",
    "\n",
    "        y_pred = classifier.predict(X_test)\n",
    "        y_pred = (y_pred > 0.5)\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "        param.append([classifier.summary(),cm,classifier.evaluate(X_test, y_test)])\n",
    "\n",
    "    return param\n",
    "\n",
    "neurons = [8,16,32,64]\n",
    "\n",
    "resultado_neuronas = grid_neurons(neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[None, array([[1292,   28],\n",
       "         [  67,  503]], dtype=int64), [0.24515310031926707,\n",
       "   0.9497354497354498]],\n",
       " [None, array([[1296,   24],\n",
       "         [  67,  503]], dtype=int64), [0.22850030831116125,\n",
       "   0.9518518518518518]],\n",
       " [None, array([[1287,   33],\n",
       "         [  55,  515]], dtype=int64), [0.25002530167429343,\n",
       "   0.9534391534391534]],\n",
       " [None, array([[1289,   31],\n",
       "         [  50,  520]], dtype=int64), [0.2324087665486211,\n",
       "   0.9571428571428572]]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado_neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2204/2204 [==============================] - 23s 11ms/step - loss: 0.6113 - acc: 0.6897\n",
      "Epoch 2/20\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.5309 - acc: 0.6897: 0s - loss: 0.5298 - acc: \n",
      "Epoch 3/20\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.4681 - acc: 0.6897\n",
      "Epoch 4/20\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.3979 - acc: 0.6897\n",
      "Epoch 5/20\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.3276 - acc: 0.7650: 1s - los\n",
      "Epoch 6/20\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.2672 - acc: 0.9483\n",
      "Epoch 7/20\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.2169 - acc: 0.9728\n",
      "Epoch 8/20\n",
      "2204/2204 [==============================] - 10s 5ms/step - loss: 0.1782 - acc: 0.9814\n",
      "Epoch 9/20\n",
      "2204/2204 [==============================] - 10s 5ms/step - loss: 0.1465 - acc: 0.9855\n",
      "Epoch 10/20\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.1214 - acc: 0.9859\n",
      "Epoch 11/20\n",
      "2204/2204 [==============================] - 12s 5ms/step - loss: 0.1051 - acc: 0.9864\n",
      "Epoch 12/20\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0917 - acc: 0.9891\n",
      "Epoch 13/20\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0806 - acc: 0.9891\n",
      "Epoch 14/20\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0699 - acc: 0.9896\n",
      "Epoch 15/20\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0623 - acc: 0.9909\n",
      "Epoch 16/20\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0567 - acc: 0.9877\n",
      "Epoch 17/20\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0524 - acc: 0.9905\n",
      "Epoch 18/20\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0474 - acc: 0.9896\n",
      "Epoch 19/20\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0474 - acc: 0.9891\n",
      "Epoch 20/20\n",
      "2204/2204 [==============================] - 12s 5ms/step - loss: 0.0435 - acc: 0.9891\n",
      "2205/2205 [==============================] - 14s 6ms/step\n",
      "2204/2204 [==============================] - 3s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2205/2205 [==============================] - 27s 12ms/step - loss: 0.6008 - acc: 0.6971\n",
      "Epoch 2/20\n",
      "2205/2205 [==============================] - 10s 5ms/step - loss: 0.5151 - acc: 0.7075\n",
      "Epoch 3/20\n",
      "2205/2205 [==============================] - 10s 5ms/step - loss: 0.4525 - acc: 0.7075:\n",
      "Epoch 4/20\n",
      "2205/2205 [==============================] - 10s 5ms/step - loss: 0.3845 - acc: 0.7075\n",
      "Epoch 5/20\n",
      "2205/2205 [==============================] - 10s 5ms/step - loss: 0.3195 - acc: 0.7433\n",
      "Epoch 6/20\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.2599 - acc: 0.9365\n",
      "Epoch 7/20\n",
      "2205/2205 [==============================] - 10s 5ms/step - loss: 0.2130 - acc: 0.9751\n",
      "Epoch 8/20\n",
      "2205/2205 [==============================] - 10s 4ms/step - loss: 0.1717 - acc: 0.9846\n",
      "Epoch 9/20\n",
      "2205/2205 [==============================] - 10s 5ms/step - loss: 0.1406 - acc: 0.9887\n",
      "Epoch 10/20\n",
      "2205/2205 [==============================] - 10s 5ms/step - loss: 0.1164 - acc: 0.9905\n",
      "Epoch 11/20\n",
      "2205/2205 [==============================] - 10s 5ms/step - loss: 0.0997 - acc: 0.9905: 1s - lo\n",
      "Epoch 12/20\n",
      "2205/2205 [==============================] - 10s 5ms/step - loss: 0.0851 - acc: 0.9909: 0s - loss: 0.0841 \n",
      "Epoch 13/20\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0743 - acc: 0.9927\n",
      "Epoch 14/20\n",
      "2205/2205 [==============================] - 10s 5ms/step - loss: 0.0654 - acc: 0.9923\n",
      "Epoch 15/20\n",
      "2205/2205 [==============================] - 10s 5ms/step - loss: 0.0570 - acc: 0.9914\n",
      "Epoch 16/20\n",
      "2205/2205 [==============================] - 10s 5ms/step - loss: 0.0482 - acc: 0.9927\n",
      "Epoch 17/20\n",
      "2205/2205 [==============================] - 10s 5ms/step - loss: 0.0462 - acc: 0.9932\n",
      "Epoch 18/20\n",
      "2205/2205 [==============================] - 10s 5ms/step - loss: 0.0420 - acc: 0.9937\n",
      "Epoch 19/20\n",
      "2205/2205 [==============================] - 10s 5ms/step - loss: 0.0391 - acc: 0.9927: 0s - loss: 0.0390 -\n",
      "Epoch 20/20\n",
      "2205/2205 [==============================] - 10s 5ms/step - loss: 0.0334 - acc: 0.9941\n",
      "2204/2204 [==============================] - 5s 2ms/step\n",
      "2205/2205 [==============================] - 3s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "2204/2204 [==============================] - 47s 21ms/step - loss: 0.6081 - acc: 0.6892\n",
      "Epoch 2/40\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.5327 - acc: 0.6897\n",
      "Epoch 3/40\n",
      "2204/2204 [==============================] - 10s 5ms/step - loss: 0.4702 - acc: 0.6897\n",
      "Epoch 4/40\n",
      "2204/2204 [==============================] - 10s 5ms/step - loss: 0.4008 - acc: 0.6901\n",
      "Epoch 5/40\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.3348 - acc: 0.7418\n",
      "Epoch 6/40\n",
      "2204/2204 [==============================] - 10s 5ms/step - loss: 0.2737 - acc: 0.9451\n",
      "Epoch 7/40\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.2213 - acc: 0.9723\n",
      "Epoch 8/40\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.1804 - acc: 0.9837\n",
      "Epoch 9/40\n",
      "2204/2204 [==============================] - 10s 5ms/step - loss: 0.1489 - acc: 0.9864\n",
      "Epoch 10/40\n",
      "2204/2204 [==============================] - 10s 5ms/step - loss: 0.1250 - acc: 0.9868\n",
      "Epoch 11/40\n",
      "2204/2204 [==============================] - 10s 5ms/step - loss: 0.1059 - acc: 0.9882\n",
      "Epoch 12/40\n",
      "2204/2204 [==============================] - 10s 5ms/step - loss: 0.0928 - acc: 0.9882\n",
      "Epoch 13/40\n",
      "2204/2204 [==============================] - 10s 5ms/step - loss: 0.0799 - acc: 0.9873\n",
      "Epoch 14/40\n",
      "2204/2204 [==============================] - 10s 5ms/step - loss: 0.0703 - acc: 0.9900\n",
      "Epoch 15/40\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0637 - acc: 0.9877\n",
      "Epoch 16/40\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0584 - acc: 0.9896\n",
      "Epoch 17/40\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0558 - acc: 0.9887\n",
      "Epoch 18/40\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0467 - acc: 0.9909\n",
      "Epoch 19/40\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0457 - acc: 0.9909: \n",
      "Epoch 20/40\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0433 - acc: 0.9914: - ETA: 0s - loss: 0.0434 - acc: 0.991\n",
      "Epoch 21/40\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0395 - acc: 0.9900\n",
      "Epoch 22/40\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0425 - acc: 0.9900\n",
      "Epoch 23/40\n",
      "2204/2204 [==============================] - 10s 5ms/step - loss: 0.0321 - acc: 0.9923\n",
      "Epoch 24/40\n",
      "2204/2204 [==============================] - 10s 4ms/step - loss: 0.0380 - acc: 0.9882: 0s - loss: 0.037\n",
      "Epoch 25/40\n",
      "2204/2204 [==============================] - 10s 5ms/step - loss: 0.0371 - acc: 0.9891\n",
      "Epoch 26/40\n",
      "2204/2204 [==============================] - 10s 5ms/step - loss: 0.0303 - acc: 0.9914\n",
      "Epoch 27/40\n",
      "2204/2204 [==============================] - 10s 5ms/step - loss: 0.0328 - acc: 0.9909\n",
      "Epoch 28/40\n",
      "2204/2204 [==============================] - 10s 4ms/step - loss: 0.0322 - acc: 0.9918\n",
      "Epoch 29/40\n",
      "2204/2204 [==============================] - 10s 5ms/step - loss: 0.0329 - acc: 0.9900\n",
      "Epoch 30/40\n",
      "2204/2204 [==============================] - 10s 5ms/step - loss: 0.0359 - acc: 0.9882\n",
      "Epoch 31/40\n",
      "2204/2204 [==============================] - 10s 5ms/step - loss: 0.0337 - acc: 0.9896\n",
      "Epoch 32/40\n",
      "2204/2204 [==============================] - 10s 4ms/step - loss: 0.0240 - acc: 0.9941\n",
      "Epoch 33/40\n",
      "2204/2204 [==============================] - 10s 5ms/step - loss: 0.0289 - acc: 0.9923\n",
      "Epoch 34/40\n",
      "2204/2204 [==============================] - 10s 4ms/step - loss: 0.0318 - acc: 0.9891\n",
      "Epoch 35/40\n",
      "2204/2204 [==============================] - 10s 5ms/step - loss: 0.0341 - acc: 0.9887: 2s - loss: 0.0328 -  - ETA:\n",
      "Epoch 36/40\n",
      "2204/2204 [==============================] - 10s 5ms/step - loss: 0.0307 - acc: 0.9909\n",
      "Epoch 37/40\n",
      "2204/2204 [==============================] - 10s 5ms/step - loss: 0.0311 - acc: 0.9923\n",
      "Epoch 38/40\n",
      "2204/2204 [==============================] - 10s 5ms/step - loss: 0.0302 - acc: 0.9905\n",
      "Epoch 39/40\n",
      "2204/2204 [==============================] - 10s 5ms/step - loss: 0.0251 - acc: 0.9927\n",
      "Epoch 40/40\n",
      "2204/2204 [==============================] - 10s 4ms/step - loss: 0.0256 - acc: 0.9932\n",
      "2205/2205 [==============================] - 8s 4ms/step\n",
      "2204/2204 [==============================] - 3s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "2205/2205 [==============================] - 25s 11ms/step - loss: 0.5942 - acc: 0.7070\n",
      "Epoch 2/40\n",
      "2205/2205 [==============================] - 10s 4ms/step - loss: 0.5142 - acc: 0.7075\n",
      "Epoch 3/40\n",
      "2205/2205 [==============================] - 10s 5ms/step - loss: 0.4526 - acc: 0.7075\n",
      "Epoch 4/40\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.3855 - acc: 0.7075\n",
      "Epoch 5/40\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.3196 - acc: 0.7429\n",
      "Epoch 6/40\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.2612 - acc: 0.9333\n",
      "Epoch 7/40\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.2129 - acc: 0.9741\n",
      "Epoch 8/40\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.1737 - acc: 0.9823\n",
      "Epoch 9/40\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.1408 - acc: 0.9891A: 0s - loss: 0.1407\n",
      "Epoch 10/40\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.1215 - acc: 0.9887\n",
      "Epoch 11/40\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.1001 - acc: 0.9900\n",
      "Epoch 12/40\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0848 - acc: 0.9923\n",
      "Epoch 13/40\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0760 - acc: 0.9900\n",
      "Epoch 14/40\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0658 - acc: 0.9896\n",
      "Epoch 15/40\n",
      "2205/2205 [==============================] - 10s 4ms/step - loss: 0.0593 - acc: 0.9896\n",
      "Epoch 16/40\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0519 - acc: 0.9927\n",
      "Epoch 17/40\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0458 - acc: 0.9941\n",
      "Epoch 18/40\n",
      "2205/2205 [==============================] - 10s 4ms/step - loss: 0.0440 - acc: 0.9932\n",
      "Epoch 19/40\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0415 - acc: 0.9923: 1s - lo\n",
      "Epoch 20/40\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0370 - acc: 0.9937\n",
      "Epoch 21/40\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0368 - acc: 0.9927\n",
      "Epoch 22/40\n",
      "2205/2205 [==============================] - 10s 4ms/step - loss: 0.0333 - acc: 0.9927: 0s - loss: 0.0336 - ac\n",
      "Epoch 23/40\n",
      "2205/2205 [==============================] - 10s 5ms/step - loss: 0.0313 - acc: 0.9941\n",
      "Epoch 24/40\n",
      "2205/2205 [==============================] - 10s 5ms/step - loss: 0.0309 - acc: 0.9946\n",
      "Epoch 25/40\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0291 - acc: 0.9937\n",
      "Epoch 26/40\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0260 - acc: 0.9955\n",
      "Epoch 27/40\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0317 - acc: 0.9927\n",
      "Epoch 28/40\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0259 - acc: 0.9927\n",
      "Epoch 29/40\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0283 - acc: 0.9932\n",
      "Epoch 30/40\n",
      "2205/2205 [==============================] - 10s 4ms/step - loss: 0.0288 - acc: 0.9918\n",
      "Epoch 31/40\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0267 - acc: 0.9923A: 0s - loss: 0.0242 -\n",
      "Epoch 32/40\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0277 - acc: 0.9918\n",
      "Epoch 33/40\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0268 - acc: 0.9927A: 0s - loss: 0.0272 - acc: 0.\n",
      "Epoch 34/40\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0277 - acc: 0.9918\n",
      "Epoch 35/40\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0234 - acc: 0.9959\n",
      "Epoch 36/40\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0256 - acc: 0.9918 - ETA: 1s - \n",
      "Epoch 37/40\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0287 - acc: 0.9918\n",
      "Epoch 38/40\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0242 - acc: 0.9941\n",
      "Epoch 39/40\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0220 - acc: 0.9946\n",
      "Epoch 40/40\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0208 - acc: 0.9937A: 0s - loss: 0.0211 - acc: 0.9\n",
      "2204/2204 [==============================] - 9s 4ms/step\n",
      "2205/2205 [==============================] - 3s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "2204/2204 [==============================] - 34s 15ms/step - loss: 0.6037 - acc: 0.6897\n",
      "Epoch 2/60\n",
      "2204/2204 [==============================] - 10s 5ms/step - loss: 0.5293 - acc: 0.6897\n",
      "Epoch 3/60\n",
      "2204/2204 [==============================] - 10s 5ms/step - loss: 0.4656 - acc: 0.6897\n",
      "Epoch 4/60\n",
      "2204/2204 [==============================] - 10s 5ms/step - loss: 0.3998 - acc: 0.6906\n",
      "Epoch 5/60\n",
      "2204/2204 [==============================] - 10s 5ms/step - loss: 0.3297 - acc: 0.7550\n",
      "Epoch 6/60\n",
      "2204/2204 [==============================] - 10s 4ms/step - loss: 0.2684 - acc: 0.9487\n",
      "Epoch 7/60\n",
      "2204/2204 [==============================] - 10s 5ms/step - loss: 0.2193 - acc: 0.9696\n",
      "Epoch 8/60\n",
      "2204/2204 [==============================] - 10s 5ms/step - loss: 0.1790 - acc: 0.9814: 1\n",
      "Epoch 9/60\n",
      "2204/2204 [==============================] - 10s 5ms/step - loss: 0.1467 - acc: 0.9841\n",
      "Epoch 10/60\n",
      "2204/2204 [==============================] - 10s 5ms/step - loss: 0.1233 - acc: 0.9859\n",
      "Epoch 11/60\n",
      "2204/2204 [==============================] - 10s 5ms/step - loss: 0.1053 - acc: 0.9877\n",
      "Epoch 12/60\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0878 - acc: 0.9882\n",
      "Epoch 13/60\n",
      "2204/2204 [==============================] - 10s 5ms/step - loss: 0.0776 - acc: 0.9882\n",
      "Epoch 14/60\n",
      "2204/2204 [==============================] - 10s 4ms/step - loss: 0.0704 - acc: 0.9873\n",
      "Epoch 15/60\n",
      "2204/2204 [==============================] - 10s 4ms/step - loss: 0.0610 - acc: 0.9891\n",
      "Epoch 16/60\n",
      "2204/2204 [==============================] - 9s 4ms/step - loss: 0.0550 - acc: 0.9896A: 1s - \n",
      "Epoch 17/60\n",
      "2204/2204 [==============================] - 9s 4ms/step - loss: 0.0523 - acc: 0.9887\n",
      "Epoch 18/60\n",
      "2204/2204 [==============================] - 9s 4ms/step - loss: 0.0477 - acc: 0.9896\n",
      "Epoch 19/60\n",
      "2204/2204 [==============================] - 9s 4ms/step - loss: 0.0422 - acc: 0.9914\n",
      "Epoch 20/60\n",
      "2204/2204 [==============================] - 9s 4ms/step - loss: 0.0410 - acc: 0.9909\n",
      "Epoch 21/60\n",
      "2204/2204 [==============================] - 9s 4ms/step - loss: 0.0366 - acc: 0.9927A: 0s - loss: 0.0368 - acc\n",
      "Epoch 22/60\n",
      "2204/2204 [==============================] - 9s 4ms/step - loss: 0.0361 - acc: 0.9914\n",
      "Epoch 23/60\n",
      "2204/2204 [==============================] - 9s 4ms/step - loss: 0.0347 - acc: 0.9905\n",
      "Epoch 24/60\n",
      "2204/2204 [==============================] - 9s 4ms/step - loss: 0.0347 - acc: 0.9887\n",
      "Epoch 25/60\n",
      "2204/2204 [==============================] - 9s 4ms/step - loss: 0.0345 - acc: 0.9877A: 0s - loss: 0.0354 - \n",
      "Epoch 26/60\n",
      "2204/2204 [==============================] - 9s 4ms/step - loss: 0.0346 - acc: 0.9900\n",
      "Epoch 27/60\n",
      "2204/2204 [==============================] - 9s 4ms/step - loss: 0.0280 - acc: 0.9918\n",
      "Epoch 28/60\n",
      "2204/2204 [==============================] - 9s 4ms/step - loss: 0.0289 - acc: 0.9923\n",
      "Epoch 29/60\n",
      "2204/2204 [==============================] - 9s 4ms/step - loss: 0.0332 - acc: 0.9887\n",
      "Epoch 30/60\n",
      "2204/2204 [==============================] - 9s 4ms/step - loss: 0.0275 - acc: 0.9941\n",
      "Epoch 31/60\n",
      "2204/2204 [==============================] - 9s 4ms/step - loss: 0.0316 - acc: 0.9896\n",
      "Epoch 32/60\n",
      "2204/2204 [==============================] - 9s 4ms/step - loss: 0.0303 - acc: 0.9900\n",
      "Epoch 33/60\n",
      "2204/2204 [==============================] - 9s 4ms/step - loss: 0.0271 - acc: 0.9914\n",
      "Epoch 34/60\n",
      "2204/2204 [==============================] - 9s 4ms/step - loss: 0.0303 - acc: 0.9900\n",
      "Epoch 35/60\n",
      "2204/2204 [==============================] - 9s 4ms/step - loss: 0.0250 - acc: 0.9923\n",
      "Epoch 36/60\n",
      "2204/2204 [==============================] - 9s 4ms/step - loss: 0.0281 - acc: 0.9905\n",
      "Epoch 37/60\n",
      "2204/2204 [==============================] - 9s 4ms/step - loss: 0.0243 - acc: 0.9914\n",
      "Epoch 38/60\n",
      "2204/2204 [==============================] - 9s 4ms/step - loss: 0.0275 - acc: 0.9887\n",
      "Epoch 39/60\n",
      "2204/2204 [==============================] - 9s 4ms/step - loss: 0.0261 - acc: 0.9914A: 1s - los\n",
      "Epoch 40/60\n",
      "2204/2204 [==============================] - 9s 4ms/step - loss: 0.0272 - acc: 0.9896A: 1s - loss:\n",
      "Epoch 41/60\n",
      "2204/2204 [==============================] - 9s 4ms/step - loss: 0.0264 - acc: 0.9905\n",
      "Epoch 42/60\n",
      "2204/2204 [==============================] - 9s 4ms/step - loss: 0.0259 - acc: 0.9891\n",
      "Epoch 43/60\n",
      "2204/2204 [==============================] - 9s 4ms/step - loss: 0.0271 - acc: 0.9900\n",
      "Epoch 44/60\n",
      "2204/2204 [==============================] - 9s 4ms/step - loss: 0.0229 - acc: 0.9914\n",
      "Epoch 45/60\n",
      "2204/2204 [==============================] - 9s 4ms/step - loss: 0.0250 - acc: 0.9914\n",
      "Epoch 46/60\n",
      "2204/2204 [==============================] - 9s 4ms/step - loss: 0.0257 - acc: 0.9914A: 1s - loss: 0\n",
      "Epoch 47/60\n",
      "2204/2204 [==============================] - 9s 4ms/step - loss: 0.0238 - acc: 0.9918\n",
      "Epoch 48/60\n",
      "2204/2204 [==============================] - 9s 4ms/step - loss: 0.0222 - acc: 0.9923\n",
      "Epoch 49/60\n",
      "2204/2204 [==============================] - 9s 4ms/step - loss: 0.0255 - acc: 0.9918A: 0s - loss: 0.0259 - acc: 0.9\n",
      "Epoch 50/60\n",
      "2204/2204 [==============================] - 9s 4ms/step - loss: 0.0245 - acc: 0.9905\n",
      "Epoch 51/60\n",
      "2204/2204 [==============================] - 9s 4ms/step - loss: 0.0284 - acc: 0.9896\n",
      "Epoch 52/60\n",
      "2204/2204 [==============================] - 9s 4ms/step - loss: 0.0228 - acc: 0.9914\n",
      "Epoch 53/60\n",
      "2204/2204 [==============================] - 10s 4ms/step - loss: 0.0224 - acc: 0.9914\n",
      "Epoch 54/60\n",
      "2204/2204 [==============================] - 9s 4ms/step - loss: 0.0242 - acc: 0.9900\n",
      "Epoch 55/60\n",
      "2204/2204 [==============================] - 9s 4ms/step - loss: 0.0239 - acc: 0.9923\n",
      "Epoch 56/60\n",
      "2204/2204 [==============================] - 9s 4ms/step - loss: 0.0250 - acc: 0.9900\n",
      "Epoch 57/60\n",
      "2204/2204 [==============================] - 9s 4ms/step - loss: 0.0251 - acc: 0.9900\n",
      "Epoch 58/60\n",
      "2204/2204 [==============================] - 9s 4ms/step - loss: 0.0253 - acc: 0.9923\n",
      "Epoch 59/60\n",
      "2204/2204 [==============================] - 9s 4ms/step - loss: 0.0216 - acc: 0.9932\n",
      "Epoch 60/60\n",
      "2204/2204 [==============================] - 9s 4ms/step - loss: 0.0222 - acc: 0.9905\n",
      "2205/2205 [==============================] - 9s 4ms/step\n",
      "2204/2204 [==============================] - 3s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "  15/2205 [..............................] - ETA: 58:33 - loss: 0.6956 - acc: 0.4000  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.125505). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2205/2205 [==============================] - 42s 19ms/step - loss: 0.6008 - acc: 0.7034\n",
      "Epoch 2/60\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.5165 - acc: 0.7075\n",
      "Epoch 3/60\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.4531 - acc: 0.7075\n",
      "Epoch 4/60\n",
      "2205/2205 [==============================] - 10s 4ms/step - loss: 0.3866 - acc: 0.7075\n",
      "Epoch 5/60\n",
      "2205/2205 [==============================] - 10s 5ms/step - loss: 0.3187 - acc: 0.7401\n",
      "Epoch 6/60\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.2602 - acc: 0.9415\n",
      "Epoch 7/60\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.2144 - acc: 0.9705\n",
      "Epoch 8/60\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.1729 - acc: 0.9810\n",
      "Epoch 9/60\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.1437 - acc: 0.9878\n",
      "Epoch 10/60\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.1178 - acc: 0.9900\n",
      "Epoch 11/60\n",
      "2205/2205 [==============================] - 10s 4ms/step - loss: 0.0990 - acc: 0.9905\n",
      "Epoch 12/60\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0858 - acc: 0.9918\n",
      "Epoch 13/60\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0759 - acc: 0.9909\n",
      "Epoch 14/60\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0664 - acc: 0.9918\n",
      "Epoch 15/60\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0592 - acc: 0.9918\n",
      "Epoch 16/60\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0519 - acc: 0.9923\n",
      "Epoch 17/60\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0466 - acc: 0.9955\n",
      "Epoch 18/60\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0431 - acc: 0.9932A: 1s - loss: 0.\n",
      "Epoch 19/60\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0377 - acc: 0.9923\n",
      "Epoch 20/60\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0348 - acc: 0.9950\n",
      "Epoch 21/60\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0360 - acc: 0.9932\n",
      "Epoch 22/60\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0306 - acc: 0.9941\n",
      "Epoch 23/60\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0308 - acc: 0.9937\n",
      "Epoch 24/60\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0315 - acc: 0.9909\n",
      "Epoch 25/60\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0275 - acc: 0.9946\n",
      "Epoch 26/60\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0280 - acc: 0.9932\n",
      "Epoch 27/60\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0271 - acc: 0.9959\n",
      "Epoch 28/60\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0287 - acc: 0.9932\n",
      "Epoch 29/60\n",
      "2205/2205 [==============================] - 10s 5ms/step - loss: 0.0280 - acc: 0.9914\n",
      "Epoch 30/60\n",
      "2205/2205 [==============================] - 10s 5ms/step - loss: 0.0286 - acc: 0.9937\n",
      "Epoch 31/60\n",
      "2205/2205 [==============================] - 10s 4ms/step - loss: 0.0273 - acc: 0.9941\n",
      "Epoch 32/60\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0281 - acc: 0.9918A: 1s - loss:\n",
      "Epoch 33/60\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0263 - acc: 0.9927\n",
      "Epoch 34/60\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0242 - acc: 0.9927\n",
      "Epoch 35/60\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0215 - acc: 0.9950\n",
      "Epoch 36/60\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0260 - acc: 0.9932\n",
      "Epoch 37/60\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0218 - acc: 0.9950\n",
      "Epoch 38/60\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0266 - acc: 0.9932\n",
      "Epoch 39/60\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0258 - acc: 0.9927\n",
      "Epoch 40/60\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0237 - acc: 0.9941\n",
      "Epoch 41/60\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0237 - acc: 0.9946\n",
      "Epoch 42/60\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0228 - acc: 0.9927\n",
      "Epoch 43/60\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0246 - acc: 0.9927\n",
      "Epoch 44/60\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0238 - acc: 0.9941\n",
      "Epoch 45/60\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0195 - acc: 0.9955\n",
      "Epoch 46/60\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0239 - acc: 0.9932A: \n",
      "Epoch 47/60\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0197 - acc: 0.9932\n",
      "Epoch 48/60\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0265 - acc: 0.9923\n",
      "Epoch 49/60\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0222 - acc: 0.9937\n",
      "Epoch 50/60\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0211 - acc: 0.9946\n",
      "Epoch 51/60\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0211 - acc: 0.9950\n",
      "Epoch 52/60\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0187 - acc: 0.9950\n",
      "Epoch 53/60\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0247 - acc: 0.9914\n",
      "Epoch 54/60\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0208 - acc: 0.9941\n",
      "Epoch 55/60\n",
      "2205/2205 [==============================] - 10s 4ms/step - loss: 0.0247 - acc: 0.9927\n",
      "Epoch 56/60\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0221 - acc: 0.9932\n",
      "Epoch 57/60\n",
      "2205/2205 [==============================] - 10s 4ms/step - loss: 0.0182 - acc: 0.9937\n",
      "Epoch 58/60\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0201 - acc: 0.9955\n",
      "Epoch 59/60\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0220 - acc: 0.9937\n",
      "Epoch 60/60\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0211 - acc: 0.9937\n",
      "2204/2204 [==============================] - 8s 4ms/step\n",
      "2205/2205 [==============================] - 3s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2204/2204 [==============================] - 27s 12ms/step - loss: 0.6181 - acc: 0.6729\n",
      "Epoch 2/100\n",
      "2204/2204 [==============================] - 10s 4ms/step - loss: 0.5328 - acc: 0.6897\n",
      "Epoch 3/100\n",
      "2204/2204 [==============================] - 10s 4ms/step - loss: 0.4670 - acc: 0.6897\n",
      "Epoch 4/100\n",
      "2204/2204 [==============================] - 10s 5ms/step - loss: 0.3979 - acc: 0.6901\n",
      "Epoch 5/100\n",
      "2204/2204 [==============================] - 10s 5ms/step - loss: 0.3280 - acc: 0.7591\n",
      "Epoch 6/100\n",
      "2204/2204 [==============================] - 10s 5ms/step - loss: 0.2691 - acc: 0.9483\n",
      "Epoch 7/100\n",
      "2204/2204 [==============================] - 10s 5ms/step - loss: 0.2174 - acc: 0.9714\n",
      "Epoch 8/100\n",
      "2204/2204 [==============================] - 10s 5ms/step - loss: 0.1781 - acc: 0.9823\n",
      "Epoch 9/100\n",
      "2204/2204 [==============================] - 9s 4ms/step - loss: 0.1458 - acc: 0.9859\n",
      "Epoch 10/100\n",
      "2204/2204 [==============================] - 9s 4ms/step - loss: 0.1247 - acc: 0.9864\n",
      "Epoch 11/100\n",
      "2204/2204 [==============================] - 9s 4ms/step - loss: 0.1014 - acc: 0.9896\n",
      "Epoch 12/100\n",
      "2204/2204 [==============================] - 9s 4ms/step - loss: 0.0884 - acc: 0.9896\n",
      "Epoch 13/100\n",
      "2204/2204 [==============================] - 10s 4ms/step - loss: 0.0784 - acc: 0.9887\n",
      "Epoch 14/100\n",
      "2204/2204 [==============================] - 10s 5ms/step - loss: 0.0690 - acc: 0.9900\n",
      "Epoch 15/100\n",
      "2204/2204 [==============================] - 10s 4ms/step - loss: 0.0634 - acc: 0.9896\n",
      "Epoch 16/100\n",
      "2204/2204 [==============================] - 9s 4ms/step - loss: 0.0574 - acc: 0.9887\n",
      "Epoch 17/100\n",
      "2204/2204 [==============================] - 9s 4ms/step - loss: 0.0506 - acc: 0.9909A: 1s - loss: \n",
      "Epoch 18/100\n",
      "2204/2204 [==============================] - 10s 4ms/step - loss: 0.0460 - acc: 0.9923\n",
      "Epoch 19/100\n",
      "2204/2204 [==============================] - 10s 4ms/step - loss: 0.0423 - acc: 0.9905\n",
      "Epoch 20/100\n",
      "2204/2204 [==============================] - 10s 5ms/step - loss: 0.0419 - acc: 0.9891\n",
      "Epoch 21/100\n",
      "2204/2204 [==============================] - 10s 5ms/step - loss: 0.0392 - acc: 0.9918\n",
      "Epoch 22/100\n",
      "2204/2204 [==============================] - 10s 5ms/step - loss: 0.0406 - acc: 0.9887\n",
      "Epoch 23/100\n",
      "2204/2204 [==============================] - 10s 4ms/step - loss: 0.0402 - acc: 0.9900\n",
      "Epoch 24/100\n",
      "2204/2204 [==============================] - 10s 4ms/step - loss: 0.0351 - acc: 0.9923\n",
      "Epoch 25/100\n",
      "2204/2204 [==============================] - 10s 4ms/step - loss: 0.0317 - acc: 0.9900\n",
      "Epoch 26/100\n",
      "2204/2204 [==============================] - 10s 4ms/step - loss: 0.0334 - acc: 0.9905\n",
      "Epoch 27/100\n",
      "2204/2204 [==============================] - 10s 4ms/step - loss: 0.0300 - acc: 0.9909\n",
      "Epoch 28/100\n",
      "2204/2204 [==============================] - 9s 4ms/step - loss: 0.0293 - acc: 0.9914\n",
      "Epoch 29/100\n",
      "2204/2204 [==============================] - 10s 4ms/step - loss: 0.0314 - acc: 0.9914\n",
      "Epoch 30/100\n",
      "2204/2204 [==============================] - 9s 4ms/step - loss: 0.0293 - acc: 0.9905\n",
      "Epoch 31/100\n",
      "2204/2204 [==============================] - 9s 4ms/step - loss: 0.0333 - acc: 0.9891\n",
      "Epoch 32/100\n",
      "2204/2204 [==============================] - 10s 4ms/step - loss: 0.0282 - acc: 0.9891\n",
      "Epoch 33/100\n",
      "2204/2204 [==============================] - 9s 4ms/step - loss: 0.0291 - acc: 0.9905\n",
      "Epoch 34/100\n",
      "2204/2204 [==============================] - 10s 5ms/step - loss: 0.0325 - acc: 0.9891\n",
      "Epoch 35/100\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0279 - acc: 0.9909\n",
      "Epoch 36/100\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0281 - acc: 0.9914\n",
      "Epoch 37/100\n",
      "2204/2204 [==============================] - 9s 4ms/step - loss: 0.0273 - acc: 0.9914\n",
      "Epoch 38/100\n",
      "2204/2204 [==============================] - 10s 4ms/step - loss: 0.0250 - acc: 0.9941\n",
      "Epoch 39/100\n",
      "2204/2204 [==============================] - 9s 4ms/step - loss: 0.0261 - acc: 0.9900\n",
      "Epoch 40/100\n",
      "2204/2204 [==============================] - 10s 4ms/step - loss: 0.0270 - acc: 0.9882\n",
      "Epoch 41/100\n",
      "2204/2204 [==============================] - 10s 4ms/step - loss: 0.0263 - acc: 0.9909\n",
      "Epoch 42/100\n",
      "2204/2204 [==============================] - 10s 4ms/step - loss: 0.0267 - acc: 0.9900\n",
      "Epoch 43/100\n",
      "2204/2204 [==============================] - 10s 4ms/step - loss: 0.0283 - acc: 0.9896\n",
      "Epoch 44/100\n",
      "2204/2204 [==============================] - 9s 4ms/step - loss: 0.0241 - acc: 0.9914\n",
      "Epoch 45/100\n",
      "2204/2204 [==============================] - 10s 4ms/step - loss: 0.0298 - acc: 0.9887\n",
      "Epoch 46/100\n",
      "2204/2204 [==============================] - 9s 4ms/step - loss: 0.0265 - acc: 0.9909\n",
      "Epoch 47/100\n",
      "2204/2204 [==============================] - 10s 4ms/step - loss: 0.0248 - acc: 0.9923\n",
      "Epoch 48/100\n",
      "2204/2204 [==============================] - 10s 4ms/step - loss: 0.0284 - acc: 0.9877\n",
      "Epoch 49/100\n",
      "2204/2204 [==============================] - 10s 4ms/step - loss: 0.0264 - acc: 0.9918\n",
      "Epoch 50/100\n",
      "2204/2204 [==============================] - 10s 4ms/step - loss: 0.0241 - acc: 0.9914\n",
      "Epoch 51/100\n",
      "2204/2204 [==============================] - 9s 4ms/step - loss: 0.0230 - acc: 0.9941\n",
      "Epoch 52/100\n",
      "2204/2204 [==============================] - 10s 4ms/step - loss: 0.0205 - acc: 0.9941\n",
      "Epoch 53/100\n",
      "2204/2204 [==============================] - 10s 4ms/step - loss: 0.0279 - acc: 0.9905: 0s - loss: 0.0276 - ac\n",
      "Epoch 54/100\n",
      "2204/2204 [==============================] - 10s 4ms/step - loss: 0.0221 - acc: 0.9923\n",
      "Epoch 55/100\n",
      "2204/2204 [==============================] - 10s 4ms/step - loss: 0.0242 - acc: 0.9923\n",
      "Epoch 56/100\n",
      "2204/2204 [==============================] - 10s 5ms/step - loss: 0.0255 - acc: 0.9905\n",
      "Epoch 57/100\n",
      "2204/2204 [==============================] - 10s 5ms/step - loss: 0.0242 - acc: 0.9905\n",
      "Epoch 58/100\n",
      "2204/2204 [==============================] - 10s 4ms/step - loss: 0.0290 - acc: 0.9887\n",
      "Epoch 59/100\n",
      "2204/2204 [==============================] - 10s 4ms/step - loss: 0.0216 - acc: 0.9923\n",
      "Epoch 60/100\n",
      "2204/2204 [==============================] - 10s 4ms/step - loss: 0.0265 - acc: 0.9905\n",
      "Epoch 61/100\n",
      "2204/2204 [==============================] - 10s 4ms/step - loss: 0.0248 - acc: 0.9923\n",
      "Epoch 62/100\n",
      "2204/2204 [==============================] - 9s 4ms/step - loss: 0.0291 - acc: 0.9891A: 0s - loss: 0.0297 - acc: 0.\n",
      "Epoch 63/100\n",
      "2204/2204 [==============================] - 9s 4ms/step - loss: 0.0221 - acc: 0.9914A: 1s - l\n",
      "Epoch 64/100\n",
      "2204/2204 [==============================] - 9s 4ms/step - loss: 0.0238 - acc: 0.9909A: 2s - loss: 0.021 - ETA: \n",
      "Epoch 65/100\n",
      "2204/2204 [==============================] - 9s 4ms/step - loss: 0.0208 - acc: 0.9914\n",
      "Epoch 66/100\n",
      "2204/2204 [==============================] - 10s 4ms/step - loss: 0.0245 - acc: 0.9909\n",
      "Epoch 67/100\n",
      "2204/2204 [==============================] - 9s 4ms/step - loss: 0.0270 - acc: 0.9900\n",
      "Epoch 68/100\n",
      "2204/2204 [==============================] - 10s 4ms/step - loss: 0.0257 - acc: 0.9909\n",
      "Epoch 69/100\n",
      "2204/2204 [==============================] - 10s 4ms/step - loss: 0.0219 - acc: 0.9932\n",
      "Epoch 70/100\n",
      "2204/2204 [==============================] - 10s 4ms/step - loss: 0.0225 - acc: 0.9918\n",
      "Epoch 71/100\n",
      "2204/2204 [==============================] - 9s 4ms/step - loss: 0.0203 - acc: 0.9918\n",
      "Epoch 72/100\n",
      "2204/2204 [==============================] - 10s 4ms/step - loss: 0.0211 - acc: 0.9923\n",
      "Epoch 73/100\n",
      "2204/2204 [==============================] - 10s 4ms/step - loss: 0.0204 - acc: 0.9918: 0s - loss: 0.0205 - acc: 0.991\n",
      "Epoch 74/100\n",
      "2204/2204 [==============================] - 10s 4ms/step - loss: 0.0208 - acc: 0.9932\n",
      "Epoch 75/100\n",
      "2204/2204 [==============================] - 10s 4ms/step - loss: 0.0197 - acc: 0.9946\n",
      "Epoch 76/100\n",
      "2204/2204 [==============================] - 10s 4ms/step - loss: 0.0212 - acc: 0.9914\n",
      "Epoch 77/100\n",
      "2204/2204 [==============================] - 10s 4ms/step - loss: 0.0271 - acc: 0.9896\n",
      "Epoch 78/100\n",
      "2204/2204 [==============================] - 10s 4ms/step - loss: 0.0236 - acc: 0.9900\n",
      "Epoch 79/100\n",
      "2204/2204 [==============================] - 10s 4ms/step - loss: 0.0239 - acc: 0.9914\n",
      "Epoch 80/100\n",
      "2204/2204 [==============================] - 10s 4ms/step - loss: 0.0238 - acc: 0.9891\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2204/2204 [==============================] - 9s 4ms/step - loss: 0.0211 - acc: 0.9923\n",
      "Epoch 82/100\n",
      "2204/2204 [==============================] - 9s 4ms/step - loss: 0.0242 - acc: 0.9905\n",
      "Epoch 83/100\n",
      "2204/2204 [==============================] - 9s 4ms/step - loss: 0.0236 - acc: 0.9896A: 0s - loss: 0.0238 - a\n",
      "Epoch 84/100\n",
      "2204/2204 [==============================] - 9s 4ms/step - loss: 0.0266 - acc: 0.9896\n",
      "Epoch 85/100\n",
      "2204/2204 [==============================] - 9s 4ms/step - loss: 0.0254 - acc: 0.9909\n",
      "Epoch 86/100\n",
      "2204/2204 [==============================] - 9s 4ms/step - loss: 0.0285 - acc: 0.9887\n",
      "Epoch 87/100\n",
      "2204/2204 [==============================] - 9s 4ms/step - loss: 0.0231 - acc: 0.9909\n",
      "Epoch 88/100\n",
      "2204/2204 [==============================] - 9s 4ms/step - loss: 0.0227 - acc: 0.9914\n",
      "Epoch 89/100\n",
      "2204/2204 [==============================] - 9s 4ms/step - loss: 0.0244 - acc: 0.9909\n",
      "Epoch 90/100\n",
      "2204/2204 [==============================] - 9s 4ms/step - loss: 0.0253 - acc: 0.9905\n",
      "Epoch 91/100\n",
      "2204/2204 [==============================] - 9s 4ms/step - loss: 0.0207 - acc: 0.9914A: 1s - loss:\n",
      "Epoch 92/100\n",
      "2204/2204 [==============================] - 9s 4ms/step - loss: 0.0235 - acc: 0.9905\n",
      "Epoch 93/100\n",
      "2204/2204 [==============================] - 9s 4ms/step - loss: 0.0249 - acc: 0.9923\n",
      "Epoch 94/100\n",
      "2204/2204 [==============================] - 10s 4ms/step - loss: 0.0232 - acc: 0.9918\n",
      "Epoch 95/100\n",
      "2204/2204 [==============================] - 9s 4ms/step - loss: 0.0256 - acc: 0.9909A: 1s - loss: 0.\n",
      "Epoch 96/100\n",
      "2204/2204 [==============================] - 9s 4ms/step - loss: 0.0230 - acc: 0.9900\n",
      "Epoch 97/100\n",
      "2204/2204 [==============================] - 9s 4ms/step - loss: 0.0244 - acc: 0.9891\n",
      "Epoch 98/100\n",
      "2204/2204 [==============================] - 10s 4ms/step - loss: 0.0205 - acc: 0.9909\n",
      "Epoch 99/100\n",
      "2204/2204 [==============================] - 10s 4ms/step - loss: 0.0245 - acc: 0.9896\n",
      "Epoch 100/100\n",
      "2204/2204 [==============================] - 9s 4ms/step - loss: 0.0200 - acc: 0.9918\n",
      "2205/2205 [==============================] - 8s 4ms/step\n",
      "2204/2204 [==============================] - 3s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "  30/2205 [..............................] - ETA: 10:51 - loss: 0.6940 - acc: 0.4333"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.141664). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2205/2205 [==============================] - 25s 11ms/step - loss: 0.5995 - acc: 0.7025\n",
      "Epoch 2/100\n",
      "2205/2205 [==============================] - 10s 4ms/step - loss: 0.5130 - acc: 0.7075\n",
      "Epoch 3/100\n",
      "2205/2205 [==============================] - 10s 4ms/step - loss: 0.4478 - acc: 0.7075\n",
      "Epoch 4/100\n",
      "2205/2205 [==============================] - 10s 5ms/step - loss: 0.3812 - acc: 0.7075\n",
      "Epoch 5/100\n",
      "2205/2205 [==============================] - 10s 5ms/step - loss: 0.3130 - acc: 0.7601\n",
      "Epoch 6/100\n",
      "2205/2205 [==============================] - 10s 5ms/step - loss: 0.2565 - acc: 0.9537\n",
      "Epoch 7/100\n",
      "2205/2205 [==============================] - 10s 5ms/step - loss: 0.2074 - acc: 0.9760\n",
      "Epoch 8/100\n",
      "2205/2205 [==============================] - 10s 4ms/step - loss: 0.1698 - acc: 0.9837\n",
      "Epoch 9/100\n",
      "2205/2205 [==============================] - 10s 4ms/step - loss: 0.1397 - acc: 0.9864\n",
      "Epoch 10/100\n",
      "2205/2205 [==============================] - 10s 5ms/step - loss: 0.1159 - acc: 0.9887\n",
      "Epoch 11/100\n",
      "2205/2205 [==============================] - 10s 5ms/step - loss: 0.0982 - acc: 0.9900\n",
      "Epoch 12/100\n",
      "2205/2205 [==============================] - 10s 5ms/step - loss: 0.0842 - acc: 0.9918\n",
      "Epoch 13/100\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0722 - acc: 0.9914\n",
      "Epoch 14/100\n",
      "2205/2205 [==============================] - 10s 5ms/step - loss: 0.0622 - acc: 0.9932\n",
      "Epoch 15/100\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0555 - acc: 0.9932\n",
      "Epoch 16/100\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0511 - acc: 0.9918A: 0s - loss: 0.0525 \n",
      "Epoch 17/100\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0462 - acc: 0.9937A: 1\n",
      "Epoch 18/100\n",
      "2205/2205 [==============================] - 10s 4ms/step - loss: 0.0428 - acc: 0.9941: 3s -\n",
      "Epoch 19/100\n",
      "2205/2205 [==============================] - 10s 4ms/step - loss: 0.0419 - acc: 0.9909: 0s - loss: 0.0432 \n",
      "Epoch 20/100\n",
      "2205/2205 [==============================] - 10s 4ms/step - loss: 0.0351 - acc: 0.9941\n",
      "Epoch 21/100\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0332 - acc: 0.9932A: 4s \n",
      "Epoch 22/100\n",
      "2205/2205 [==============================] - 10s 4ms/step - loss: 0.0319 - acc: 0.9937\n",
      "Epoch 23/100\n",
      "2205/2205 [==============================] - 10s 4ms/step - loss: 0.0325 - acc: 0.9927\n",
      "Epoch 24/100\n",
      "2205/2205 [==============================] - 10s 4ms/step - loss: 0.0281 - acc: 0.9946: 1s - loss: 0.\n",
      "Epoch 25/100\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0274 - acc: 0.9941\n",
      "Epoch 26/100\n",
      "2205/2205 [==============================] - 10s 4ms/step - loss: 0.0260 - acc: 0.9941: 1\n",
      "Epoch 27/100\n",
      "2205/2205 [==============================] - 10s 4ms/step - loss: 0.0259 - acc: 0.9932: 1s - lo\n",
      "Epoch 28/100\n",
      "2205/2205 [==============================] - 10s 4ms/step - loss: 0.0260 - acc: 0.9937: 0s - loss: 0.0268 - acc\n",
      "Epoch 29/100\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0249 - acc: 0.9937\n",
      "Epoch 30/100\n",
      "2205/2205 [==============================] - 10s 4ms/step - loss: 0.0275 - acc: 0.9923: 0s - loss: 0.02\n",
      "Epoch 31/100\n",
      "2205/2205 [==============================] - 10s 4ms/step - loss: 0.0249 - acc: 0.9927\n",
      "Epoch 32/100\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0232 - acc: 0.9941\n",
      "Epoch 33/100\n",
      "2205/2205 [==============================] - 10s 4ms/step - loss: 0.0229 - acc: 0.9937\n",
      "Epoch 34/100\n",
      "2205/2205 [==============================] - 10s 4ms/step - loss: 0.0218 - acc: 0.9937\n",
      "Epoch 35/100\n",
      "2205/2205 [==============================] - 10s 4ms/step - loss: 0.0255 - acc: 0.9918\n",
      "Epoch 36/100\n",
      "2205/2205 [==============================] - 10s 4ms/step - loss: 0.0218 - acc: 0.9932\n",
      "Epoch 37/100\n",
      "2205/2205 [==============================] - 10s 4ms/step - loss: 0.0231 - acc: 0.9937\n",
      "Epoch 38/100\n",
      "2205/2205 [==============================] - 10s 4ms/step - loss: 0.0223 - acc: 0.9955\n",
      "Epoch 39/100\n",
      "2205/2205 [==============================] - 10s 4ms/step - loss: 0.0212 - acc: 0.9927\n",
      "Epoch 40/100\n",
      "2205/2205 [==============================] - 10s 4ms/step - loss: 0.0226 - acc: 0.9923\n",
      "Epoch 41/100\n",
      "2205/2205 [==============================] - 10s 5ms/step - loss: 0.0218 - acc: 0.9937\n",
      "Epoch 42/100\n",
      "2205/2205 [==============================] - 10s 5ms/step - loss: 0.0232 - acc: 0.9941\n",
      "Epoch 43/100\n",
      "2205/2205 [==============================] - 10s 4ms/step - loss: 0.0183 - acc: 0.9937\n",
      "Epoch 44/100\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0201 - acc: 0.9937\n",
      "Epoch 45/100\n",
      "2205/2205 [==============================] - 10s 4ms/step - loss: 0.0236 - acc: 0.9932\n",
      "Epoch 46/100\n",
      "2205/2205 [==============================] - 10s 4ms/step - loss: 0.0228 - acc: 0.9927: 0s - loss: 0.0235 - ac\n",
      "Epoch 47/100\n",
      "2205/2205 [==============================] - 10s 4ms/step - loss: 0.0242 - acc: 0.9932\n",
      "Epoch 48/100\n",
      "2205/2205 [==============================] - 10s 4ms/step - loss: 0.0197 - acc: 0.9955\n",
      "Epoch 49/100\n",
      "2205/2205 [==============================] - 10s 4ms/step - loss: 0.0230 - acc: 0.9905\n",
      "Epoch 50/100\n",
      "2205/2205 [==============================] - 10s 4ms/step - loss: 0.0173 - acc: 0.9955\n",
      "Epoch 51/100\n",
      "2205/2205 [==============================] - 10s 4ms/step - loss: 0.0179 - acc: 0.9941\n",
      "Epoch 52/100\n",
      "2205/2205 [==============================] - 10s 4ms/step - loss: 0.0227 - acc: 0.9927: 0s - loss: 0.0221 - acc: 0.9\n",
      "Epoch 53/100\n",
      "2205/2205 [==============================] - 10s 4ms/step - loss: 0.0205 - acc: 0.9909\n",
      "Epoch 54/100\n",
      "2205/2205 [==============================] - 10s 4ms/step - loss: 0.0175 - acc: 0.9946: 1s - loss: 0.0176 - acc: - ETA: 1s - lo\n",
      "Epoch 55/100\n",
      "2205/2205 [==============================] - 10s 4ms/step - loss: 0.0207 - acc: 0.9932\n",
      "Epoch 56/100\n",
      "2205/2205 [==============================] - 10s 4ms/step - loss: 0.0201 - acc: 0.9927\n",
      "Epoch 57/100\n",
      "2205/2205 [==============================] - 10s 4ms/step - loss: 0.0258 - acc: 0.9927\n",
      "Epoch 58/100\n",
      "2205/2205 [==============================] - 10s 4ms/step - loss: 0.0208 - acc: 0.9914\n",
      "Epoch 59/100\n",
      "2205/2205 [==============================] - 10s 4ms/step - loss: 0.0237 - acc: 0.9932\n",
      "Epoch 60/100\n",
      "2205/2205 [==============================] - 10s 4ms/step - loss: 0.0210 - acc: 0.9932\n",
      "Epoch 61/100\n",
      "2205/2205 [==============================] - 10s 4ms/step - loss: 0.0197 - acc: 0.9932\n",
      "Epoch 62/100\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0197 - acc: 0.9927\n",
      "Epoch 63/100\n",
      "2205/2205 [==============================] - 10s 4ms/step - loss: 0.0212 - acc: 0.9923\n",
      "Epoch 64/100\n",
      "2205/2205 [==============================] - 10s 4ms/step - loss: 0.0200 - acc: 0.9927\n",
      "Epoch 65/100\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0143 - acc: 0.9950\n",
      "Epoch 66/100\n",
      "2205/2205 [==============================] - 10s 4ms/step - loss: 0.0202 - acc: 0.9927\n",
      "Epoch 67/100\n",
      "2205/2205 [==============================] - 10s 4ms/step - loss: 0.0194 - acc: 0.9923\n",
      "Epoch 68/100\n",
      "2205/2205 [==============================] - 10s 4ms/step - loss: 0.0231 - acc: 0.9923\n",
      "Epoch 69/100\n",
      "2205/2205 [==============================] - 10s 4ms/step - loss: 0.0226 - acc: 0.9923\n",
      "Epoch 70/100\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0229 - acc: 0.9923\n",
      "Epoch 71/100\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0180 - acc: 0.9950\n",
      "Epoch 72/100\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0201 - acc: 0.9941TA: 0s - loss: 0.0189 - acc: 0.99\n",
      "Epoch 73/100\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0183 - acc: 0.9932\n",
      "Epoch 74/100\n",
      "2205/2205 [==============================] - 10s 4ms/step - loss: 0.0210 - acc: 0.9905\n",
      "Epoch 75/100\n",
      "2205/2205 [==============================] - 10s 4ms/step - loss: 0.0197 - acc: 0.9937\n",
      "Epoch 76/100\n",
      "2205/2205 [==============================] - 10s 4ms/step - loss: 0.0214 - acc: 0.9914\n",
      "Epoch 77/100\n",
      "2205/2205 [==============================] - 10s 4ms/step - loss: 0.0206 - acc: 0.9941\n",
      "Epoch 78/100\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0226 - acc: 0.9918\n",
      "Epoch 79/100\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0202 - acc: 0.9937\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0200 - acc: 0.9932\n",
      "Epoch 81/100\n",
      "2205/2205 [==============================] - 10s 4ms/step - loss: 0.0193 - acc: 0.9923\n",
      "Epoch 82/100\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0261 - acc: 0.9909\n",
      "Epoch 83/100\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0236 - acc: 0.9905\n",
      "Epoch 84/100\n",
      "2205/2205 [==============================] - 10s 4ms/step - loss: 0.0153 - acc: 0.9950\n",
      "Epoch 85/100\n",
      "2205/2205 [==============================] - 10s 4ms/step - loss: 0.0232 - acc: 0.9932: 0s - loss: 0.0225 - acc: 0.\n",
      "Epoch 86/100\n",
      "2205/2205 [==============================] - 10s 4ms/step - loss: 0.0229 - acc: 0.9909\n",
      "Epoch 87/100\n",
      "2205/2205 [==============================] - 10s 4ms/step - loss: 0.0181 - acc: 0.9927: 1s -\n",
      "Epoch 88/100\n",
      "2205/2205 [==============================] - 10s 4ms/step - loss: 0.0231 - acc: 0.9932\n",
      "Epoch 89/100\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0191 - acc: 0.9946\n",
      "Epoch 90/100\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0217 - acc: 0.9923\n",
      "Epoch 91/100\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0161 - acc: 0.9932\n",
      "Epoch 92/100\n",
      "2205/2205 [==============================] - 10s 4ms/step - loss: 0.0162 - acc: 0.9950\n",
      "Epoch 93/100\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0202 - acc: 0.9932\n",
      "Epoch 94/100\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0191 - acc: 0.9946A: 0s - loss: 0.0198 - acc\n",
      "Epoch 95/100\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0186 - acc: 0.9932\n",
      "Epoch 96/100\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0174 - acc: 0.9950\n",
      "Epoch 97/100\n",
      "2205/2205 [==============================] - 10s 4ms/step - loss: 0.0190 - acc: 0.9932\n",
      "Epoch 98/100\n",
      "2205/2205 [==============================] - 10s 4ms/step - loss: 0.0227 - acc: 0.9932\n",
      "Epoch 99/100\n",
      "2205/2205 [==============================] - 10s 5ms/step - loss: 0.0194 - acc: 0.9932\n",
      "Epoch 100/100\n",
      "2205/2205 [==============================] - 9s 4ms/step - loss: 0.0196 - acc: 0.9923\n",
      "2204/2204 [==============================] - 6s 3ms/step\n",
      "2205/2205 [==============================] - 3s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2204/2204 [==============================] - 48s 22ms/step - loss: 0.6363 - acc: 0.6851\n",
      "Epoch 2/20\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.5591 - acc: 0.6897\n",
      "Epoch 3/20\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.5184 - acc: 0.6897\n",
      "Epoch 4/20\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.4780 - acc: 0.6897\n",
      "Epoch 5/20\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.4335 - acc: 0.6897\n",
      "Epoch 6/20\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.3861 - acc: 0.6897\n",
      "Epoch 7/20\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.3433 - acc: 0.7028\n",
      "Epoch 8/20\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.3023 - acc: 0.8299\n",
      "Epoch 9/20\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.2667 - acc: 0.9551\n",
      "Epoch 10/20\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.2345 - acc: 0.9673A: 0s - loss: 0.2367 - acc: \n",
      "Epoch 11/20\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.2077 - acc: 0.9787\n",
      "Epoch 12/20\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.1821 - acc: 0.9819\n",
      "Epoch 13/20\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.1636 - acc: 0.9868\n",
      "Epoch 14/20\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.1419 - acc: 0.9868\n",
      "Epoch 15/20\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.1254 - acc: 0.9882\n",
      "Epoch 16/20\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.1160 - acc: 0.9873\n",
      "Epoch 17/20\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.1043 - acc: 0.9909\n",
      "Epoch 18/20\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0955 - acc: 0.9882\n",
      "Epoch 19/20\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0882 - acc: 0.9887\n",
      "Epoch 20/20\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0803 - acc: 0.9887\n",
      "2205/2205 [==============================] - 8s 4ms/step\n",
      "2204/2204 [==============================] - 3s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "  20/2205 [..............................] - ETA: 33:52 - loss: 0.6781 - acc: 0.7000  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.174036). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2205/2205 [==============================] - 39s 18ms/step - loss: 0.6113 - acc: 0.7075\n",
      "Epoch 2/20\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.5416 - acc: 0.7075\n",
      "Epoch 3/20\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.5033 - acc: 0.7075\n",
      "Epoch 4/20\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.4624 - acc: 0.7075A: 4s - loss: 0.4898 - acc: 0.698 \n",
      "Epoch 5/20\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.4208 - acc: 0.7075\n",
      "Epoch 6/20\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.3761 - acc: 0.7075A: 5s - loss: 0 - ETA: 4s - loss: - ETA: 3s - loss: 0.3793 - a - ETA: 2s - loss: - ETA: 1s - l\n",
      "Epoch 7/20\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.3350 - acc: 0.7134\n",
      "Epoch 8/20\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.2959 - acc: 0.7950A: 0s - loss: 0.3016 -\n",
      "Epoch 9/20\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.2601 - acc: 0.9356\n",
      "Epoch 10/20\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.2310 - acc: 0.9710\n",
      "Epoch 11/20\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.2027 - acc: 0.9782\n",
      "Epoch 12/20\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.1784 - acc: 0.9841\n",
      "Epoch 13/20\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.1583 - acc: 0.9891A: 1s - loss\n",
      "Epoch 14/20\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.1411 - acc: 0.9887\n",
      "Epoch 15/20\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.1240 - acc: 0.9900A: 0s - loss: 0.1243 - ac\n",
      "Epoch 16/20\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.1096 - acc: 0.9909A: 1s -\n",
      "Epoch 17/20\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0994 - acc: 0.9927\n",
      "Epoch 18/20\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0900 - acc: 0.9927\n",
      "Epoch 19/20\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0832 - acc: 0.9927\n",
      "Epoch 20/20\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0755 - acc: 0.9941\n",
      "2204/2204 [==============================] - 11s 5ms/step\n",
      "2205/2205 [==============================] - 3s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "2204/2204 [==============================] - 19s 8ms/step - loss: 0.6427 - acc: 0.6638\n",
      "Epoch 2/40\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.5625 - acc: 0.6897\n",
      "Epoch 3/40\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.5199 - acc: 0.6897\n",
      "Epoch 4/40\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.4790 - acc: 0.6897\n",
      "Epoch 5/40\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.4331 - acc: 0.6897\n",
      "Epoch 6/40\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.3892 - acc: 0.6906\n",
      "Epoch 7/40\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.3447 - acc: 0.7024\n",
      "Epoch 8/40\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.3027 - acc: 0.8362\n",
      "Epoch 9/40\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.2670 - acc: 0.9555\n",
      "Epoch 10/40\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.2318 - acc: 0.9728\n",
      "Epoch 11/40\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.2051 - acc: 0.9814A: 0s - loss: 0.2079 - acc:\n",
      "Epoch 12/40\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.1804 - acc: 0.9846\n",
      "Epoch 13/40\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.1601 - acc: 0.9859\n",
      "Epoch 14/40\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.1421 - acc: 0.9864\n",
      "Epoch 15/40\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.1307 - acc: 0.9873\n",
      "Epoch 16/40\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.1114 - acc: 0.9887\n",
      "Epoch 17/40\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.1032 - acc: 0.9891A: 0s - loss: 0.1022 - a\n",
      "Epoch 18/40\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0951 - acc: 0.9900\n",
      "Epoch 19/40\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0865 - acc: 0.9909\n",
      "Epoch 20/40\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0798 - acc: 0.9909\n",
      "Epoch 21/40\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0744 - acc: 0.9896\n",
      "Epoch 22/40\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0716 - acc: 0.9891\n",
      "Epoch 23/40\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0647 - acc: 0.9914\n",
      "Epoch 24/40\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0622 - acc: 0.9900\n",
      "Epoch 25/40\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0560 - acc: 0.9896\n",
      "Epoch 26/40\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0534 - acc: 0.9905\n",
      "Epoch 27/40\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0503 - acc: 0.9927\n",
      "Epoch 28/40\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0482 - acc: 0.9896\n",
      "Epoch 29/40\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0473 - acc: 0.9905\n",
      "Epoch 30/40\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0454 - acc: 0.9900\n",
      "Epoch 31/40\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0441 - acc: 0.9909\n",
      "Epoch 32/40\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0426 - acc: 0.9887A: 3s - loss - ETA:\n",
      "Epoch 33/40\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0402 - acc: 0.9887\n",
      "Epoch 34/40\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0396 - acc: 0.9900\n",
      "Epoch 35/40\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0403 - acc: 0.9900\n",
      "Epoch 36/40\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0389 - acc: 0.9896\n",
      "Epoch 37/40\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0322 - acc: 0.9936\n",
      "Epoch 38/40\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0368 - acc: 0.9909\n",
      "Epoch 39/40\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0361 - acc: 0.9900\n",
      "Epoch 40/40\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0345 - acc: 0.9905\n",
      "2205/2205 [==============================] - 10s 5ms/step\n",
      "2204/2204 [==============================] - 3s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "2205/2205 [==============================] - 19s 8ms/step - loss: 0.6137 - acc: 0.7075\n",
      "Epoch 2/40\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.5433 - acc: 0.7075\n",
      "Epoch 3/40\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.5027 - acc: 0.7075\n",
      "Epoch 4/40\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.4636 - acc: 0.7075\n",
      "Epoch 5/40\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.4205 - acc: 0.7075\n",
      "Epoch 6/40\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.3760 - acc: 0.7079\n",
      "Epoch 7/40\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.3345 - acc: 0.7134A: 0s - loss: 0.3377 - acc:\n",
      "Epoch 8/40\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.2930 - acc: 0.7946\n",
      "Epoch 9/40\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.2586 - acc: 0.9569\n",
      "Epoch 10/40\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.2267 - acc: 0.9714\n",
      "Epoch 11/40\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.1996 - acc: 0.9778\n",
      "Epoch 12/40\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.1715 - acc: 0.9846\n",
      "Epoch 13/40\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.1538 - acc: 0.9882\n",
      "Epoch 14/40\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.1361 - acc: 0.9887\n",
      "Epoch 15/40\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.1214 - acc: 0.9891\n",
      "Epoch 16/40\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.1091 - acc: 0.9914\n",
      "Epoch 17/40\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0976 - acc: 0.9918\n",
      "Epoch 18/40\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0889 - acc: 0.9914\n",
      "Epoch 19/40\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0808 - acc: 0.9918\n",
      "Epoch 20/40\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0724 - acc: 0.9932\n",
      "Epoch 21/40\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0672 - acc: 0.9937\n",
      "Epoch 22/40\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0609 - acc: 0.9909\n",
      "Epoch 23/40\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0576 - acc: 0.9923\n",
      "Epoch 24/40\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0536 - acc: 0.9927\n",
      "Epoch 25/40\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0521 - acc: 0.9923\n",
      "Epoch 26/40\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0484 - acc: 0.9923\n",
      "Epoch 27/40\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0449 - acc: 0.9923\n",
      "Epoch 28/40\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0418 - acc: 0.9923\n",
      "Epoch 29/40\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0413 - acc: 0.9918\n",
      "Epoch 30/40\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0356 - acc: 0.9946\n",
      "Epoch 31/40\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0378 - acc: 0.9946\n",
      "Epoch 32/40\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0324 - acc: 0.9955\n",
      "Epoch 33/40\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0323 - acc: 0.9946\n",
      "Epoch 34/40\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0337 - acc: 0.9932\n",
      "Epoch 35/40\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0309 - acc: 0.9955\n",
      "Epoch 36/40\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0288 - acc: 0.9941\n",
      "Epoch 37/40\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0293 - acc: 0.9946 ETA: 2s - l - ETA: 1s - loss: \n",
      "Epoch 38/40\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0297 - acc: 0.9927\n",
      "Epoch 39/40\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0265 - acc: 0.9932\n",
      "Epoch 40/40\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0249 - acc: 0.9941\n",
      "2204/2204 [==============================] - 5s 2ms/step\n",
      "2205/2205 [==============================] - 3s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "2204/2204 [==============================] - 17s 8ms/step - loss: 0.6343 - acc: 0.6856\n",
      "Epoch 2/60\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.5508 - acc: 0.6897\n",
      "Epoch 3/60\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.4829 - acc: 0.6897\n",
      "Epoch 4/60\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.4180 - acc: 0.6897\n",
      "Epoch 5/60\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.3558 - acc: 0.6978\n",
      "Epoch 6/60\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.3022 - acc: 0.8811\n",
      "Epoch 7/60\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.2582 - acc: 0.9369\n",
      "Epoch 8/60\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.2219 - acc: 0.9483\n",
      "Epoch 9/60\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.1966 - acc: 0.9574\n",
      "Epoch 10/60\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.1725 - acc: 0.9696\n",
      "Epoch 11/60\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.1510 - acc: 0.9819\n",
      "Epoch 12/60\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.1368 - acc: 0.9841\n",
      "Epoch 13/60\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.1261 - acc: 0.9855A: \n",
      "Epoch 14/60\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.1072 - acc: 0.9882\n",
      "Epoch 15/60\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.1014 - acc: 0.9896\n",
      "Epoch 16/60\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0972 - acc: 0.9873\n",
      "Epoch 17/60\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0885 - acc: 0.9864\n",
      "Epoch 18/60\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0764 - acc: 0.9891\n",
      "Epoch 19/60\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0726 - acc: 0.9891\n",
      "Epoch 20/60\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0687 - acc: 0.9909\n",
      "Epoch 21/60\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0678 - acc: 0.9859\n",
      "Epoch 22/60\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0652 - acc: 0.9873\n",
      "Epoch 23/60\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0577 - acc: 0.9905\n",
      "Epoch 24/60\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0551 - acc: 0.9909A: 2s - loss: 0.0480 - ETA: 1s - ETA: 0s - loss: 0.0542 - acc: 0.99\n",
      "Epoch 25/60\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0528 - acc: 0.9909\n",
      "Epoch 26/60\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0518 - acc: 0.9896\n",
      "Epoch 27/60\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0492 - acc: 0.9909\n",
      "Epoch 28/60\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0474 - acc: 0.9896\n",
      "Epoch 29/60\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0433 - acc: 0.9918\n",
      "Epoch 30/60\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0447 - acc: 0.9891\n",
      "Epoch 31/60\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0416 - acc: 0.9909\n",
      "Epoch 32/60\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0398 - acc: 0.9882\n",
      "Epoch 33/60\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0366 - acc: 0.9914\n",
      "Epoch 34/60\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0375 - acc: 0.9900\n",
      "Epoch 35/60\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0393 - acc: 0.9905\n",
      "Epoch 36/60\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0361 - acc: 0.9873\n",
      "Epoch 37/60\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0302 - acc: 0.9936\n",
      "Epoch 38/60\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0343 - acc: 0.9909\n",
      "Epoch 39/60\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0343 - acc: 0.9914\n",
      "Epoch 40/60\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0298 - acc: 0.9914\n",
      "Epoch 41/60\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0302 - acc: 0.9923\n",
      "Epoch 42/60\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0318 - acc: 0.9927\n",
      "Epoch 43/60\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0282 - acc: 0.9927\n",
      "Epoch 44/60\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0286 - acc: 0.9914\n",
      "Epoch 45/60\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0335 - acc: 0.9891\n",
      "Epoch 46/60\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0328 - acc: 0.9909\n",
      "Epoch 47/60\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0292 - acc: 0.9882A: 0s - loss: 0.0292 - acc: 0.98\n",
      "Epoch 48/60\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0324 - acc: 0.9882\n",
      "Epoch 49/60\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0279 - acc: 0.9909\n",
      "Epoch 50/60\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0234 - acc: 0.9918\n",
      "Epoch 51/60\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0239 - acc: 0.9923\n",
      "Epoch 52/60\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0279 - acc: 0.9918\n",
      "Epoch 53/60\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0268 - acc: 0.9914\n",
      "Epoch 54/60\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0281 - acc: 0.9909\n",
      "Epoch 55/60\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0271 - acc: 0.9896A: 1s - lo\n",
      "Epoch 56/60\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0234 - acc: 0.9900\n",
      "Epoch 57/60\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0295 - acc: 0.9887\n",
      "Epoch 58/60\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0262 - acc: 0.9896\n",
      "Epoch 59/60\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0241 - acc: 0.9927\n",
      "Epoch 60/60\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0268 - acc: 0.9891\n",
      "2205/2205 [==============================] - 4s 2ms/step\n",
      "2204/2204 [==============================] - 3s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "2205/2205 [==============================] - 16s 7ms/step - loss: 0.6101 - acc: 0.7075\n",
      "Epoch 2/60\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.5409 - acc: 0.7075A: 0s - loss: 0.5453 - \n",
      "Epoch 3/60\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.5015 - acc: 0.7075\n",
      "Epoch 4/60\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.4625 - acc: 0.7075\n",
      "Epoch 5/60\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.4179 - acc: 0.7075\n",
      "Epoch 6/60\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.3781 - acc: 0.7075A: \n",
      "Epoch 7/60\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.3347 - acc: 0.7147\n",
      "Epoch 8/60\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.2954 - acc: 0.7891\n",
      "Epoch 9/60\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.2591 - acc: 0.9515\n",
      "Epoch 10/60\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.2306 - acc: 0.9728\n",
      "Epoch 11/60\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.1994 - acc: 0.9805\n",
      "Epoch 12/60\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.1745 - acc: 0.9864\n",
      "Epoch 13/60\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.1554 - acc: 0.9878\n",
      "Epoch 14/60\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.1382 - acc: 0.9909\n",
      "Epoch 15/60\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.1220 - acc: 0.9905\n",
      "Epoch 16/60\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.1101 - acc: 0.9905\n",
      "Epoch 17/60\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.1006 - acc: 0.9905\n",
      "Epoch 18/60\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0895 - acc: 0.9918A: 1\n",
      "Epoch 19/60\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0820 - acc: 0.9909\n",
      "Epoch 20/60\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0744 - acc: 0.9927\n",
      "Epoch 21/60\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0675 - acc: 0.9927\n",
      "Epoch 22/60\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0656 - acc: 0.9918\n",
      "Epoch 23/60\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0567 - acc: 0.9946\n",
      "Epoch 24/60\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0579 - acc: 0.9918\n",
      "Epoch 25/60\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0515 - acc: 0.9932\n",
      "Epoch 26/60\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0494 - acc: 0.9932A: 0s - loss: 0.0500 -\n",
      "Epoch 27/60\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0471 - acc: 0.9927\n",
      "Epoch 28/60\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0432 - acc: 0.9941\n",
      "Epoch 29/60\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0416 - acc: 0.9937\n",
      "Epoch 30/60\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0385 - acc: 0.9932A: 0s - loss: 0.0386 - acc: \n",
      "Epoch 31/60\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0366 - acc: 0.9941\n",
      "Epoch 32/60\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0380 - acc: 0.9932\n",
      "Epoch 33/60\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0344 - acc: 0.9937\n",
      "Epoch 34/60\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0322 - acc: 0.9937\n",
      "Epoch 35/60\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0333 - acc: 0.9937\n",
      "Epoch 36/60\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0310 - acc: 0.9937\n",
      "Epoch 37/60\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0311 - acc: 0.9927\n",
      "Epoch 38/60\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0315 - acc: 0.9927\n",
      "Epoch 39/60\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0280 - acc: 0.9937\n",
      "Epoch 40/60\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0291 - acc: 0.9927\n",
      "Epoch 41/60\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0307 - acc: 0.9914\n",
      "Epoch 42/60\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0246 - acc: 0.9946\n",
      "Epoch 43/60\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0301 - acc: 0.9923A: 0s - loss: 0.0304 - acc: 0.9\n",
      "Epoch 44/60\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0268 - acc: 0.9932\n",
      "Epoch 45/60\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0259 - acc: 0.9946\n",
      "Epoch 46/60\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0265 - acc: 0.9918 - ETA: 1s - loss: 0\n",
      "Epoch 47/60\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0254 - acc: 0.9923\n",
      "Epoch 48/60\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0317 - acc: 0.9909A: 0s - loss: 0.0\n",
      "Epoch 49/60\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0265 - acc: 0.9932\n",
      "Epoch 50/60\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0276 - acc: 0.9932\n",
      "Epoch 51/60\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0261 - acc: 0.9937\n",
      "Epoch 52/60\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0269 - acc: 0.9918\n",
      "Epoch 53/60\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0240 - acc: 0.9923A: 0s - loss: 0.02\n",
      "Epoch 54/60\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0245 - acc: 0.9946\n",
      "Epoch 55/60\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0241 - acc: 0.9932\n",
      "Epoch 56/60\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0222 - acc: 0.9950\n",
      "Epoch 57/60\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0254 - acc: 0.9941\n",
      "Epoch 58/60\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0262 - acc: 0.9918\n",
      "Epoch 59/60\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0271 - acc: 0.9909\n",
      "Epoch 60/60\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0252 - acc: 0.9937\n",
      "2204/2204 [==============================] - 7s 3ms/step\n",
      "2205/2205 [==============================] - 3s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2204/2204 [==============================] - 27s 12ms/step - loss: 0.6344 - acc: 0.6887\n",
      "Epoch 2/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.5611 - acc: 0.6897\n",
      "Epoch 3/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.5196 - acc: 0.6897\n",
      "Epoch 4/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.4787 - acc: 0.6897\n",
      "Epoch 5/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.4345 - acc: 0.6897\n",
      "Epoch 6/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.3886 - acc: 0.6906\n",
      "Epoch 7/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.3448 - acc: 0.7069\n",
      "Epoch 8/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.3032 - acc: 0.8280\n",
      "Epoch 9/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.2663 - acc: 0.9528\n",
      "Epoch 10/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.2327 - acc: 0.9687\n",
      "Epoch 11/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.2040 - acc: 0.9796\n",
      "Epoch 12/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.1795 - acc: 0.9850\n",
      "Epoch 13/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.1602 - acc: 0.9855\n",
      "Epoch 14/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.1430 - acc: 0.9864\n",
      "Epoch 15/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.1273 - acc: 0.9882\n",
      "Epoch 16/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.1161 - acc: 0.9873\n",
      "Epoch 17/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.1033 - acc: 0.9900\n",
      "Epoch 18/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0957 - acc: 0.9882\n",
      "Epoch 19/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0880 - acc: 0.9891\n",
      "Epoch 20/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0801 - acc: 0.9877\n",
      "Epoch 21/100\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0756 - acc: 0.9877\n",
      "Epoch 22/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0687 - acc: 0.9905\n",
      "Epoch 23/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0664 - acc: 0.9891\n",
      "Epoch 24/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0601 - acc: 0.9909\n",
      "Epoch 25/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0588 - acc: 0.9891\n",
      "Epoch 26/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0515 - acc: 0.9909\n",
      "Epoch 27/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0504 - acc: 0.9909\n",
      "Epoch 28/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0471 - acc: 0.9927\n",
      "Epoch 29/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0452 - acc: 0.9905\n",
      "Epoch 30/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0419 - acc: 0.9918A: 0s - loss: 0.043\n",
      "Epoch 31/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0429 - acc: 0.9877A: \n",
      "Epoch 32/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0430 - acc: 0.9891\n",
      "Epoch 33/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0396 - acc: 0.9905\n",
      "Epoch 34/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0395 - acc: 0.9896\n",
      "Epoch 35/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0379 - acc: 0.9905\n",
      "Epoch 36/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0356 - acc: 0.9905\n",
      "Epoch 37/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0333 - acc: 0.9941\n",
      "Epoch 38/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0314 - acc: 0.9914\n",
      "Epoch 39/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0310 - acc: 0.9927\n",
      "Epoch 40/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0319 - acc: 0.9932\n",
      "Epoch 41/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0317 - acc: 0.9914\n",
      "Epoch 42/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0324 - acc: 0.9896\n",
      "Epoch 43/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0294 - acc: 0.9909A: 1s - loss\n",
      "Epoch 44/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0281 - acc: 0.9914\n",
      "Epoch 45/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0352 - acc: 0.9909\n",
      "Epoch 46/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0304 - acc: 0.9909\n",
      "Epoch 47/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0249 - acc: 0.9932\n",
      "Epoch 48/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0270 - acc: 0.9905\n",
      "Epoch 49/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0295 - acc: 0.9905\n",
      "Epoch 50/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0226 - acc: 0.9936\n",
      "Epoch 51/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0282 - acc: 0.9909\n",
      "Epoch 52/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0281 - acc: 0.9918\n",
      "Epoch 53/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0238 - acc: 0.9927\n",
      "Epoch 54/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0278 - acc: 0.9923\n",
      "Epoch 55/100\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0288 - acc: 0.9896A: 1s - loss: \n",
      "Epoch 56/100\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0247 - acc: 0.9927A: 2s - loss: 0.0242 - a - ETA: 1s - lo\n",
      "Epoch 57/100\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0269 - acc: 0.9923\n",
      "Epoch 58/100\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0271 - acc: 0.9896\n",
      "Epoch 59/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0277 - acc: 0.9914\n",
      "Epoch 60/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0251 - acc: 0.9909\n",
      "Epoch 61/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0271 - acc: 0.9909\n",
      "Epoch 62/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0226 - acc: 0.9923\n",
      "Epoch 63/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0256 - acc: 0.9918A: 1s - loss:\n",
      "Epoch 64/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0229 - acc: 0.9927\n",
      "Epoch 65/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0262 - acc: 0.9909\n",
      "Epoch 66/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0243 - acc: 0.9914\n",
      "Epoch 67/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0276 - acc: 0.9909A: 0s - loss: 0.0278 - acc: 0.990\n",
      "Epoch 68/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0264 - acc: 0.9896\n",
      "Epoch 69/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0288 - acc: 0.9896\n",
      "Epoch 70/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0248 - acc: 0.9905\n",
      "Epoch 71/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0226 - acc: 0.9923\n",
      "Epoch 72/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0228 - acc: 0.9923\n",
      "Epoch 73/100\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0229 - acc: 0.9914\n",
      "Epoch 74/100\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0241 - acc: 0.9923\n",
      "Epoch 75/100\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0262 - acc: 0.9882\n",
      "Epoch 76/100\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0295 - acc: 0.9882\n",
      "Epoch 77/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0263 - acc: 0.9923\n",
      "Epoch 78/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0219 - acc: 0.9909\n",
      "Epoch 79/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0242 - acc: 0.9923\n",
      "Epoch 80/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0280 - acc: 0.9891\n",
      "Epoch 81/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0256 - acc: 0.9914\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0226 - acc: 0.9918\n",
      "Epoch 83/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0230 - acc: 0.9909\n",
      "Epoch 84/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0264 - acc: 0.9896\n",
      "Epoch 85/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0231 - acc: 0.9927\n",
      "Epoch 86/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0280 - acc: 0.9900\n",
      "Epoch 87/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0234 - acc: 0.9923\n",
      "Epoch 88/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0226 - acc: 0.9914\n",
      "Epoch 89/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0224 - acc: 0.9900\n",
      "Epoch 90/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0243 - acc: 0.9900\n",
      "Epoch 91/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0240 - acc: 0.9891\n",
      "Epoch 92/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0250 - acc: 0.9923\n",
      "Epoch 93/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0246 - acc: 0.9909\n",
      "Epoch 94/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0238 - acc: 0.9914\n",
      "Epoch 95/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0264 - acc: 0.9905\n",
      "Epoch 96/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0263 - acc: 0.9891\n",
      "Epoch 97/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0241 - acc: 0.9923\n",
      "Epoch 98/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0234 - acc: 0.9914\n",
      "Epoch 99/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0233 - acc: 0.9905\n",
      "Epoch 100/100\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0242 - acc: 0.9896\n",
      "2205/2205 [==============================] - 5s 2ms/step\n",
      "2204/2204 [==============================] - 3s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2205/2205 [==============================] - 37s 17ms/step - loss: 0.6287 - acc: 0.6980\n",
      "Epoch 2/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.5458 - acc: 0.7075\n",
      "Epoch 3/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.5044 - acc: 0.7075\n",
      "Epoch 4/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.4631 - acc: 0.7075A:\n",
      "Epoch 5/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.4198 - acc: 0.7075\n",
      "Epoch 6/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.3783 - acc: 0.7075\n",
      "Epoch 7/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.3362 - acc: 0.7129\n",
      "Epoch 8/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.2961 - acc: 0.7778\n",
      "Epoch 9/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.2598 - acc: 0.9383\n",
      "Epoch 10/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.2282 - acc: 0.9741\n",
      "Epoch 11/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.2004 - acc: 0.9782\n",
      "Epoch 12/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.1771 - acc: 0.9832\n",
      "Epoch 13/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.1551 - acc: 0.9887\n",
      "Epoch 14/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.1371 - acc: 0.9896\n",
      "Epoch 15/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.1243 - acc: 0.9909\n",
      "Epoch 16/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.1102 - acc: 0.9900\n",
      "Epoch 17/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0981 - acc: 0.9927\n",
      "Epoch 18/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0904 - acc: 0.9932\n",
      "Epoch 19/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0826 - acc: 0.9909\n",
      "Epoch 20/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0752 - acc: 0.9923\n",
      "Epoch 21/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0670 - acc: 0.9932A: 3s - loss: 0.07\n",
      "Epoch 22/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0638 - acc: 0.9923\n",
      "Epoch 23/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0572 - acc: 0.9927\n",
      "Epoch 24/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0556 - acc: 0.9941\n",
      "Epoch 25/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0527 - acc: 0.9923A: 0s - loss: 0.0538 - \n",
      "Epoch 26/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0476 - acc: 0.9927\n",
      "Epoch 27/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0458 - acc: 0.9937\n",
      "Epoch 28/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0415 - acc: 0.9950\n",
      "Epoch 29/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0375 - acc: 0.9950\n",
      "Epoch 30/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0377 - acc: 0.9918\n",
      "Epoch 31/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0340 - acc: 0.9950\n",
      "Epoch 32/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0350 - acc: 0.9927\n",
      "Epoch 33/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0331 - acc: 0.9927\n",
      "Epoch 34/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0344 - acc: 0.9937\n",
      "Epoch 35/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0320 - acc: 0.9946\n",
      "Epoch 36/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0293 - acc: 0.9946\n",
      "Epoch 37/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0283 - acc: 0.9937\n",
      "Epoch 38/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0269 - acc: 0.9937\n",
      "Epoch 39/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0271 - acc: 0.9932\n",
      "Epoch 40/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0258 - acc: 0.9941\n",
      "Epoch 41/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0273 - acc: 0.9932A: 1s - loss: 0\n",
      "Epoch 42/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0263 - acc: 0.9918\n",
      "Epoch 43/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0227 - acc: 0.9946\n",
      "Epoch 44/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0287 - acc: 0.9932\n",
      "Epoch 45/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0218 - acc: 0.9937\n",
      "Epoch 46/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0236 - acc: 0.9959\n",
      "Epoch 47/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0241 - acc: 0.9937\n",
      "Epoch 48/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0266 - acc: 0.9923A: 0s - loss: 0.0278 - acc:\n",
      "Epoch 49/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0190 - acc: 0.9950\n",
      "Epoch 50/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0220 - acc: 0.9946\n",
      "Epoch 51/100\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0200 - acc: 0.9932\n",
      "Epoch 52/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0210 - acc: 0.9932A: 1s - loss: 0.0195 - acc: 0.993 - ETA: 1s - \n",
      "Epoch 53/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0225 - acc: 0.9923\n",
      "Epoch 54/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0227 - acc: 0.9932\n",
      "Epoch 55/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0202 - acc: 0.9937\n",
      "Epoch 56/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0227 - acc: 0.9914\n",
      "Epoch 57/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0241 - acc: 0.9918\n",
      "Epoch 58/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0200 - acc: 0.9946\n",
      "Epoch 59/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0228 - acc: 0.9932\n",
      "Epoch 60/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0191 - acc: 0.9941A: 1s - \n",
      "Epoch 61/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0201 - acc: 0.9932\n",
      "Epoch 62/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0178 - acc: 0.9950A: 0s - loss: 0.0191 \n",
      "Epoch 63/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0212 - acc: 0.9927\n",
      "Epoch 64/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0191 - acc: 0.9937\n",
      "Epoch 65/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0187 - acc: 0.9946\n",
      "Epoch 66/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0200 - acc: 0.9932\n",
      "Epoch 67/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0160 - acc: 0.9955\n",
      "Epoch 68/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0191 - acc: 0.9937\n",
      "Epoch 69/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0232 - acc: 0.9918\n",
      "Epoch 70/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0196 - acc: 0.9927\n",
      "Epoch 71/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0176 - acc: 0.9932\n",
      "Epoch 72/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0152 - acc: 0.9959A: 1s -\n",
      "Epoch 73/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0225 - acc: 0.9914A: 0s - loss: 0.0231 - acc: 0.\n",
      "Epoch 74/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0174 - acc: 0.9927\n",
      "Epoch 75/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0155 - acc: 0.9950\n",
      "Epoch 76/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0224 - acc: 0.9918\n",
      "Epoch 77/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0160 - acc: 0.9946\n",
      "Epoch 78/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0195 - acc: 0.9927\n",
      "Epoch 79/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0157 - acc: 0.9946\n",
      "Epoch 80/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0198 - acc: 0.9932\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0168 - acc: 0.9941\n",
      "Epoch 82/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0192 - acc: 0.9937\n",
      "Epoch 83/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0175 - acc: 0.9932\n",
      "Epoch 84/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0206 - acc: 0.9927\n",
      "Epoch 85/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0222 - acc: 0.9927\n",
      "Epoch 86/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0155 - acc: 0.9950\n",
      "Epoch 87/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0233 - acc: 0.9923\n",
      "Epoch 88/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0127 - acc: 0.9977\n",
      "Epoch 89/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0154 - acc: 0.9950\n",
      "Epoch 90/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0236 - acc: 0.9918\n",
      "Epoch 91/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0170 - acc: 0.9950A: 1s\n",
      "Epoch 92/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0138 - acc: 0.9959\n",
      "Epoch 93/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0181 - acc: 0.9941\n",
      "Epoch 94/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0150 - acc: 0.9941A: 0s - loss: 0.0134 - acc\n",
      "Epoch 95/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0136 - acc: 0.9955\n",
      "Epoch 96/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0206 - acc: 0.9918\n",
      "Epoch 97/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0170 - acc: 0.9941\n",
      "Epoch 98/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0192 - acc: 0.9918A: 1s - loss: 0.\n",
      "Epoch 99/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0157 - acc: 0.9955\n",
      "Epoch 100/100\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0165 - acc: 0.9946\n",
      "2204/2204 [==============================] - 4s 2ms/step\n",
      "2205/2205 [==============================] - 3s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2204/2204 [==============================] - 19s 8ms/step - loss: 0.6536 - acc: 0.6897\n",
      "Epoch 2/20\n",
      " 100/2204 [>.............................] - ETA: 15s - loss: 0.6508 - acc: 0.6200"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.187262). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2204/2204 [==============================] - 5s 2ms/step - loss: 0.5901 - acc: 0.6897A: 2s - los\n",
      "Epoch 3/20\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.5563 - acc: 0.6897\n",
      "Epoch 4/20\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.5295 - acc: 0.6897\n",
      "Epoch 5/20\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.5036 - acc: 0.6897\n",
      "Epoch 6/20\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.4798 - acc: 0.6897\n",
      "Epoch 7/20\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.4525 - acc: 0.6897\n",
      "Epoch 8/20\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.4275 - acc: 0.6897\n",
      "Epoch 9/20\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.4014 - acc: 0.6897\n",
      "Epoch 10/20\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.3730 - acc: 0.6901\n",
      "Epoch 11/20\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.3482 - acc: 0.6965\n",
      "Epoch 12/20\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.3232 - acc: 0.7214\n",
      "Epoch 13/20\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.3000 - acc: 0.8190\n",
      "Epoch 14/20\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.2776 - acc: 0.9433\n",
      "Epoch 15/20\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.2559 - acc: 0.9642\n",
      "Epoch 16/20\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.2372 - acc: 0.9701\n",
      "Epoch 17/20\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.2214 - acc: 0.9796\n",
      "Epoch 18/20\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.2033 - acc: 0.9832\n",
      "Epoch 19/20\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.1877 - acc: 0.9841\n",
      "Epoch 20/20\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.1751 - acc: 0.9855\n",
      "2205/2205 [==============================] - 6s 3ms/step\n",
      "2204/2204 [==============================] - 3s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2205/2205 [==============================] - 21s 9ms/step - loss: 0.6529 - acc: 0.6812\n",
      "Epoch 2/20\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.5763 - acc: 0.7075\n",
      "Epoch 3/20\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.5405 - acc: 0.7075\n",
      "Epoch 4/20\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.5109 - acc: 0.7075\n",
      "Epoch 5/20\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.4895 - acc: 0.7075\n",
      "Epoch 6/20\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.4650 - acc: 0.7075\n",
      "Epoch 7/20\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.4404 - acc: 0.7075\n",
      "Epoch 8/20\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.4145 - acc: 0.7075\n",
      "Epoch 9/20\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.3861 - acc: 0.7075\n",
      "Epoch 10/20\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.3616 - acc: 0.7075\n",
      "Epoch 11/20\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.3362 - acc: 0.7098\n",
      "Epoch 12/20\n",
      "2205/2205 [==============================] - 5s 2ms/step - loss: 0.3136 - acc: 0.7252\n",
      "Epoch 13/20\n",
      "2205/2205 [==============================] - 5s 2ms/step - loss: 0.2887 - acc: 0.7873\n",
      "Epoch 14/20\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.2668 - acc: 0.8943\n",
      "Epoch 15/20\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.2473 - acc: 0.9637\n",
      "Epoch 16/20\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.2304 - acc: 0.9760\n",
      "Epoch 17/20\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.2132 - acc: 0.9791\n",
      "Epoch 18/20\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.1978 - acc: 0.9823\n",
      "Epoch 19/20\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.1831 - acc: 0.9855\n",
      "Epoch 20/20\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.1700 - acc: 0.9882\n",
      "2204/2204 [==============================] - 5s 2ms/step\n",
      "2205/2205 [==============================] - 3s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "2204/2204 [==============================] - 20s 9ms/step - loss: 0.6665 - acc: 0.6338\n",
      "Epoch 2/40\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.5991 - acc: 0.6897\n",
      "Epoch 3/40\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.5584 - acc: 0.6897\n",
      "Epoch 4/40\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.5327 - acc: 0.6897\n",
      "Epoch 5/40\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.5089 - acc: 0.6897\n",
      "Epoch 6/40\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.4848 - acc: 0.6897\n",
      "Epoch 7/40\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.4565 - acc: 0.6897\n",
      "Epoch 8/40\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.4313 - acc: 0.6897\n",
      "Epoch 9/40\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.4058 - acc: 0.6897\n",
      "Epoch 10/40\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.3770 - acc: 0.6910\n",
      "Epoch 11/40\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.3504 - acc: 0.7015\n",
      "Epoch 12/40\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.3253 - acc: 0.7201\n",
      "Epoch 13/40\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.3036 - acc: 0.8026\n",
      "Epoch 14/40\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.2794 - acc: 0.9170\n",
      "Epoch 15/40\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.2569 - acc: 0.9614\n",
      "Epoch 16/40\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.2413 - acc: 0.9723\n",
      "Epoch 17/40\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.2228 - acc: 0.9773\n",
      "Epoch 18/40\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.2060 - acc: 0.9841\n",
      "Epoch 19/40\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.1927 - acc: 0.9850\n",
      "Epoch 20/40\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.1784 - acc: 0.9841\n",
      "Epoch 21/40\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.1663 - acc: 0.9859\n",
      "Epoch 22/40\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.1560 - acc: 0.9864\n",
      "Epoch 23/40\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.1442 - acc: 0.9877\n",
      "Epoch 24/40\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.1370 - acc: 0.9891\n",
      "Epoch 25/40\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.1313 - acc: 0.9887\n",
      "Epoch 26/40\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.1208 - acc: 0.9864\n",
      "Epoch 27/40\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.1128 - acc: 0.9896\n",
      "Epoch 28/40\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.1070 - acc: 0.9882\n",
      "Epoch 29/40\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.1023 - acc: 0.9877\n",
      "Epoch 30/40\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0952 - acc: 0.9909\n",
      "Epoch 31/40\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0922 - acc: 0.9896\n",
      "Epoch 32/40\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0871 - acc: 0.9914\n",
      "Epoch 33/40\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0825 - acc: 0.9918\n",
      "Epoch 34/40\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0780 - acc: 0.9909\n",
      "Epoch 35/40\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0734 - acc: 0.9900\n",
      "Epoch 36/40\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0721 - acc: 0.9896\n",
      "Epoch 37/40\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0715 - acc: 0.9896\n",
      "Epoch 38/40\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0655 - acc: 0.9909\n",
      "Epoch 39/40\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0637 - acc: 0.9909\n",
      "Epoch 40/40\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0607 - acc: 0.9914\n",
      "2205/2205 [==============================] - 10s 4ms/step\n",
      "2204/2204 [==============================] - 6s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "2205/2205 [==============================] - 34s 15ms/step - loss: 0.6584 - acc: 0.6653\n",
      "Epoch 2/40\n",
      "2205/2205 [==============================] - 5s 2ms/step - loss: 0.5837 - acc: 0.7075\n",
      "Epoch 3/40\n",
      "2205/2205 [==============================] - 5s 2ms/step - loss: 0.5386 - acc: 0.7075\n",
      "Epoch 4/40\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.5151 - acc: 0.7075\n",
      "Epoch 5/40\n",
      "2205/2205 [==============================] - 5s 2ms/step - loss: 0.4909 - acc: 0.7075\n",
      "Epoch 6/40\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.4640 - acc: 0.7075\n",
      "Epoch 7/40\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.4389 - acc: 0.7075\n",
      "Epoch 8/40\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.4115 - acc: 0.7075\n",
      "Epoch 9/40\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.3872 - acc: 0.7075\n",
      "Epoch 10/40\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.3611 - acc: 0.7075\n",
      "Epoch 11/40\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.3356 - acc: 0.7120\n",
      "Epoch 12/40\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.3126 - acc: 0.7315\n",
      "Epoch 13/40\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.2885 - acc: 0.7782\n",
      "Epoch 14/40\n",
      "2205/2205 [==============================] - 5s 2ms/step - loss: 0.2657 - acc: 0.9029\n",
      "Epoch 15/40\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.2488 - acc: 0.9660\n",
      "Epoch 16/40\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.2297 - acc: 0.9755\n",
      "Epoch 17/40\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.2130 - acc: 0.9791\n",
      "Epoch 18/40\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.1977 - acc: 0.9810\n",
      "Epoch 19/40\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.1825 - acc: 0.9864\n",
      "Epoch 20/40\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.1709 - acc: 0.9873\n",
      "Epoch 21/40\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.1580 - acc: 0.9891\n",
      "Epoch 22/40\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.1477 - acc: 0.9905\n",
      "Epoch 23/40\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.1368 - acc: 0.9914\n",
      "Epoch 24/40\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.1292 - acc: 0.9900\n",
      "Epoch 25/40\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.1202 - acc: 0.9900\n",
      "Epoch 26/40\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.1121 - acc: 0.9914\n",
      "Epoch 27/40\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.1085 - acc: 0.9918\n",
      "Epoch 28/40\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.0998 - acc: 0.992 - 4s 2ms/step - loss: 0.0999 - acc: 0.9927\n",
      "Epoch 29/40\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0923 - acc: 0.9937\n",
      "Epoch 30/40\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0878 - acc: 0.9923\n",
      "Epoch 31/40\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0857 - acc: 0.9941\n",
      "Epoch 32/40\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0792 - acc: 0.9937\n",
      "Epoch 33/40\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0738 - acc: 0.9946\n",
      "Epoch 34/40\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0708 - acc: 0.9950\n",
      "Epoch 35/40\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.0688 - acc: 0.993 - 4s 2ms/step - loss: 0.0688 - acc: 0.9937\n",
      "Epoch 36/40\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0651 - acc: 0.9932\n",
      "Epoch 37/40\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0623 - acc: 0.9932\n",
      "Epoch 38/40\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0589 - acc: 0.9923\n",
      "Epoch 39/40\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0575 - acc: 0.9946\n",
      "Epoch 40/40\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0560 - acc: 0.9941\n",
      "2204/2204 [==============================] - 6s 3ms/step\n",
      "2205/2205 [==============================] - 2s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "2204/2204 [==============================] - 21s 10ms/step - loss: 0.6566 - acc: 0.6688\n",
      "Epoch 2/60\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.5930 - acc: 0.6897\n",
      "Epoch 3/60\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.5562 - acc: 0.6897\n",
      "Epoch 4/60\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.5302 - acc: 0.6897\n",
      "Epoch 5/60\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.5077 - acc: 0.6897\n",
      "Epoch 6/60\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.4787 - acc: 0.6897\n",
      "Epoch 7/60\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.4531 - acc: 0.6897\n",
      "Epoch 8/60\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.4279 - acc: 0.6897\n",
      "Epoch 9/60\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.3999 - acc: 0.6901\n",
      "Epoch 10/60\n",
      "2204/2204 [==============================] - 5s 2ms/step - loss: 0.3749 - acc: 0.6910\n",
      "Epoch 11/60\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.3454 - acc: 0.6983\n",
      "Epoch 12/60\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.3212 - acc: 0.7323\n",
      "Epoch 13/60\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.2971 - acc: 0.8312\n",
      "Epoch 14/60\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.2754 - acc: 0.9387\n",
      "Epoch 15/60\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.2560 - acc: 0.9637\n",
      "Epoch 16/60\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.2372 - acc: 0.9719\n",
      "Epoch 17/60\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.2216 - acc: 0.9755\n",
      "Epoch 18/60\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.2034 - acc: 0.9823\n",
      "Epoch 19/60\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.1887 - acc: 0.9846\n",
      "Epoch 20/60\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.1743 - acc: 0.9855\n",
      "Epoch 21/60\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.1636 - acc: 0.9864\n",
      "Epoch 22/60\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.1538 - acc: 0.9868\n",
      "Epoch 23/60\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.1433 - acc: 0.9882\n",
      "Epoch 24/60\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.1339 - acc: 0.9864\n",
      "Epoch 25/60\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.1269 - acc: 0.9873\n",
      "Epoch 26/60\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.1189 - acc: 0.9896\n",
      "Epoch 27/60\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.1131 - acc: 0.9882\n",
      "Epoch 28/60\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.1073 - acc: 0.9882\n",
      "Epoch 29/60\n",
      "2204/2204 [==============================] - 5s 2ms/step - loss: 0.1026 - acc: 0.9905\n",
      "Epoch 30/60\n",
      "2204/2204 [==============================] - 5s 2ms/step - loss: 0.0950 - acc: 0.9905\n",
      "Epoch 31/60\n",
      "2204/2204 [==============================] - 5s 2ms/step - loss: 0.0923 - acc: 0.9887\n",
      "Epoch 32/60\n",
      "2204/2204 [==============================] - 5s 2ms/step - loss: 0.0863 - acc: 0.9905\n",
      "Epoch 33/60\n",
      "2204/2204 [==============================] - 5s 2ms/step - loss: 0.0830 - acc: 0.9909\n",
      "Epoch 34/60\n",
      "2204/2204 [==============================] - 5s 2ms/step - loss: 0.0784 - acc: 0.9900\n",
      "Epoch 35/60\n",
      "2204/2204 [==============================] - 5s 2ms/step - loss: 0.0756 - acc: 0.9905\n",
      "Epoch 36/60\n",
      "2204/2204 [==============================] - 5s 2ms/step - loss: 0.0738 - acc: 0.9905\n",
      "Epoch 37/60\n",
      "2204/2204 [==============================] - 5s 2ms/step - loss: 0.0670 - acc: 0.9923\n",
      "Epoch 38/60\n",
      "2204/2204 [==============================] - 5s 2ms/step - loss: 0.0636 - acc: 0.9918A: 3s - loss: 0.0705 - ETA: 2s\n",
      "Epoch 39/60\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0656 - acc: 0.9891\n",
      "Epoch 40/60\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0624 - acc: 0.9905\n",
      "Epoch 41/60\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0577 - acc: 0.9923\n",
      "Epoch 42/60\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0562 - acc: 0.9900\n",
      "Epoch 43/60\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0596 - acc: 0.9891\n",
      "Epoch 44/60\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0531 - acc: 0.9891\n",
      "Epoch 45/60\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0516 - acc: 0.9914\n",
      "Epoch 46/60\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0496 - acc: 0.9896\n",
      "Epoch 47/60\n",
      "2204/2204 [==============================] - 5s 2ms/step - loss: 0.0462 - acc: 0.9923\n",
      "Epoch 48/60\n",
      "2204/2204 [==============================] - 5s 2ms/step - loss: 0.0475 - acc: 0.9905\n",
      "Epoch 49/60\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0439 - acc: 0.9909\n",
      "Epoch 50/60\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0479 - acc: 0.9891\n",
      "Epoch 51/60\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0437 - acc: 0.9918\n",
      "Epoch 52/60\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0432 - acc: 0.9905\n",
      "Epoch 53/60\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0415 - acc: 0.9923\n",
      "Epoch 54/60\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0398 - acc: 0.9909\n",
      "Epoch 55/60\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0402 - acc: 0.9936\n",
      "Epoch 56/60\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0434 - acc: 0.9891\n",
      "Epoch 57/60\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0414 - acc: 0.9896\n",
      "Epoch 58/60\n",
      "2204/2204 [==============================] - 5s 2ms/step - loss: 0.0393 - acc: 0.9896\n",
      "Epoch 59/60\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0373 - acc: 0.9914\n",
      "Epoch 60/60\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0362 - acc: 0.9923\n",
      "2205/2205 [==============================] - 7s 3ms/step\n",
      "2204/2204 [==============================] - 5s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "2205/2205 [==============================] - 19s 9ms/step - loss: 0.6643 - acc: 0.6490\n",
      "Epoch 2/60\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.5889 - acc: 0.7075\n",
      "Epoch 3/60\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.5439 - acc: 0.7075\n",
      "Epoch 4/60\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.5176 - acc: 0.7075\n",
      "Epoch 5/60\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.4927 - acc: 0.7075\n",
      "Epoch 6/60\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.4708 - acc: 0.7075\n",
      "Epoch 7/60\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.4461 - acc: 0.706 - 4s 2ms/step - loss: 0.4455 - acc: 0.7075\n",
      "Epoch 8/60\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.4192 - acc: 0.7075\n",
      "Epoch 9/60\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.3938 - acc: 0.7075A: 1s - loss: 0\n",
      "Epoch 10/60\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.3668 - acc: 0.7075\n",
      "Epoch 11/60\n",
      "2205/2205 [==============================] - 5s 2ms/step - loss: 0.3447 - acc: 0.7084\n",
      "Epoch 12/60\n",
      "2205/2205 [==============================] - 5s 2ms/step - loss: 0.3178 - acc: 0.7143\n",
      "Epoch 13/60\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.2966 - acc: 0.7465\n",
      "Epoch 14/60\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.2746 - acc: 0.8463\n",
      "Epoch 15/60\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.2566 - acc: 0.9605\n",
      "Epoch 16/60\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.2361 - acc: 0.9732\n",
      "Epoch 17/60\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.2199 - acc: 0.9778\n",
      "Epoch 18/60\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.2044 - acc: 0.9805A: 0s - loss: 0.2062 - \n",
      "Epoch 19/60\n",
      "2205/2205 [==============================] - 5s 2ms/step - loss: 0.1870 - acc: 0.9868\n",
      "Epoch 20/60\n",
      "2205/2205 [==============================] - 5s 2ms/step - loss: 0.1732 - acc: 0.9868A: 0s - loss: 0.1760 - a\n",
      "Epoch 21/60\n",
      "2205/2205 [==============================] - 5s 2ms/step - loss: 0.1620 - acc: 0.9896\n",
      "Epoch 22/60\n",
      "2205/2205 [==============================] - 5s 2ms/step - loss: 0.1514 - acc: 0.9905\n",
      "Epoch 23/60\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.1431 - acc: 0.9909\n",
      "Epoch 24/60\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.1335 - acc: 0.9909\n",
      "Epoch 25/60\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.1244 - acc: 0.9918\n",
      "Epoch 26/60\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.1156 - acc: 0.9909\n",
      "Epoch 27/60\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.1081 - acc: 0.9932\n",
      "Epoch 28/60\n",
      "2205/2205 [==============================] - 5s 2ms/step - loss: 0.1018 - acc: 0.9927\n",
      "Epoch 29/60\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0962 - acc: 0.9932\n",
      "Epoch 30/60\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0903 - acc: 0.9923\n",
      "Epoch 31/60\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0863 - acc: 0.9923\n",
      "Epoch 32/60\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0827 - acc: 0.9941\n",
      "Epoch 33/60\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0772 - acc: 0.9932\n",
      "Epoch 34/60\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0764 - acc: 0.9923\n",
      "Epoch 35/60\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0696 - acc: 0.9937\n",
      "Epoch 36/60\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0672 - acc: 0.9946\n",
      "Epoch 37/60\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0642 - acc: 0.9941\n",
      "Epoch 38/60\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0609 - acc: 0.9950\n",
      "Epoch 39/60\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0578 - acc: 0.9932\n",
      "Epoch 40/60\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0556 - acc: 0.9941\n",
      "Epoch 41/60\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0554 - acc: 0.9941\n",
      "Epoch 42/60\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0519 - acc: 0.9941\n",
      "Epoch 43/60\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0514 - acc: 0.9941\n",
      "Epoch 44/60\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0503 - acc: 0.9937\n",
      "Epoch 45/60\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0483 - acc: 0.9941\n",
      "Epoch 46/60\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0450 - acc: 0.9941\n",
      "Epoch 47/60\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0430 - acc: 0.9941\n",
      "Epoch 48/60\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0431 - acc: 0.9955\n",
      "Epoch 49/60\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0409 - acc: 0.9950\n",
      "Epoch 50/60\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0412 - acc: 0.9932\n",
      "Epoch 51/60\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0357 - acc: 0.9950\n",
      "Epoch 52/60\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0392 - acc: 0.9937\n",
      "Epoch 53/60\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0380 - acc: 0.9937\n",
      "Epoch 54/60\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0363 - acc: 0.9941\n",
      "Epoch 55/60\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0354 - acc: 0.9937\n",
      "Epoch 56/60\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0340 - acc: 0.9941\n",
      "Epoch 57/60\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0350 - acc: 0.9932\n",
      "Epoch 58/60\n",
      "2205/2205 [==============================] - 5s 2ms/step - loss: 0.0329 - acc: 0.9941\n",
      "Epoch 59/60\n",
      "2205/2205 [==============================] - 5s 2ms/step - loss: 0.0328 - acc: 0.9932\n",
      "Epoch 60/60\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0309 - acc: 0.9946\n",
      "2204/2204 [==============================] - 6s 3ms/step\n",
      "2205/2205 [==============================] - 3s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2204/2204 [==============================] - 31s 14ms/step - loss: 0.6538 - acc: 0.6878\n",
      "Epoch 2/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.5915 - acc: 0.6897\n",
      "Epoch 3/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.5550 - acc: 0.6897\n",
      "Epoch 4/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.5314 - acc: 0.6897\n",
      "Epoch 5/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.5055 - acc: 0.6897\n",
      "Epoch 6/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.4794 - acc: 0.6897\n",
      "Epoch 7/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.4528 - acc: 0.6897A: 1s - loss:\n",
      "Epoch 8/100\n",
      "2204/2204 [==============================] - 5s 2ms/step - loss: 0.4235 - acc: 0.6897\n",
      "Epoch 9/100\n",
      "2204/2204 [==============================] - 5s 2ms/step - loss: 0.3966 - acc: 0.6897\n",
      "Epoch 10/100\n",
      "2204/2204 [==============================] - 5s 2ms/step - loss: 0.3702 - acc: 0.6906\n",
      "Epoch 11/100\n",
      "2204/2204 [==============================] - 5s 2ms/step - loss: 0.3456 - acc: 0.7015\n",
      "Epoch 12/100\n",
      "2204/2204 [==============================] - 5s 2ms/step - loss: 0.3178 - acc: 0.7400\n",
      "Epoch 13/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.2935 - acc: 0.8403\n",
      "Epoch 14/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.2732 - acc: 0.9537\n",
      "Epoch 15/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.2526 - acc: 0.9669\n",
      "Epoch 16/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.2329 - acc: 0.9719\n",
      "Epoch 17/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.2158 - acc: 0.9782\n",
      "Epoch 18/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.1991 - acc: 0.9837\n",
      "Epoch 19/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.1866 - acc: 0.9837\n",
      "Epoch 20/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.1719 - acc: 0.9859\n",
      "Epoch 21/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.1612 - acc: 0.9855\n",
      "Epoch 22/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.1502 - acc: 0.9873\n",
      "Epoch 23/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.1411 - acc: 0.9877\n",
      "Epoch 24/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.1315 - acc: 0.9873\n",
      "Epoch 25/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.1236 - acc: 0.9891\n",
      "Epoch 26/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.1161 - acc: 0.9882\n",
      "Epoch 27/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.1105 - acc: 0.9891\n",
      "Epoch 28/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.1025 - acc: 0.9900\n",
      "Epoch 29/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0988 - acc: 0.9882\n",
      "Epoch 30/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0922 - acc: 0.9896\n",
      "Epoch 31/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0876 - acc: 0.9905\n",
      "Epoch 32/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0834 - acc: 0.9909\n",
      "Epoch 33/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0787 - acc: 0.9914\n",
      "Epoch 34/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0747 - acc: 0.9914\n",
      "Epoch 35/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0709 - acc: 0.9914\n",
      "Epoch 36/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0685 - acc: 0.9918\n",
      "Epoch 37/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0657 - acc: 0.9905\n",
      "Epoch 38/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0639 - acc: 0.9909\n",
      "Epoch 39/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0613 - acc: 0.9918\n",
      "Epoch 40/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0594 - acc: 0.9918\n",
      "Epoch 41/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0546 - acc: 0.9927\n",
      "Epoch 42/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0560 - acc: 0.9905\n",
      "Epoch 43/100\n",
      "2204/2204 [==============================] - ETA: 0s - loss: 0.0565 - acc: 0.992 - 4s 2ms/step - loss: 0.0566 - acc: 0.9923\n",
      "Epoch 44/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0499 - acc: 0.9936\n",
      "Epoch 45/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0516 - acc: 0.9905\n",
      "Epoch 46/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0489 - acc: 0.9927\n",
      "Epoch 47/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0457 - acc: 0.9927\n",
      "Epoch 48/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0484 - acc: 0.9914\n",
      "Epoch 49/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0449 - acc: 0.9914\n",
      "Epoch 50/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0417 - acc: 0.9923\n",
      "Epoch 51/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0409 - acc: 0.9927\n",
      "Epoch 52/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0382 - acc: 0.9923\n",
      "Epoch 53/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0401 - acc: 0.9923\n",
      "Epoch 54/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0406 - acc: 0.9914\n",
      "Epoch 55/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0360 - acc: 0.9936\n",
      "Epoch 56/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0367 - acc: 0.9927\n",
      "Epoch 57/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0383 - acc: 0.9905\n",
      "Epoch 58/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0331 - acc: 0.9936\n",
      "Epoch 59/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0361 - acc: 0.9914\n",
      "Epoch 60/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0329 - acc: 0.9927\n",
      "Epoch 61/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0344 - acc: 0.9914\n",
      "Epoch 62/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0309 - acc: 0.9932\n",
      "Epoch 63/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0333 - acc: 0.9932\n",
      "Epoch 64/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0332 - acc: 0.9923\n",
      "Epoch 65/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0327 - acc: 0.9905\n",
      "Epoch 66/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0327 - acc: 0.9918\n",
      "Epoch 67/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0317 - acc: 0.9909\n",
      "Epoch 68/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0306 - acc: 0.9941\n",
      "Epoch 69/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0297 - acc: 0.9923\n",
      "Epoch 70/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0295 - acc: 0.9927\n",
      "Epoch 71/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0337 - acc: 0.9909\n",
      "Epoch 72/100\n",
      "2204/2204 [==============================] - 5s 2ms/step - loss: 0.0274 - acc: 0.9927\n",
      "Epoch 73/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0282 - acc: 0.9914\n",
      "Epoch 74/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0319 - acc: 0.9905\n",
      "Epoch 75/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0291 - acc: 0.9914\n",
      "Epoch 76/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0265 - acc: 0.9923\n",
      "Epoch 77/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0267 - acc: 0.9909\n",
      "Epoch 78/100\n",
      "2204/2204 [==============================] - 5s 2ms/step - loss: 0.0338 - acc: 0.9891\n",
      "Epoch 79/100\n",
      "2204/2204 [==============================] - 5s 2ms/step - loss: 0.0305 - acc: 0.9918\n",
      "Epoch 80/100\n",
      "2204/2204 [==============================] - 5s 2ms/step - loss: 0.0276 - acc: 0.9923\n",
      "Epoch 81/100\n",
      "2204/2204 [==============================] - 5s 2ms/step - loss: 0.0264 - acc: 0.9927\n",
      "Epoch 82/100\n",
      "2204/2204 [==============================] - 5s 2ms/step - loss: 0.0263 - acc: 0.9914\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2204/2204 [==============================] - 5s 2ms/step - loss: 0.0243 - acc: 0.9927\n",
      "Epoch 84/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0257 - acc: 0.9909\n",
      "Epoch 85/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0273 - acc: 0.9927\n",
      "Epoch 86/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0274 - acc: 0.9914\n",
      "Epoch 87/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0261 - acc: 0.9914\n",
      "Epoch 88/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0259 - acc: 0.9927\n",
      "Epoch 89/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0238 - acc: 0.9918\n",
      "Epoch 90/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0262 - acc: 0.9923\n",
      "Epoch 91/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0272 - acc: 0.9932\n",
      "Epoch 92/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0249 - acc: 0.9914\n",
      "Epoch 93/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0229 - acc: 0.9932\n",
      "Epoch 94/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0253 - acc: 0.9936\n",
      "Epoch 95/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0274 - acc: 0.9905\n",
      "Epoch 96/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0300 - acc: 0.9900\n",
      "Epoch 97/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0265 - acc: 0.9927\n",
      "Epoch 98/100\n",
      "2204/2204 [==============================] - 5s 2ms/step - loss: 0.0226 - acc: 0.9914\n",
      "Epoch 99/100\n",
      "2204/2204 [==============================] - 5s 2ms/step - loss: 0.0240 - acc: 0.9909A: 2s - loss: 0.0215 - acc: 0.991 - E\n",
      "Epoch 100/100\n",
      "2204/2204 [==============================] - 5s 2ms/step - loss: 0.0296 - acc: 0.9900\n",
      "2205/2205 [==============================] - 8s 4ms/step\n",
      "2204/2204 [==============================] - 3s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2205/2205 [==============================] - 17s 8ms/step - loss: 0.6653 - acc: 0.6385\n",
      "Epoch 2/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.5924 - acc: 0.7075\n",
      "Epoch 3/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.5369 - acc: 0.7075\n",
      "Epoch 4/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.4934 - acc: 0.7075\n",
      "Epoch 5/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.4523 - acc: 0.7075\n",
      "Epoch 6/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.4113 - acc: 0.7075\n",
      "Epoch 7/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.3736 - acc: 0.7075\n",
      "Epoch 8/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.3420 - acc: 0.7079\n",
      "Epoch 9/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.3079 - acc: 0.7215\n",
      "Epoch 10/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.2832 - acc: 0.8621\n",
      "Epoch 11/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.2596 - acc: 0.9361\n",
      "Epoch 12/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.2380 - acc: 0.9474\n",
      "Epoch 13/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.2165 - acc: 0.9542\n",
      "Epoch 14/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.2037 - acc: 0.9510\n",
      "Epoch 15/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.1846 - acc: 0.9637\n",
      "Epoch 16/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.1727 - acc: 0.9660\n",
      "Epoch 17/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.1580 - acc: 0.9782\n",
      "Epoch 18/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.1491 - acc: 0.9773\n",
      "Epoch 19/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.1408 - acc: 0.9864\n",
      "Epoch 20/100\n",
      "2205/2205 [==============================] - 5s 2ms/step - loss: 0.1314 - acc: 0.9873\n",
      "Epoch 21/100\n",
      "2205/2205 [==============================] - 5s 2ms/step - loss: 0.1220 - acc: 0.9891\n",
      "Epoch 22/100\n",
      "2205/2205 [==============================] - 5s 2ms/step - loss: 0.1139 - acc: 0.9909\n",
      "Epoch 23/100\n",
      "2205/2205 [==============================] - 5s 2ms/step - loss: 0.1077 - acc: 0.9909\n",
      "Epoch 24/100\n",
      "2205/2205 [==============================] - 5s 2ms/step - loss: 0.1011 - acc: 0.9923\n",
      "Epoch 25/100\n",
      "2205/2205 [==============================] - 5s 2ms/step - loss: 0.1002 - acc: 0.9900\n",
      "Epoch 26/100\n",
      "2205/2205 [==============================] - 5s 2ms/step - loss: 0.0911 - acc: 0.9909\n",
      "Epoch 27/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0894 - acc: 0.9918\n",
      "Epoch 28/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0824 - acc: 0.9923\n",
      "Epoch 29/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0812 - acc: 0.9918\n",
      "Epoch 30/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0735 - acc: 0.9937A: 1s - \n",
      "Epoch 31/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0713 - acc: 0.9923\n",
      "Epoch 32/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0662 - acc: 0.9950\n",
      "Epoch 33/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0668 - acc: 0.9932\n",
      "Epoch 34/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0642 - acc: 0.9937\n",
      "Epoch 35/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0622 - acc: 0.9923\n",
      "Epoch 36/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0578 - acc: 0.9927\n",
      "Epoch 37/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0576 - acc: 0.9918\n",
      "Epoch 38/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0535 - acc: 0.9937\n",
      "Epoch 39/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0521 - acc: 0.9937\n",
      "Epoch 40/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0491 - acc: 0.9959\n",
      "Epoch 41/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0482 - acc: 0.9937\n",
      "Epoch 42/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0479 - acc: 0.9923\n",
      "Epoch 43/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0474 - acc: 0.9932\n",
      "Epoch 44/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0481 - acc: 0.9909\n",
      "Epoch 45/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0433 - acc: 0.9932\n",
      "Epoch 46/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0422 - acc: 0.9946\n",
      "Epoch 47/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0417 - acc: 0.9923\n",
      "Epoch 48/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0421 - acc: 0.9927\n",
      "Epoch 49/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0411 - acc: 0.9937\n",
      "Epoch 50/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0364 - acc: 0.9941\n",
      "Epoch 51/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0382 - acc: 0.9932\n",
      "Epoch 52/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0350 - acc: 0.9946\n",
      "Epoch 53/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0396 - acc: 0.9914\n",
      "Epoch 54/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0330 - acc: 0.9918\n",
      "Epoch 55/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0337 - acc: 0.9927\n",
      "Epoch 56/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0338 - acc: 0.9941\n",
      "Epoch 57/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0348 - acc: 0.9937A: 1s - loss\n",
      "Epoch 58/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0295 - acc: 0.9941\n",
      "Epoch 59/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0339 - acc: 0.9914\n",
      "Epoch 60/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0335 - acc: 0.9923A: \n",
      "Epoch 61/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0312 - acc: 0.9937\n",
      "Epoch 62/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0310 - acc: 0.9923\n",
      "Epoch 63/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0318 - acc: 0.9937\n",
      "Epoch 64/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0269 - acc: 0.9941\n",
      "Epoch 65/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0279 - acc: 0.9927\n",
      "Epoch 66/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0269 - acc: 0.9927\n",
      "Epoch 67/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0292 - acc: 0.9932\n",
      "Epoch 68/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0293 - acc: 0.9927\n",
      "Epoch 69/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0281 - acc: 0.9932\n",
      "Epoch 70/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0267 - acc: 0.9941\n",
      "Epoch 71/100\n",
      "2205/2205 [==============================] - 5s 2ms/step - loss: 0.0298 - acc: 0.9927\n",
      "Epoch 72/100\n",
      "2205/2205 [==============================] - 5s 2ms/step - loss: 0.0247 - acc: 0.9932\n",
      "Epoch 73/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0289 - acc: 0.9955\n",
      "Epoch 74/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0264 - acc: 0.9927\n",
      "Epoch 75/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0265 - acc: 0.9918\n",
      "Epoch 76/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0273 - acc: 0.9918\n",
      "Epoch 77/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0309 - acc: 0.9927\n",
      "Epoch 78/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0260 - acc: 0.9932\n",
      "Epoch 79/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0267 - acc: 0.9927\n",
      "Epoch 80/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0308 - acc: 0.9914\n",
      "Epoch 81/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0256 - acc: 0.9927\n",
      "Epoch 82/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0261 - acc: 0.9918\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0273 - acc: 0.9932\n",
      "Epoch 84/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0256 - acc: 0.9937\n",
      "Epoch 85/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0258 - acc: 0.9927\n",
      "Epoch 86/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0233 - acc: 0.9937\n",
      "Epoch 87/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0240 - acc: 0.9927A: 0s - loss: 0.0224 - acc: 0.9\n",
      "Epoch 88/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0207 - acc: 0.9946\n",
      "Epoch 89/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0249 - acc: 0.9914\n",
      "Epoch 90/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0291 - acc: 0.9918\n",
      "Epoch 91/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0227 - acc: 0.9937\n",
      "Epoch 92/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0210 - acc: 0.9923\n",
      "Epoch 93/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0226 - acc: 0.9941\n",
      "Epoch 94/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0273 - acc: 0.9941\n",
      "Epoch 95/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0261 - acc: 0.9927\n",
      "Epoch 96/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0239 - acc: 0.9941\n",
      "Epoch 97/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0256 - acc: 0.9923\n",
      "Epoch 98/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0221 - acc: 0.9927\n",
      "Epoch 99/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0246 - acc: 0.9941\n",
      "Epoch 100/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0226 - acc: 0.9932\n",
      "2204/2204 [==============================] - 4s 2ms/step\n",
      "2205/2205 [==============================] - 4s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2204/2204 [==============================] - 19s 9ms/step - loss: 0.6767 - acc: 0.6647\n",
      "Epoch 2/20\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.6407 - acc: 0.6897\n",
      "Epoch 3/20\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.6082 - acc: 0.6897\n",
      "Epoch 4/20\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.5817 - acc: 0.6897\n",
      "Epoch 5/20\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.5639 - acc: 0.6897\n",
      "Epoch 6/20\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.5512 - acc: 0.6897\n",
      "Epoch 7/20\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.5372 - acc: 0.6897\n",
      "Epoch 8/20\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.5243 - acc: 0.6897\n",
      "Epoch 9/20\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.5130 - acc: 0.6897\n",
      "Epoch 10/20\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.5022 - acc: 0.6897\n",
      "Epoch 11/20\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.4898 - acc: 0.6897\n",
      "Epoch 12/20\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.4778 - acc: 0.6897\n",
      "Epoch 13/20\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.4614 - acc: 0.6897\n",
      "Epoch 14/20\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.4519 - acc: 0.6897\n",
      "Epoch 15/20\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.4371 - acc: 0.6897\n",
      "Epoch 16/20\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.4263 - acc: 0.6897\n",
      "Epoch 17/20\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.4139 - acc: 0.6897\n",
      "Epoch 18/20\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.4016 - acc: 0.6897\n",
      "Epoch 19/20\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.3888 - acc: 0.6897\n",
      "Epoch 20/20\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.3743 - acc: 0.6906\n",
      "2205/2205 [==============================] - 6s 3ms/step\n",
      "2204/2204 [==============================] - 2s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2205/2205 [==============================] - 23s 10ms/step - loss: 0.6690 - acc: 0.7061\n",
      "Epoch 2/20\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.6306 - acc: 0.7075\n",
      "Epoch 3/20\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.5938 - acc: 0.7075\n",
      "Epoch 4/20\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.5684 - acc: 0.7075\n",
      "Epoch 5/20\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.5478 - acc: 0.7075\n",
      "Epoch 6/20\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.5315 - acc: 0.7075\n",
      "Epoch 7/20\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.5211 - acc: 0.7075\n",
      "Epoch 8/20\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.5068 - acc: 0.7075\n",
      "Epoch 9/20\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.4966 - acc: 0.7075\n",
      "Epoch 10/20\n",
      "2205/2205 [==============================] - 3s 2ms/step - loss: 0.4844 - acc: 0.7075\n",
      "Epoch 11/20\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.4704 - acc: 0.7075\n",
      "Epoch 12/20\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.4577 - acc: 0.7075\n",
      "Epoch 13/20\n",
      "2205/2205 [==============================] - 3s 2ms/step - loss: 0.4456 - acc: 0.7075\n",
      "Epoch 14/20\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.4350 - acc: 0.7075\n",
      "Epoch 15/20\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.4230 - acc: 0.7075\n",
      "Epoch 16/20\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.4090 - acc: 0.7075\n",
      "Epoch 17/20\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.4002 - acc: 0.7075\n",
      "Epoch 18/20\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.3870 - acc: 0.7075\n",
      "Epoch 19/20\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.3759 - acc: 0.7075\n",
      "Epoch 20/20\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.3632 - acc: 0.7075\n",
      "2204/2204 [==============================] - 6s 3ms/step\n",
      "2205/2205 [==============================] - 2s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "2204/2204 [==============================] - 28s 13ms/step - loss: 0.6668 - acc: 0.6901\n",
      "Epoch 2/40\n",
      "2204/2204 [==============================] - 3s 2ms/step - loss: 0.6344 - acc: 0.6897\n",
      "Epoch 3/40\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.6037 - acc: 0.6897\n",
      "Epoch 4/40\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.5806 - acc: 0.6897\n",
      "Epoch 5/40\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.5628 - acc: 0.6897\n",
      "Epoch 6/40\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.5483 - acc: 0.6897\n",
      "Epoch 7/40\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.5346 - acc: 0.6897\n",
      "Epoch 8/40\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.5222 - acc: 0.6897\n",
      "Epoch 9/40\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.5100 - acc: 0.6897\n",
      "Epoch 10/40\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.4951 - acc: 0.6897\n",
      "Epoch 11/40\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.4853 - acc: 0.6897\n",
      "Epoch 12/40\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.4729 - acc: 0.6897\n",
      "Epoch 13/40\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.4591 - acc: 0.6897\n",
      "Epoch 14/40\n",
      "2204/2204 [==============================] - 3s 2ms/step - loss: 0.4462 - acc: 0.6897\n",
      "Epoch 15/40\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.4328 - acc: 0.6897\n",
      "Epoch 16/40\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.4216 - acc: 0.6897\n",
      "Epoch 17/40\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.4073 - acc: 0.6897\n",
      "Epoch 18/40\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.3957 - acc: 0.6901\n",
      "Epoch 19/40\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.3834 - acc: 0.6897\n",
      "Epoch 20/40\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.3706 - acc: 0.6901\n",
      "Epoch 21/40\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.3593 - acc: 0.6910\n",
      "Epoch 22/40\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.3463 - acc: 0.6965\n",
      "Epoch 23/40\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.3354 - acc: 0.7028\n",
      "Epoch 24/40\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.3245 - acc: 0.7151\n",
      "Epoch 25/40\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.3107 - acc: 0.7414\n",
      "Epoch 26/40\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.3027 - acc: 0.7795\n",
      "Epoch 27/40\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.2918 - acc: 0.8389\n",
      "Epoch 28/40\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.2817 - acc: 0.8621\n",
      "Epoch 29/40\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.2714 - acc: 0.9496\n",
      "Epoch 30/40\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.2627 - acc: 0.9619\n",
      "Epoch 31/40\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.2522 - acc: 0.9664\n",
      "Epoch 32/40\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.2439 - acc: 0.9710\n",
      "Epoch 33/40\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.2346 - acc: 0.9782\n",
      "Epoch 34/40\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.2269 - acc: 0.9791\n",
      "Epoch 35/40\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.2186 - acc: 0.9819\n",
      "Epoch 36/40\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.2116 - acc: 0.9841\n",
      "Epoch 37/40\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.2043 - acc: 0.9859\n",
      "Epoch 38/40\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.1984 - acc: 0.9864\n",
      "Epoch 39/40\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.1903 - acc: 0.9868\n",
      "Epoch 40/40\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.1845 - acc: 0.9882\n",
      "2205/2205 [==============================] - 15s 7ms/step\n",
      "2204/2204 [==============================] - 2s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "2205/2205 [==============================] - 29s 13ms/step - loss: 0.6772 - acc: 0.6508\n",
      "Epoch 2/40\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.6395 - acc: 0.7075\n",
      "Epoch 3/40\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.6041 - acc: 0.7075\n",
      "Epoch 4/40\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.5733 - acc: 0.7075\n",
      "Epoch 5/40\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.5531 - acc: 0.7075\n",
      "Epoch 6/40\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.5381 - acc: 0.7075\n",
      "Epoch 7/40\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.5246 - acc: 0.7075\n",
      "Epoch 8/40\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.5110 - acc: 0.7075\n",
      "Epoch 9/40\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.5018 - acc: 0.7075\n",
      "Epoch 10/40\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.4875 - acc: 0.7075\n",
      "Epoch 11/40\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.4750 - acc: 0.7075\n",
      "Epoch 12/40\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.4643 - acc: 0.7075\n",
      "Epoch 13/40\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.4535 - acc: 0.7075\n",
      "Epoch 14/40\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.4399 - acc: 0.7075\n",
      "Epoch 15/40\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.4273 - acc: 0.7075\n",
      "Epoch 16/40\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.4140 - acc: 0.7075\n",
      "Epoch 17/40\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.4044 - acc: 0.7075\n",
      "Epoch 18/40\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.3930 - acc: 0.7075\n",
      "Epoch 19/40\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.3800 - acc: 0.7075\n",
      "Epoch 20/40\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.3687 - acc: 0.7075\n",
      "Epoch 21/40\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.3559 - acc: 0.7079\n",
      "Epoch 22/40\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.3453 - acc: 0.7079\n",
      "Epoch 23/40\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.3341 - acc: 0.7093A: 2s - loss: 0.29 - ETA: 1s -\n",
      "Epoch 24/40\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.3245 - acc: 0.7125\n",
      "Epoch 25/40\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.3100 - acc: 0.7152\n",
      "Epoch 26/40\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.2999 - acc: 0.7410\n",
      "Epoch 27/40\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.2903 - acc: 0.7546\n",
      "Epoch 28/40\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.2811 - acc: 0.7714\n",
      "Epoch 29/40\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.2731 - acc: 0.8449A: 0s - loss: 0.2737 - acc: 0\n",
      "Epoch 30/40\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.2619 - acc: 0.8644\n",
      "Epoch 31/40\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.2529 - acc: 0.9596\n",
      "Epoch 32/40\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.2423 - acc: 0.9728\n",
      "Epoch 33/40\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.2357 - acc: 0.9760\n",
      "Epoch 34/40\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.2264 - acc: 0.9778\n",
      "Epoch 35/40\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.2200 - acc: 0.9805\n",
      "Epoch 36/40\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.2119 - acc: 0.9823\n",
      "Epoch 37/40\n",
      "2205/2205 [==============================] - 3s 2ms/step - loss: 0.2054 - acc: 0.9855\n",
      "Epoch 38/40\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.1974 - acc: 0.9850\n",
      "Epoch 39/40\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.1923 - acc: 0.9882\n",
      "Epoch 40/40\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.1852 - acc: 0.9887\n",
      "2204/2204 [==============================] - 4s 2ms/step\n",
      "2205/2205 [==============================] - 3s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "2204/2204 [==============================] - 19s 9ms/step - loss: 0.6772 - acc: 0.6638\n",
      "Epoch 2/60\n",
      "2204/2204 [==============================] - 3s 2ms/step - loss: 0.6426 - acc: 0.6897\n",
      "Epoch 3/60\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.6084 - acc: 0.6897\n",
      "Epoch 4/60\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.5835 - acc: 0.6897\n",
      "Epoch 5/60\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.5658 - acc: 0.6897\n",
      "Epoch 6/60\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.5511 - acc: 0.6897\n",
      "Epoch 7/60\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.5385 - acc: 0.6897\n",
      "Epoch 8/60\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.5258 - acc: 0.6897\n",
      "Epoch 9/60\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.5117 - acc: 0.6897\n",
      "Epoch 10/60\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.5034 - acc: 0.6897\n",
      "Epoch 11/60\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.4890 - acc: 0.6897\n",
      "Epoch 12/60\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.4756 - acc: 0.6897\n",
      "Epoch 13/60\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.4630 - acc: 0.6897\n",
      "Epoch 14/60\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.4490 - acc: 0.6897\n",
      "Epoch 15/60\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.4383 - acc: 0.6897\n",
      "Epoch 16/60\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.4253 - acc: 0.6897\n",
      "Epoch 17/60\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.4143 - acc: 0.6897\n",
      "Epoch 18/60\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.4024 - acc: 0.6897\n",
      "Epoch 19/60\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.3881 - acc: 0.6897\n",
      "Epoch 20/60\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.3762 - acc: 0.6901\n",
      "Epoch 21/60\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.3648 - acc: 0.6906\n",
      "Epoch 22/60\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.3520 - acc: 0.6928\n",
      "Epoch 23/60\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.3413 - acc: 0.7005\n",
      "Epoch 24/60\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.3285 - acc: 0.7060\n",
      "Epoch 25/60\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.3162 - acc: 0.7359\n",
      "Epoch 26/60\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.3057 - acc: 0.7405\n",
      "Epoch 27/60\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.2965 - acc: 0.8299\n",
      "Epoch 28/60\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.2861 - acc: 0.8457\n",
      "Epoch 29/60\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.2773 - acc: 0.9233\n",
      "Epoch 30/60\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.2668 - acc: 0.9601\n",
      "Epoch 31/60\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.2556 - acc: 0.9682\n",
      "Epoch 32/60\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.2500 - acc: 0.9687\n",
      "Epoch 33/60\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.2436 - acc: 0.9741\n",
      "Epoch 34/60\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.2321 - acc: 0.9769\n",
      "Epoch 35/60\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.2239 - acc: 0.9791\n",
      "Epoch 36/60\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.2170 - acc: 0.9832\n",
      "Epoch 37/60\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.2088 - acc: 0.9837\n",
      "Epoch 38/60\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.2058 - acc: 0.9855\n",
      "Epoch 39/60\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.1954 - acc: 0.9864\n",
      "Epoch 40/60\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.1896 - acc: 0.9873\n",
      "Epoch 41/60\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.1837 - acc: 0.9859\n",
      "Epoch 42/60\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.1783 - acc: 0.9887\n",
      "Epoch 43/60\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.1715 - acc: 0.9868\n",
      "Epoch 44/60\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.1658 - acc: 0.9891\n",
      "Epoch 45/60\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.1606 - acc: 0.9877\n",
      "Epoch 46/60\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.1569 - acc: 0.9891\n",
      "Epoch 47/60\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.1520 - acc: 0.9891\n",
      "Epoch 48/60\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.1460 - acc: 0.9887\n",
      "Epoch 49/60\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.1426 - acc: 0.9900\n",
      "Epoch 50/60\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.1393 - acc: 0.9900\n",
      "Epoch 51/60\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.1355 - acc: 0.9896\n",
      "Epoch 52/60\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.1333 - acc: 0.9896\n",
      "Epoch 53/60\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.1279 - acc: 0.9887\n",
      "Epoch 54/60\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.1256 - acc: 0.9891\n",
      "Epoch 55/60\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.1225 - acc: 0.9891\n",
      "Epoch 56/60\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.1165 - acc: 0.9896\n",
      "Epoch 57/60\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.1124 - acc: 0.9905\n",
      "Epoch 58/60\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.1108 - acc: 0.9909\n",
      "Epoch 59/60\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.1077 - acc: 0.9891\n",
      "Epoch 60/60\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.1064 - acc: 0.9909\n",
      "2205/2205 [==============================] - 10s 5ms/step\n",
      "2204/2204 [==============================] - 2s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "2205/2205 [==============================] - 27s 12ms/step - loss: 0.6752 - acc: 0.6721\n",
      "Epoch 2/60\n",
      "2205/2205 [==============================] - 3s 2ms/step - loss: 0.6358 - acc: 0.7075\n",
      "Epoch 3/60\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.5982 - acc: 0.7075\n",
      "Epoch 4/60\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.5695 - acc: 0.7075\n",
      "Epoch 5/60\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.5505 - acc: 0.7075\n",
      "Epoch 6/60\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.5334 - acc: 0.7075\n",
      "Epoch 7/60\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.5197 - acc: 0.7075\n",
      "Epoch 8/60\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.5066 - acc: 0.7075\n",
      "Epoch 9/60\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.4958 - acc: 0.7075\n",
      "Epoch 10/60\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.4848 - acc: 0.7075\n",
      "Epoch 11/60\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.4735 - acc: 0.7075\n",
      "Epoch 12/60\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.4612 - acc: 0.7075\n",
      "Epoch 13/60\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.4474 - acc: 0.7075\n",
      "Epoch 14/60\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.4348 - acc: 0.7075\n",
      "Epoch 15/60\n",
      "2205/2205 [==============================] - 3s 2ms/step - loss: 0.4247 - acc: 0.7075\n",
      "Epoch 16/60\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.4101 - acc: 0.7075\n",
      "Epoch 17/60\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.3996 - acc: 0.7075\n",
      "Epoch 18/60\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.3866 - acc: 0.7075\n",
      "Epoch 19/60\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.3768 - acc: 0.7075\n",
      "Epoch 20/60\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.3626 - acc: 0.7075\n",
      "Epoch 21/60\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.3516 - acc: 0.7079\n",
      "Epoch 22/60\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.3422 - acc: 0.7075\n",
      "Epoch 23/60\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.3302 - acc: 0.7107\n",
      "Epoch 24/60\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.3177 - acc: 0.7170\n",
      "Epoch 25/60\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.3081 - acc: 0.7161\n",
      "Epoch 26/60\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.2973 - acc: 0.7460\n",
      "Epoch 27/60\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.2871 - acc: 0.7492\n",
      "Epoch 28/60\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.2765 - acc: 0.8204\n",
      "Epoch 29/60\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.2658 - acc: 0.8567\n",
      "Epoch 30/60\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.2567 - acc: 0.9288\n",
      "Epoch 31/60\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.2467 - acc: 0.9710\n",
      "Epoch 32/60\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.2385 - acc: 0.9737\n",
      "Epoch 33/60\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.2304 - acc: 0.9787\n",
      "Epoch 34/60\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.2217 - acc: 0.9791\n",
      "Epoch 35/60\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.2147 - acc: 0.9819\n",
      "Epoch 36/60\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.2068 - acc: 0.9850\n",
      "Epoch 37/60\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.2004 - acc: 0.9855\n",
      "Epoch 38/60\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.1926 - acc: 0.9882\n",
      "Epoch 39/60\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.1862 - acc: 0.9878\n",
      "Epoch 40/60\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.1808 - acc: 0.9873\n",
      "Epoch 41/60\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.1730 - acc: 0.9900\n",
      "Epoch 42/60\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.1679 - acc: 0.9896\n",
      "Epoch 43/60\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.1624 - acc: 0.9909\n",
      "Epoch 44/60\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.1570 - acc: 0.9914\n",
      "Epoch 45/60\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.1527 - acc: 0.9918\n",
      "Epoch 46/60\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.1481 - acc: 0.9918\n",
      "Epoch 47/60\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.1417 - acc: 0.9914\n",
      "Epoch 48/60\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.1401 - acc: 0.9923\n",
      "Epoch 49/60\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.1346 - acc: 0.9937\n",
      "Epoch 50/60\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.1307 - acc: 0.9923\n",
      "Epoch 51/60\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.1260 - acc: 0.9927\n",
      "Epoch 52/60\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.1242 - acc: 0.9923\n",
      "Epoch 53/60\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.1212 - acc: 0.9927\n",
      "Epoch 54/60\n",
      "2205/2205 [==============================] - 3s 2ms/step - loss: 0.1149 - acc: 0.9927\n",
      "Epoch 55/60\n",
      "2205/2205 [==============================] - 3s 2ms/step - loss: 0.1098 - acc: 0.9937\n",
      "Epoch 56/60\n",
      "2205/2205 [==============================] - 3s 2ms/step - loss: 0.1091 - acc: 0.9927\n",
      "Epoch 57/60\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.1082 - acc: 0.9932\n",
      "Epoch 58/60\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.1041 - acc: 0.9927\n",
      "Epoch 59/60\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.1017 - acc: 0.9923\n",
      "Epoch 60/60\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.0977 - acc: 0.9937\n",
      "2204/2204 [==============================] - 5s 2ms/step\n",
      "2205/2205 [==============================] - 2s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2204/2204 [==============================] - 16s 7ms/step - loss: 0.6833 - acc: 0.6012\n",
      "Epoch 2/100\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.6493 - acc: 0.6897\n",
      "Epoch 3/100\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.6149 - acc: 0.6897\n",
      "Epoch 4/100\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.5872 - acc: 0.6897\n",
      "Epoch 5/100\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.5700 - acc: 0.6897\n",
      "Epoch 6/100\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.5532 - acc: 0.6897\n",
      "Epoch 7/100\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.5414 - acc: 0.6897\n",
      "Epoch 8/100\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.5276 - acc: 0.6897\n",
      "Epoch 9/100\n",
      "2204/2204 [==============================] - 3s 2ms/step - loss: 0.5168 - acc: 0.6897\n",
      "Epoch 10/100\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.5044 - acc: 0.6897\n",
      "Epoch 11/100\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.4924 - acc: 0.6897\n",
      "Epoch 12/100\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.4791 - acc: 0.6897\n",
      "Epoch 13/100\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.4683 - acc: 0.6897\n",
      "Epoch 14/100\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.4565 - acc: 0.6897\n",
      "Epoch 15/100\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.4446 - acc: 0.6897\n",
      "Epoch 16/100\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.4327 - acc: 0.6897\n",
      "Epoch 17/100\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.4199 - acc: 0.6897\n",
      "Epoch 18/100\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.4070 - acc: 0.6897\n",
      "Epoch 19/100\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.3947 - acc: 0.6897\n",
      "Epoch 20/100\n",
      "2204/2204 [==============================] - 3s 2ms/step - loss: 0.3837 - acc: 0.6897\n",
      "Epoch 21/100\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.3707 - acc: 0.6901\n",
      "Epoch 22/100\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.3580 - acc: 0.6915\n",
      "Epoch 23/100\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.3478 - acc: 0.6956\n",
      "Epoch 24/100\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.3358 - acc: 0.7033\n",
      "Epoch 25/100\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.3228 - acc: 0.7074\n",
      "Epoch 26/100\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.3153 - acc: 0.7300\n",
      "Epoch 27/100\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.3049 - acc: 0.7400\n",
      "Epoch 28/100\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.2926 - acc: 0.8285\n",
      "Epoch 29/100\n",
      "2204/2204 [==============================] - 3s 2ms/step - loss: 0.2827 - acc: 0.8448\n",
      "Epoch 30/100\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.2735 - acc: 0.9392\n",
      "Epoch 31/100\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.2637 - acc: 0.9619\n",
      "Epoch 32/100\n",
      "2204/2204 [==============================] - 3s 2ms/step - loss: 0.2551 - acc: 0.9678\n",
      "Epoch 33/100\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.2457 - acc: 0.9728\n",
      "Epoch 34/100\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.2371 - acc: 0.9769\n",
      "Epoch 35/100\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.2304 - acc: 0.9787\n",
      "Epoch 36/100\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.2212 - acc: 0.9832\n",
      "Epoch 37/100\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.2149 - acc: 0.9828\n",
      "Epoch 38/100\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.2067 - acc: 0.9846\n",
      "Epoch 39/100\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.1988 - acc: 0.9859\n",
      "Epoch 40/100\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.1914 - acc: 0.9859\n",
      "Epoch 41/100\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.1890 - acc: 0.9850\n",
      "Epoch 42/100\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.1796 - acc: 0.9873\n",
      "Epoch 43/100\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.1769 - acc: 0.9877\n",
      "Epoch 44/100\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.1691 - acc: 0.9887\n",
      "Epoch 45/100\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.1652 - acc: 0.9877\n",
      "Epoch 46/100\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.1595 - acc: 0.9891\n",
      "Epoch 47/100\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.1569 - acc: 0.9882\n",
      "Epoch 48/100\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.1507 - acc: 0.9877\n",
      "Epoch 49/100\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.1471 - acc: 0.9877\n",
      "Epoch 50/100\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.1434 - acc: 0.9882\n",
      "Epoch 51/100\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.1372 - acc: 0.9887\n",
      "Epoch 52/100\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.1341 - acc: 0.9887\n",
      "Epoch 53/100\n",
      "2204/2204 [==============================] - 3s 2ms/step - loss: 0.1301 - acc: 0.9896\n",
      "Epoch 54/100\n",
      "2204/2204 [==============================] - 3s 2ms/step - loss: 0.1259 - acc: 0.9891\n",
      "Epoch 55/100\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.1233 - acc: 0.9891\n",
      "Epoch 56/100\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.1194 - acc: 0.9900\n",
      "Epoch 57/100\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.1153 - acc: 0.9896\n",
      "Epoch 58/100\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.1136 - acc: 0.9896\n",
      "Epoch 59/100\n",
      "2204/2204 [==============================] - 3s 2ms/step - loss: 0.1082 - acc: 0.9909\n",
      "Epoch 60/100\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.1077 - acc: 0.9905\n",
      "Epoch 61/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.1045 - acc: 0.9900\n",
      "Epoch 62/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.1033 - acc: 0.9909\n",
      "Epoch 63/100\n",
      "2204/2204 [==============================] - 3s 2ms/step - loss: 0.1004 - acc: 0.9900\n",
      "Epoch 64/100\n",
      "2204/2204 [==============================] - 3s 2ms/step - loss: 0.0991 - acc: 0.9896\n",
      "Epoch 65/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0946 - acc: 0.9909\n",
      "Epoch 66/100\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.0933 - acc: 0.9905\n",
      "Epoch 67/100\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.0906 - acc: 0.9900\n",
      "Epoch 68/100\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.0890 - acc: 0.9909\n",
      "Epoch 69/100\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.0867 - acc: 0.9918\n",
      "Epoch 70/100\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.0848 - acc: 0.9918\n",
      "Epoch 71/100\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.0830 - acc: 0.9936\n",
      "Epoch 72/100\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.0816 - acc: 0.9927\n",
      "Epoch 73/100\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.0793 - acc: 0.9923\n",
      "Epoch 74/100\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.0752 - acc: 0.9932\n",
      "Epoch 75/100\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.0732 - acc: 0.9927\n",
      "Epoch 76/100\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.0732 - acc: 0.9923\n",
      "Epoch 77/100\n",
      "2204/2204 [==============================] - 3s 2ms/step - loss: 0.0731 - acc: 0.9927\n",
      "Epoch 78/100\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.0709 - acc: 0.9923\n",
      "Epoch 79/100\n",
      "2204/2204 [==============================] - 3s 2ms/step - loss: 0.0707 - acc: 0.9918\n",
      "Epoch 80/100\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.0690 - acc: 0.9918\n",
      "Epoch 81/100\n",
      "2204/2204 [==============================] - 3s 2ms/step - loss: 0.0668 - acc: 0.9927\n",
      "Epoch 82/100\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.0673 - acc: 0.9914\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.0643 - acc: 0.9941\n",
      "Epoch 84/100\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.0653 - acc: 0.9918\n",
      "Epoch 85/100\n",
      "2204/2204 [==============================] - 3s 2ms/step - loss: 0.0643 - acc: 0.9932\n",
      "Epoch 86/100\n",
      "2204/2204 [==============================] - 4s 2ms/step - loss: 0.0635 - acc: 0.9918\n",
      "Epoch 87/100\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.0591 - acc: 0.9923\n",
      "Epoch 88/100\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.0608 - acc: 0.9918\n",
      "Epoch 89/100\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.0588 - acc: 0.9923\n",
      "Epoch 90/100\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.0576 - acc: 0.9918\n",
      "Epoch 91/100\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.0578 - acc: 0.9914\n",
      "Epoch 92/100\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.0544 - acc: 0.9932\n",
      "Epoch 93/100\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.0530 - acc: 0.9936\n",
      "Epoch 94/100\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.0549 - acc: 0.9909\n",
      "Epoch 95/100\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.0521 - acc: 0.9909\n",
      "Epoch 96/100\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.0522 - acc: 0.9918\n",
      "Epoch 97/100\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.0541 - acc: 0.9914\n",
      "Epoch 98/100\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.0487 - acc: 0.9946\n",
      "Epoch 99/100\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.0519 - acc: 0.9914\n",
      "Epoch 100/100\n",
      "2204/2204 [==============================] - 3s 1ms/step - loss: 0.0510 - acc: 0.9909\n",
      "2205/2205 [==============================] - 7s 3ms/step\n",
      "2204/2204 [==============================] - 3s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2205/2205 [==============================] - 25s 11ms/step - loss: 0.6819 - acc: 0.6145\n",
      "Epoch 2/100\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.6432 - acc: 0.7075\n",
      "Epoch 3/100\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.6046 - acc: 0.7075\n",
      "Epoch 4/100\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.5731 - acc: 0.7075\n",
      "Epoch 5/100\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.5518 - acc: 0.7075\n",
      "Epoch 6/100\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.5357 - acc: 0.7075\n",
      "Epoch 7/100\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.5209 - acc: 0.7075\n",
      "Epoch 8/100\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.5085 - acc: 0.7075\n",
      "Epoch 9/100\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.4964 - acc: 0.7075\n",
      "Epoch 10/100\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.4841 - acc: 0.7075\n",
      "Epoch 11/100\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.4755 - acc: 0.7075\n",
      "Epoch 12/100\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.4592 - acc: 0.7075\n",
      "Epoch 13/100\n",
      "2205/2205 [==============================] - 3s 2ms/step - loss: 0.4481 - acc: 0.7075\n",
      "Epoch 14/100\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.4387 - acc: 0.7075\n",
      "Epoch 15/100\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.4251 - acc: 0.7075\n",
      "Epoch 16/100\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.4129 - acc: 0.7075\n",
      "Epoch 17/100\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.4020 - acc: 0.7075\n",
      "Epoch 18/100\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.3902 - acc: 0.7075\n",
      "Epoch 19/100\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.3759 - acc: 0.7075\n",
      "Epoch 20/100\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.3663 - acc: 0.7075\n",
      "Epoch 21/100\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.3543 - acc: 0.7079\n",
      "Epoch 22/100\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.3438 - acc: 0.7075\n",
      "Epoch 23/100\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.3311 - acc: 0.7088\n",
      "Epoch 24/100\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.3199 - acc: 0.7166\n",
      "Epoch 25/100\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.3096 - acc: 0.7161\n",
      "Epoch 26/100\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.2993 - acc: 0.7265\n",
      "Epoch 27/100\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.2900 - acc: 0.7524\n",
      "Epoch 28/100\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.2793 - acc: 0.7805\n",
      "Epoch 29/100\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.2700 - acc: 0.8608\n",
      "Epoch 30/100\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.2602 - acc: 0.8834\n",
      "Epoch 31/100\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.2528 - acc: 0.9628\n",
      "Epoch 32/100\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.2409 - acc: 0.9714\n",
      "Epoch 33/100\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.2319 - acc: 0.9760\n",
      "Epoch 34/100\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.2257 - acc: 0.9810\n",
      "Epoch 35/100\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.2160 - acc: 0.9810\n",
      "Epoch 36/100\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.2101 - acc: 0.9855\n",
      "Epoch 37/100\n",
      "2205/2205 [==============================] - 3s 2ms/step - loss: 0.2041 - acc: 0.9846\n",
      "Epoch 38/100\n",
      "2205/2205 [==============================] - 3s 2ms/step - loss: 0.1968 - acc: 0.9859\n",
      "Epoch 39/100\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.1907 - acc: 0.9873\n",
      "Epoch 40/100\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.1845 - acc: 0.9878\n",
      "Epoch 41/100\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.1766 - acc: 0.9896\n",
      "Epoch 42/100\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.1734 - acc: 0.9900\n",
      "Epoch 43/100\n",
      "2205/2205 [==============================] - 3s 2ms/step - loss: 0.1650 - acc: 0.9905\n",
      "Epoch 44/100\n",
      "2205/2205 [==============================] - 3s 2ms/step - loss: 0.1607 - acc: 0.9905\n",
      "Epoch 45/100\n",
      "2205/2205 [==============================] - 3s 2ms/step - loss: 0.1548 - acc: 0.9909\n",
      "Epoch 46/100\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.1512 - acc: 0.9909\n",
      "Epoch 47/100\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.1454 - acc: 0.9923\n",
      "Epoch 48/100\n",
      "2205/2205 [==============================] - 3s 2ms/step - loss: 0.1407 - acc: 0.9923\n",
      "Epoch 49/100\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.1374 - acc: 0.9914\n",
      "Epoch 50/100\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.1328 - acc: 0.9923\n",
      "Epoch 51/100\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.1305 - acc: 0.9927\n",
      "Epoch 52/100\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.1257 - acc: 0.9927\n",
      "Epoch 53/100\n",
      "2205/2205 [==============================] - 3s 2ms/step - loss: 0.1209 - acc: 0.9923\n",
      "Epoch 54/100\n",
      "2205/2205 [==============================] - 3s 2ms/step - loss: 0.1184 - acc: 0.9923\n",
      "Epoch 55/100\n",
      "2205/2205 [==============================] - 3s 2ms/step - loss: 0.1150 - acc: 0.9937\n",
      "Epoch 56/100\n",
      "2205/2205 [==============================] - 3s 2ms/step - loss: 0.1123 - acc: 0.9914\n",
      "Epoch 57/100\n",
      "2205/2205 [==============================] - 3s 2ms/step - loss: 0.1091 - acc: 0.9923\n",
      "Epoch 58/100\n",
      "2205/2205 [==============================] - 3s 2ms/step - loss: 0.1062 - acc: 0.9941\n",
      "Epoch 59/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.1029 - acc: 0.9941\n",
      "Epoch 60/100\n",
      "2205/2205 [==============================] - 3s 2ms/step - loss: 0.0996 - acc: 0.9923\n",
      "Epoch 61/100\n",
      "2205/2205 [==============================] - 3s 2ms/step - loss: 0.0963 - acc: 0.9932\n",
      "Epoch 62/100\n",
      "2205/2205 [==============================] - 3s 2ms/step - loss: 0.0944 - acc: 0.9932\n",
      "Epoch 63/100\n",
      "2205/2205 [==============================] - 3s 2ms/step - loss: 0.0935 - acc: 0.9932\n",
      "Epoch 64/100\n",
      "2205/2205 [==============================] - 3s 2ms/step - loss: 0.0900 - acc: 0.9927\n",
      "Epoch 65/100\n",
      "2205/2205 [==============================] - 3s 2ms/step - loss: 0.0871 - acc: 0.9937\n",
      "Epoch 66/100\n",
      "2205/2205 [==============================] - 3s 2ms/step - loss: 0.0846 - acc: 0.9932\n",
      "Epoch 67/100\n",
      "2205/2205 [==============================] - 3s 2ms/step - loss: 0.0841 - acc: 0.9927\n",
      "Epoch 68/100\n",
      "2205/2205 [==============================] - 3s 2ms/step - loss: 0.0820 - acc: 0.9937\n",
      "Epoch 69/100\n",
      "2205/2205 [==============================] - 3s 2ms/step - loss: 0.0794 - acc: 0.9946\n",
      "Epoch 70/100\n",
      "2205/2205 [==============================] - 4s 2ms/step - loss: 0.0763 - acc: 0.9950\n",
      "Epoch 71/100\n",
      "2205/2205 [==============================] - 3s 2ms/step - loss: 0.0761 - acc: 0.9927\n",
      "Epoch 72/100\n",
      "2205/2205 [==============================] - 3s 2ms/step - loss: 0.0722 - acc: 0.9941\n",
      "Epoch 73/100\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.0730 - acc: 0.9927\n",
      "Epoch 74/100\n",
      "2205/2205 [==============================] - 3s 2ms/step - loss: 0.0710 - acc: 0.9946\n",
      "Epoch 75/100\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.0706 - acc: 0.9946\n",
      "Epoch 76/100\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.0669 - acc: 0.9955\n",
      "Epoch 77/100\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.0662 - acc: 0.9955\n",
      "Epoch 78/100\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.0639 - acc: 0.994 - 3s 2ms/step - loss: 0.0639 - acc: 0.9946\n",
      "Epoch 79/100\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.0648 - acc: 0.9941\n",
      "Epoch 80/100\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.0630 - acc: 0.9946\n",
      "Epoch 81/100\n",
      "2205/2205 [==============================] - 3s 2ms/step - loss: 0.0623 - acc: 0.9927\n",
      "Epoch 82/100\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.0617 - acc: 0.9941\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2205/2205 [==============================] - 3s 2ms/step - loss: 0.0594 - acc: 0.9941\n",
      "Epoch 84/100\n",
      "2205/2205 [==============================] - 3s 2ms/step - loss: 0.0590 - acc: 0.9950\n",
      "Epoch 85/100\n",
      "2205/2205 [==============================] - 3s 2ms/step - loss: 0.0576 - acc: 0.9955\n",
      "Epoch 86/100\n",
      "2205/2205 [==============================] - 3s 2ms/step - loss: 0.0533 - acc: 0.9959\n",
      "Epoch 87/100\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.0560 - acc: 0.9946\n",
      "Epoch 88/100\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.0535 - acc: 0.9950\n",
      "Epoch 89/100\n",
      "2205/2205 [==============================] - 3s 2ms/step - loss: 0.0548 - acc: 0.9941\n",
      "Epoch 90/100\n",
      "2205/2205 [==============================] - 3s 2ms/step - loss: 0.0526 - acc: 0.9946\n",
      "Epoch 91/100\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.0530 - acc: 0.9937\n",
      "Epoch 92/100\n",
      "2205/2205 [==============================] - 3s 2ms/step - loss: 0.0499 - acc: 0.9946\n",
      "Epoch 93/100\n",
      "2205/2205 [==============================] - 3s 2ms/step - loss: 0.0504 - acc: 0.9932\n",
      "Epoch 94/100\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.0492 - acc: 0.9937\n",
      "Epoch 95/100\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.0490 - acc: 0.9937\n",
      "Epoch 96/100\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.0461 - acc: 0.9955\n",
      "Epoch 97/100\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.0469 - acc: 0.9941\n",
      "Epoch 98/100\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.0468 - acc: 0.9941\n",
      "Epoch 99/100\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.0463 - acc: 0.9950\n",
      "Epoch 100/100\n",
      "2205/2205 [==============================] - 3s 1ms/step - loss: 0.0438 - acc: 0.9950\n",
      "2204/2204 [==============================] - 14s 6ms/step\n",
      "2205/2205 [==============================] - 10s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "  20/2204 [..............................] - ETA: 1:00:46 - loss: 0.6922 - acc: 0.8000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.101555). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2204/2204 [==============================] - 51s 23ms/step - loss: 0.4441 - acc: 0.8158\n",
      "Epoch 2/20\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.1489 - acc: 0.9551\n",
      "Epoch 3/20\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0932 - acc: 0.9710\n",
      "Epoch 4/20\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0791 - acc: 0.9787\n",
      "Epoch 5/20\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0475 - acc: 0.9841\n",
      "Epoch 6/20\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0436 - acc: 0.9887\n",
      "Epoch 7/20\n",
      "2204/2204 [==============================] - 12s 5ms/step - loss: 0.0384 - acc: 0.9868A: 2s - loss: 0.0383 - a\n",
      "Epoch 8/20\n",
      "2204/2204 [==============================] - 12s 5ms/step - loss: 0.0320 - acc: 0.9896\n",
      "Epoch 9/20\n",
      "2204/2204 [==============================] - 10s 5ms/step - loss: 0.0287 - acc: 0.9927\n",
      "Epoch 10/20\n",
      "2204/2204 [==============================] - 10s 5ms/step - loss: 0.0260 - acc: 0.9918\n",
      "Epoch 11/20\n",
      "2204/2204 [==============================] - 10s 5ms/step - loss: 0.0256 - acc: 0.9905\n",
      "Epoch 12/20\n",
      "2204/2204 [==============================] - 10s 5ms/step - loss: 0.0243 - acc: 0.9927\n",
      "Epoch 13/20\n",
      "2204/2204 [==============================] - 10s 5ms/step - loss: 0.0233 - acc: 0.9927\n",
      "Epoch 14/20\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0224 - acc: 0.9918\n",
      "Epoch 15/20\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0208 - acc: 0.9923\n",
      "Epoch 16/20\n",
      "2204/2204 [==============================] - 10s 5ms/step - loss: 0.0212 - acc: 0.9923\n",
      "Epoch 17/20\n",
      "2204/2204 [==============================] - 10s 5ms/step - loss: 0.0200 - acc: 0.9927\n",
      "Epoch 18/20\n",
      "2204/2204 [==============================] - 10s 5ms/step - loss: 0.0219 - acc: 0.9918\n",
      "Epoch 19/20\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0188 - acc: 0.9932\n",
      "Epoch 20/20\n",
      "2204/2204 [==============================] - 10s 5ms/step - loss: 0.0179 - acc: 0.9923\n",
      "2205/2205 [==============================] - 9s 4ms/step\n",
      "2204/2204 [==============================] - 3s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2205/2205 [==============================] - 33s 15ms/step - loss: 0.4206 - acc: 0.8313\n",
      "Epoch 2/20\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.1348 - acc: 0.9587\n",
      "Epoch 3/20\n",
      "2205/2205 [==============================] - 12s 5ms/step - loss: 0.0866 - acc: 0.9778\n",
      "Epoch 4/20\n",
      "2205/2205 [==============================] - 12s 5ms/step - loss: 0.0669 - acc: 0.9859: 1s - l\n",
      "Epoch 5/20\n",
      "2205/2205 [==============================] - 12s 5ms/step - loss: 0.0520 - acc: 0.9900\n",
      "Epoch 6/20\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0488 - acc: 0.9891\n",
      "Epoch 7/20\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0403 - acc: 0.9909\n",
      "Epoch 8/20\n",
      "2205/2205 [==============================] - 12s 5ms/step - loss: 0.0367 - acc: 0.9918: 0s - loss: 0.03\n",
      "Epoch 9/20\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0347 - acc: 0.9914\n",
      "Epoch 10/20\n",
      "2205/2205 [==============================] - 10s 5ms/step - loss: 0.0385 - acc: 0.9923\n",
      "Epoch 11/20\n",
      "2205/2205 [==============================] - 10s 4ms/step - loss: 0.0331 - acc: 0.9927\n",
      "Epoch 12/20\n",
      "2205/2205 [==============================] - 10s 4ms/step - loss: 0.0317 - acc: 0.9932: 1s - loss: 0.\n",
      "Epoch 13/20\n",
      "2205/2205 [==============================] - 10s 5ms/step - loss: 0.0354 - acc: 0.9923\n",
      "Epoch 14/20\n",
      "2205/2205 [==============================] - 10s 5ms/step - loss: 0.0364 - acc: 0.9923\n",
      "Epoch 15/20\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0370 - acc: 0.9923\n",
      "Epoch 16/20\n",
      "2205/2205 [==============================] - 10s 5ms/step - loss: 0.0290 - acc: 0.9946\n",
      "Epoch 17/20\n",
      "2205/2205 [==============================] - 10s 5ms/step - loss: 0.0307 - acc: 0.9914\n",
      "Epoch 18/20\n",
      "2205/2205 [==============================] - 10s 5ms/step - loss: 0.0373 - acc: 0.9937\n",
      "Epoch 19/20\n",
      "2205/2205 [==============================] - 10s 5ms/step - loss: 0.0352 - acc: 0.9927\n",
      "Epoch 20/20\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0286 - acc: 0.9941\n",
      "2204/2204 [==============================] - 9s 4ms/step\n",
      "2205/2205 [==============================] - 3s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "  10/2204 [..............................] - ETA: 5:09:08 - loss: 0.6927 - acc: 0.6000 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.181210). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2204/2204 [==============================] - 109s 49ms/step - loss: 0.4742 - acc: 0.71371s - loss: 0.4760 - acc: 0.\n",
      "Epoch 2/40\n",
      "2204/2204 [==============================] - 12s 5ms/step - loss: 0.2486 - acc: 0.9478\n",
      "Epoch 3/40\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.1078 - acc: 0.9814: 1s - lo\n",
      "Epoch 4/40\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0640 - acc: 0.9846\n",
      "Epoch 5/40\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0442 - acc: 0.9905\n",
      "Epoch 6/40\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0398 - acc: 0.9905: 1\n",
      "Epoch 7/40\n",
      "2204/2204 [==============================] - 10s 5ms/step - loss: 0.0371 - acc: 0.9914\n",
      "Epoch 8/40\n",
      "2204/2204 [==============================] - 10s 5ms/step - loss: 0.0368 - acc: 0.9909\n",
      "Epoch 9/40\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0333 - acc: 0.9914\n",
      "Epoch 10/40\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0346 - acc: 0.9896\n",
      "Epoch 11/40\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0315 - acc: 0.9909\n",
      "Epoch 12/40\n",
      "2204/2204 [==============================] - 10s 5ms/step - loss: 0.0308 - acc: 0.9923\n",
      "Epoch 13/40\n",
      "2204/2204 [==============================] - 10s 5ms/step - loss: 0.0330 - acc: 0.9896\n",
      "Epoch 14/40\n",
      "2204/2204 [==============================] - 10s 4ms/step - loss: 0.0330 - acc: 0.9918\n",
      "Epoch 15/40\n",
      "2204/2204 [==============================] - 10s 4ms/step - loss: 0.0280 - acc: 0.9923\n",
      "Epoch 16/40\n",
      "2204/2204 [==============================] - 10s 4ms/step - loss: 0.0321 - acc: 0.9918\n",
      "Epoch 17/40\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0302 - acc: 0.9896\n",
      "Epoch 18/40\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0304 - acc: 0.9914\n",
      "Epoch 19/40\n",
      "2204/2204 [==============================] - 12s 5ms/step - loss: 0.0295 - acc: 0.9909\n",
      "Epoch 20/40\n",
      "2204/2204 [==============================] - 12s 5ms/step - loss: 0.0309 - acc: 0.9905\n",
      "Epoch 21/40\n",
      "2204/2204 [==============================] - 12s 5ms/step - loss: 0.0319 - acc: 0.9918\n",
      "Epoch 22/40\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0305 - acc: 0.9923\n",
      "Epoch 23/40\n",
      "2204/2204 [==============================] - 10s 5ms/step - loss: 0.0307 - acc: 0.9900\n",
      "Epoch 24/40\n",
      "2204/2204 [==============================] - 10s 5ms/step - loss: 0.0327 - acc: 0.9900\n",
      "Epoch 25/40\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0343 - acc: 0.9918\n",
      "Epoch 26/40\n",
      "2204/2204 [==============================] - 10s 5ms/step - loss: 0.0303 - acc: 0.9932\n",
      "Epoch 27/40\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0275 - acc: 0.9936\n",
      "Epoch 28/40\n",
      "2204/2204 [==============================] - 12s 5ms/step - loss: 0.0307 - acc: 0.9923\n",
      "Epoch 29/40\n",
      "2204/2204 [==============================] - 12s 5ms/step - loss: 0.0298 - acc: 0.9914\n",
      "Epoch 30/40\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0241 - acc: 0.9927: 0s - loss: 0.024\n",
      "Epoch 31/40\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0284 - acc: 0.9923: 1s - l\n",
      "Epoch 32/40\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0296 - acc: 0.9909TA: 0s - loss: 0.0301 - \n",
      "Epoch 33/40\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0298 - acc: 0.9923: 0s - loss: 0.0296 \n",
      "Epoch 34/40\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0309 - acc: 0.9918\n",
      "Epoch 35/40\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0304 - acc: 0.9914\n",
      "Epoch 36/40\n",
      "2204/2204 [==============================] - 13s 6ms/step - loss: 0.0273 - acc: 0.9923\n",
      "Epoch 37/40\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0268 - acc: 0.9932\n",
      "Epoch 38/40\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0288 - acc: 0.9909: 0s - loss: 0.0277 - acc:\n",
      "Epoch 39/40\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0307 - acc: 0.9923\n",
      "Epoch 40/40\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0294 - acc: 0.9914\n",
      "2205/2205 [==============================] - 11s 5ms/step\n",
      "2204/2204 [==============================] - 5s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "2205/2205 [==============================] - 67s 31ms/step - loss: 0.4939 - acc: 0.7397\n",
      "Epoch 2/40\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.1977 - acc: 0.9478\n",
      "Epoch 3/40\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.1056 - acc: 0.9800\n",
      "Epoch 4/40\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0783 - acc: 0.9864\n",
      "Epoch 5/40\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0619 - acc: 0.9891\n",
      "Epoch 6/40\n",
      "2205/2205 [==============================] - 10s 5ms/step - loss: 0.0506 - acc: 0.9909\n",
      "Epoch 7/40\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0447 - acc: 0.9914\n",
      "Epoch 8/40\n",
      "2205/2205 [==============================] - 10s 5ms/step - loss: 0.0434 - acc: 0.9909: 0s - loss: 0.0436 - acc: 0.990\n",
      "Epoch 9/40\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0368 - acc: 0.9927\n",
      "Epoch 10/40\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0356 - acc: 0.9927\n",
      "Epoch 11/40\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0341 - acc: 0.9937\n",
      "Epoch 12/40\n",
      "2205/2205 [==============================] - 10s 5ms/step - loss: 0.0336 - acc: 0.9927\n",
      "Epoch 13/40\n",
      "2205/2205 [==============================] - 10s 5ms/step - loss: 0.0345 - acc: 0.9932\n",
      "Epoch 14/40\n",
      "2205/2205 [==============================] - 10s 5ms/step - loss: 0.0379 - acc: 0.9918\n",
      "Epoch 15/40\n",
      "2205/2205 [==============================] - 10s 5ms/step - loss: 0.0302 - acc: 0.9955\n",
      "Epoch 16/40\n",
      "2205/2205 [==============================] - 10s 5ms/step - loss: 0.0321 - acc: 0.9941\n",
      "Epoch 17/40\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.0313 - acc: 0.994 - 10s 5ms/step - loss: 0.0312 - acc: 0.9946\n",
      "Epoch 18/40\n",
      "2205/2205 [==============================] - 10s 5ms/step - loss: 0.0308 - acc: 0.9941\n",
      "Epoch 19/40\n",
      "2205/2205 [==============================] - 10s 5ms/step - loss: 0.0359 - acc: 0.9937\n",
      "Epoch 20/40\n",
      "2205/2205 [==============================] - 10s 5ms/step - loss: 0.0307 - acc: 0.9932: 0s - loss: 0.032\n",
      "Epoch 21/40\n",
      "2205/2205 [==============================] - 10s 5ms/step - loss: 0.0312 - acc: 0.9946\n",
      "Epoch 22/40\n",
      "2205/2205 [==============================] - 10s 5ms/step - loss: 0.0301 - acc: 0.9941\n",
      "Epoch 23/40\n",
      "2205/2205 [==============================] - 10s 5ms/step - loss: 0.0316 - acc: 0.9937\n",
      "Epoch 24/40\n",
      "2205/2205 [==============================] - 10s 5ms/step - loss: 0.0303 - acc: 0.9937\n",
      "Epoch 25/40\n",
      "2205/2205 [==============================] - 10s 5ms/step - loss: 0.0289 - acc: 0.9941\n",
      "Epoch 26/40\n",
      "2205/2205 [==============================] - 10s 5ms/step - loss: 0.0295 - acc: 0.9941\n",
      "Epoch 27/40\n",
      "2205/2205 [==============================] - 10s 5ms/step - loss: 0.0284 - acc: 0.9937\n",
      "Epoch 28/40\n",
      "2205/2205 [==============================] - 10s 5ms/step - loss: 0.0289 - acc: 0.9950\n",
      "Epoch 29/40\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0270 - acc: 0.9950\n",
      "Epoch 30/40\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0292 - acc: 0.9946: 3s - loss: 0.0358 - acc: 0.9 - ETA: 2s - loss: 0.0350 - - E\n",
      "Epoch 31/40\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0326 - acc: 0.9927\n",
      "Epoch 32/40\n",
      "2205/2205 [==============================] - 10s 5ms/step - loss: 0.0290 - acc: 0.9941\n",
      "Epoch 33/40\n",
      "2205/2205 [==============================] - 10s 5ms/step - loss: 0.0286 - acc: 0.9946\n",
      "Epoch 34/40\n",
      "2205/2205 [==============================] - 10s 5ms/step - loss: 0.0318 - acc: 0.9932\n",
      "Epoch 35/40\n",
      "2205/2205 [==============================] - 10s 5ms/step - loss: 0.0264 - acc: 0.9937\n",
      "Epoch 36/40\n",
      "2205/2205 [==============================] - 10s 4ms/step - loss: 0.0251 - acc: 0.9950\n",
      "Epoch 37/40\n",
      "2205/2205 [==============================] - 10s 4ms/step - loss: 0.0294 - acc: 0.9946\n",
      "Epoch 38/40\n",
      "2205/2205 [==============================] - 10s 4ms/step - loss: 0.0302 - acc: 0.9946\n",
      "Epoch 39/40\n",
      "2205/2205 [==============================] - 10s 5ms/step - loss: 0.0287 - acc: 0.9946\n",
      "Epoch 40/40\n",
      "2205/2205 [==============================] - 10s 5ms/step - loss: 0.0286 - acc: 0.9937\n",
      "2204/2204 [==============================] - 9s 4ms/step\n",
      "2205/2205 [==============================] - 3s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "2204/2204 [==============================] - 36s 16ms/step - loss: 0.4720 - acc: 0.8072\n",
      "Epoch 2/60\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.1529 - acc: 0.9574\n",
      "Epoch 3/60\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0824 - acc: 0.9791\n",
      "Epoch 4/60\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0531 - acc: 0.9850\n",
      "Epoch 5/60\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0470 - acc: 0.9859: 1s - los\n",
      "Epoch 6/60\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0456 - acc: 0.9877\n",
      "Epoch 7/60\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0368 - acc: 0.9905\n",
      "Epoch 8/60\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0318 - acc: 0.9914\n",
      "Epoch 9/60\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0312 - acc: 0.9927\n",
      "Epoch 10/60\n",
      "2204/2204 [==============================] - 12s 5ms/step - loss: 0.0327 - acc: 0.9896TA - ETA: 0s - loss: 0.0332 - acc\n",
      "Epoch 11/60\n",
      "2204/2204 [==============================] - 12s 5ms/step - loss: 0.0283 - acc: 0.9927\n",
      "Epoch 12/60\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0233 - acc: 0.9932\n",
      "Epoch 13/60\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0198 - acc: 0.9918\n",
      "Epoch 14/60\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0260 - acc: 0.9927\n",
      "Epoch 15/60\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0183 - acc: 0.9927\n",
      "Epoch 16/60\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0177 - acc: 0.9936\n",
      "Epoch 17/60\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0172 - acc: 0.9927\n",
      "Epoch 18/60\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0176 - acc: 0.9932\n",
      "Epoch 19/60\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0260 - acc: 0.9927\n",
      "Epoch 20/60\n",
      "2204/2204 [==============================] - 10s 5ms/step - loss: 0.0177 - acc: 0.9936\n",
      "Epoch 21/60\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0178 - acc: 0.9927\n",
      "Epoch 22/60\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0242 - acc: 0.9927\n",
      "Epoch 23/60\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0206 - acc: 0.9927\n",
      "Epoch 24/60\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0174 - acc: 0.9936\n",
      "Epoch 25/60\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0163 - acc: 0.9941\n",
      "Epoch 26/60\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0169 - acc: 0.9927\n",
      "Epoch 27/60\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0183 - acc: 0.9936\n",
      "Epoch 28/60\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0174 - acc: 0.9946: 1s - los\n",
      "Epoch 29/60\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0178 - acc: 0.9941\n",
      "Epoch 30/60\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0274 - acc: 0.9936\n",
      "Epoch 31/60\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0175 - acc: 0.9936\n",
      "Epoch 32/60\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0203 - acc: 0.9927\n",
      "Epoch 33/60\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0163 - acc: 0.9941\n",
      "Epoch 34/60\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0225 - acc: 0.9941\n",
      "Epoch 35/60\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0152 - acc: 0.9941\n",
      "Epoch 36/60\n",
      "2204/2204 [==============================] - 12s 5ms/step - loss: 0.0197 - acc: 0.9936: 0s - loss: 0.01\n",
      "Epoch 37/60\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0182 - acc: 0.9932\n",
      "Epoch 38/60\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0176 - acc: 0.9932\n",
      "Epoch 39/60\n",
      "2204/2204 [==============================] - 13s 6ms/step - loss: 0.0158 - acc: 0.9941\n",
      "Epoch 40/60\n",
      "2204/2204 [==============================] - 13s 6ms/step - loss: 0.0159 - acc: 0.9932\n",
      "Epoch 41/60\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0155 - acc: 0.9946\n",
      "Epoch 42/60\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0165 - acc: 0.9946\n",
      "Epoch 43/60\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0150 - acc: 0.9946\n",
      "Epoch 44/60\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0170 - acc: 0.9927\n",
      "Epoch 45/60\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0165 - acc: 0.9936- ETA: 1s - loss: 0.\n",
      "Epoch 46/60\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0158 - acc: 0.9941\n",
      "Epoch 47/60\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0163 - acc: 0.9936\n",
      "Epoch 48/60\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0180 - acc: 0.9932\n",
      "Epoch 49/60\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0165 - acc: 0.9932\n",
      "Epoch 50/60\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0149 - acc: 0.9936\n",
      "Epoch 51/60\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0148 - acc: 0.9941\n",
      "Epoch 52/60\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0153 - acc: 0.9932\n",
      "Epoch 53/60\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0151 - acc: 0.9936\n",
      "Epoch 54/60\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0162 - acc: 0.9936\n",
      "Epoch 55/60\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0159 - acc: 0.9936\n",
      "Epoch 56/60\n",
      "2204/2204 [==============================] - 12s 6ms/step - loss: 0.0159 - acc: 0.9941\n",
      "Epoch 57/60\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0156 - acc: 0.9941\n",
      "Epoch 58/60\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0165 - acc: 0.9927\n",
      "Epoch 59/60\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0233 - acc: 0.9927\n",
      "Epoch 60/60\n",
      "2204/2204 [==============================] - 12s 5ms/step - loss: 0.0157 - acc: 0.9936\n",
      "2205/2205 [==============================] - 11s 5ms/step\n",
      "2204/2204 [==============================] - 7s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "2205/2205 [==============================] - 59s 27ms/step - loss: 0.4442 - acc: 0.7914\n",
      "Epoch 2/60\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.1673 - acc: 0.9420\n",
      "Epoch 3/60\n",
      "2205/2205 [==============================] - 12s 5ms/step - loss: 0.1162 - acc: 0.9728\n",
      "Epoch 4/60\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0837 - acc: 0.9823\n",
      "Epoch 5/60\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0764 - acc: 0.9855\n",
      "Epoch 6/60\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0576 - acc: 0.9900\n",
      "Epoch 7/60\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0513 - acc: 0.9918TA: 0s - loss: 0.054\n",
      "Epoch 8/60\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0483 - acc: 0.9909\n",
      "Epoch 9/60\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0418 - acc: 0.9923: 1s - loss: \n",
      "Epoch 10/60\n",
      "2205/2205 [==============================] - 12s 5ms/step - loss: 0.0381 - acc: 0.9937\n",
      "Epoch 11/60\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0365 - acc: 0.9937: 0s - loss: 0.0367 - a\n",
      "Epoch 12/60\n",
      "2205/2205 [==============================] - 12s 5ms/step - loss: 0.0376 - acc: 0.9923\n",
      "Epoch 13/60\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0319 - acc: 0.9950\n",
      "Epoch 14/60\n",
      "2205/2205 [==============================] - 12s 5ms/step - loss: 0.0312 - acc: 0.9937: 0s - loss: 0.0317 - acc\n",
      "Epoch 15/60\n",
      "2205/2205 [==============================] - 12s 5ms/step - loss: 0.0373 - acc: 0.9927\n",
      "Epoch 16/60\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0263 - acc: 0.9955\n",
      "Epoch 17/60\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0289 - acc: 0.9946\n",
      "Epoch 18/60\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0270 - acc: 0.9955\n",
      "Epoch 19/60\n",
      "2205/2205 [==============================] - 12s 5ms/step - loss: 0.0271 - acc: 0.9946\n",
      "Epoch 20/60\n",
      "2205/2205 [==============================] - 12s 6ms/step - loss: 0.0282 - acc: 0.9927\n",
      "Epoch 21/60\n",
      "2205/2205 [==============================] - 12s 5ms/step - loss: 0.0258 - acc: 0.9950\n",
      "Epoch 22/60\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0230 - acc: 0.9950\n",
      "Epoch 23/60\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0253 - acc: 0.9946\n",
      "Epoch 24/60\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0233 - acc: 0.9946\n",
      "Epoch 25/60\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0231 - acc: 0.9950: 1s - l\n",
      "Epoch 26/60\n",
      "2205/2205 [==============================] - 12s 5ms/step - loss: 0.0227 - acc: 0.9955: 5s - loss: 0\n",
      "Epoch 27/60\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0206 - acc: 0.9955\n",
      "Epoch 28/60\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0244 - acc: 0.9932: 1s - loss:\n",
      "Epoch 29/60\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0221 - acc: 0.9941\n",
      "Epoch 30/60\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0221 - acc: 0.9950\n",
      "Epoch 31/60\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0225 - acc: 0.9950\n",
      "Epoch 32/60\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0223 - acc: 0.9941\n",
      "Epoch 33/60\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0204 - acc: 0.9959\n",
      "Epoch 34/60\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0195 - acc: 0.9946: 1s - los\n",
      "Epoch 35/60\n",
      "2205/2205 [==============================] - 12s 5ms/step - loss: 0.0220 - acc: 0.9950\n",
      "Epoch 36/60\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0227 - acc: 0.9941\n",
      "Epoch 37/60\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0209 - acc: 0.9932\n",
      "Epoch 38/60\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0220 - acc: 0.9955\n",
      "Epoch 39/60\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0231 - acc: 0.9946\n",
      "Epoch 40/60\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0215 - acc: 0.9946\n",
      "Epoch 41/60\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0237 - acc: 0.9932\n",
      "Epoch 42/60\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0218 - acc: 0.9955\n",
      "Epoch 43/60\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0209 - acc: 0.9946\n",
      "Epoch 44/60\n",
      "2205/2205 [==============================] - 12s 6ms/step - loss: 0.0227 - acc: 0.9941\n",
      "Epoch 45/60\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0204 - acc: 0.9946\n",
      "Epoch 46/60\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0225 - acc: 0.9937\n",
      "Epoch 47/60\n",
      "2205/2205 [==============================] - 12s 5ms/step - loss: 0.0217 - acc: 0.9959\n",
      "Epoch 48/60\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0211 - acc: 0.9946\n",
      "Epoch 49/60\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0224 - acc: 0.9932\n",
      "Epoch 50/60\n",
      "2205/2205 [==============================] - 12s 5ms/step - loss: 0.0227 - acc: 0.9937\n",
      "Epoch 51/60\n",
      "2205/2205 [==============================] - 12s 5ms/step - loss: 0.0224 - acc: 0.9941\n",
      "Epoch 52/60\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0202 - acc: 0.9955\n",
      "Epoch 53/60\n",
      "2205/2205 [==============================] - 12s 6ms/step - loss: 0.0195 - acc: 0.9955: 0s - loss: 0.0195 - acc: 0.995\n",
      "Epoch 54/60\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0205 - acc: 0.9937\n",
      "Epoch 55/60\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0215 - acc: 0.9932\n",
      "Epoch 56/60\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0205 - acc: 0.9932\n",
      "Epoch 57/60\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0187 - acc: 0.9955\n",
      "Epoch 58/60\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0213 - acc: 0.9946\n",
      "Epoch 59/60\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0207 - acc: 0.9937\n",
      "Epoch 60/60\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0196 - acc: 0.9946\n",
      "2204/2204 [==============================] - 11s 5ms/step\n",
      "2205/2205 [==============================] - 4s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "  35/2204 [..............................] - ETA: 28:54 - loss: 0.6931 - acc: 0.4286"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.382850). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2204/2204 [==============================] - 45s 21ms/step - loss: 0.4872 - acc: 0.7831\n",
      "Epoch 2/100\n",
      "2204/2204 [==============================] - 12s 6ms/step - loss: 0.1868 - acc: 0.9378\n",
      "Epoch 3/100\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.1011 - acc: 0.9760\n",
      "Epoch 4/100\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0685 - acc: 0.9819\n",
      "Epoch 5/100\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0491 - acc: 0.9846\n",
      "Epoch 6/100\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0386 - acc: 0.9882\n",
      "Epoch 7/100\n",
      "2204/2204 [==============================] - 10s 5ms/step - loss: 0.0322 - acc: 0.9887\n",
      "Epoch 8/100\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0388 - acc: 0.9914\n",
      "Epoch 9/100\n",
      "2204/2204 [==============================] - 12s 5ms/step - loss: 0.0286 - acc: 0.9914\n",
      "Epoch 10/100\n",
      "2204/2204 [==============================] - 12s 5ms/step - loss: 0.0269 - acc: 0.9923\n",
      "Epoch 11/100\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0263 - acc: 0.9918\n",
      "Epoch 12/100\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0259 - acc: 0.9909\n",
      "Epoch 13/100\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0237 - acc: 0.9909\n",
      "Epoch 14/100\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0237 - acc: 0.9914\n",
      "Epoch 15/100\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0218 - acc: 0.9923\n",
      "Epoch 16/100\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0203 - acc: 0.9923\n",
      "Epoch 17/100\n",
      "2204/2204 [==============================] - 12s 5ms/step - loss: 0.0214 - acc: 0.9927\n",
      "Epoch 18/100\n",
      "2204/2204 [==============================] - 12s 5ms/step - loss: 0.0229 - acc: 0.9927\n",
      "Epoch 19/100\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0206 - acc: 0.9932: 1s -\n",
      "Epoch 20/100\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0271 - acc: 0.9914\n",
      "Epoch 21/100\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0188 - acc: 0.9932\n",
      "Epoch 22/100\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0192 - acc: 0.9927\n",
      "Epoch 23/100\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0181 - acc: 0.9936: 1s - los\n",
      "Epoch 24/100\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0219 - acc: 0.9923\n",
      "Epoch 25/100\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0211 - acc: 0.9914\n",
      "Epoch 26/100\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0197 - acc: 0.9927\n",
      "Epoch 27/100\n",
      "2204/2204 [==============================] - 12s 5ms/step - loss: 0.0220 - acc: 0.9923\n",
      "Epoch 28/100\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0185 - acc: 0.9923\n",
      "Epoch 29/100\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0164 - acc: 0.9936\n",
      "Epoch 30/100\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0172 - acc: 0.9936\n",
      "Epoch 31/100\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0186 - acc: 0.9941: 1s - loss:\n",
      "Epoch 32/100\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0198 - acc: 0.9923\n",
      "Epoch 33/100\n",
      "2204/2204 [==============================] - 12s 5ms/step - loss: 0.0181 - acc: 0.9927\n",
      "Epoch 34/100\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0194 - acc: 0.9923\n",
      "Epoch 35/100\n",
      "2204/2204 [==============================] - 12s 6ms/step - loss: 0.0194 - acc: 0.9923\n",
      "Epoch 36/100\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0216 - acc: 0.9914\n",
      "Epoch 37/100\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0185 - acc: 0.9927\n",
      "Epoch 38/100\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0193 - acc: 0.9932\n",
      "Epoch 39/100\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0177 - acc: 0.9936\n",
      "Epoch 40/100\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0188 - acc: 0.9936\n",
      "Epoch 41/100\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0165 - acc: 0.9941: 0s - loss: 0.0166 - acc: 0.99\n",
      "Epoch 42/100\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0260 - acc: 0.9909\n",
      "Epoch 43/100\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0202 - acc: 0.9923\n",
      "Epoch 44/100\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0150 - acc: 0.9936\n",
      "Epoch 45/100\n",
      "2204/2204 [==============================] - 12s 6ms/step - loss: 0.0210 - acc: 0.9923\n",
      "Epoch 46/100\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0173 - acc: 0.9941\n",
      "Epoch 47/100\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0166 - acc: 0.9936:\n",
      "Epoch 48/100\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0221 - acc: 0.9918: 2s - loss: 0 - ETA: 1s \n",
      "Epoch 49/100\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0261 - acc: 0.9918\n",
      "Epoch 50/100\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0185 - acc: 0.9932\n",
      "Epoch 51/100\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0179 - acc: 0.9936\n",
      "Epoch 52/100\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0204 - acc: 0.9932\n",
      "Epoch 53/100\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0253 - acc: 0.9927: 0s - loss: 0.0262 - \n",
      "Epoch 54/100\n",
      "2204/2204 [==============================] - 12s 6ms/step - loss: 0.0164 - acc: 0.9927\n",
      "Epoch 55/100\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0183 - acc: 0.9918\n",
      "Epoch 56/100\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0257 - acc: 0.9932\n",
      "Epoch 57/100\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0252 - acc: 0.9932\n",
      "Epoch 58/100\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0214 - acc: 0.9923\n",
      "Epoch 59/100\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0167 - acc: 0.9932\n",
      "Epoch 60/100\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0173 - acc: 0.9923\n",
      "Epoch 61/100\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0225 - acc: 0.9923\n",
      "Epoch 62/100\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0161 - acc: 0.9941\n",
      "Epoch 63/100\n",
      "2204/2204 [==============================] - 13s 6ms/step - loss: 0.0182 - acc: 0.9923\n",
      "Epoch 64/100\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0183 - acc: 0.9936\n",
      "Epoch 65/100\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0180 - acc: 0.9932\n",
      "Epoch 66/100\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0172 - acc: 0.9936: 1s -\n",
      "Epoch 67/100\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0161 - acc: 0.9936\n",
      "Epoch 68/100\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0186 - acc: 0.9923\n",
      "Epoch 69/100\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0181 - acc: 0.9918\n",
      "Epoch 70/100\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0200 - acc: 0.9932\n",
      "Epoch 71/100\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0162 - acc: 0.9941\n",
      "Epoch 72/100\n",
      "2204/2204 [==============================] - 12s 5ms/step - loss: 0.0176 - acc: 0.9923\n",
      "Epoch 73/100\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0179 - acc: 0.9936\n",
      "Epoch 74/100\n",
      "2204/2204 [==============================] - 12s 5ms/step - loss: 0.0163 - acc: 0.9923\n",
      "Epoch 75/100\n",
      "2204/2204 [==============================] - 12s 5ms/step - loss: 0.0167 - acc: 0.9936\n",
      "Epoch 76/100\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0191 - acc: 0.9927\n",
      "Epoch 77/100\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0184 - acc: 0.9927\n",
      "Epoch 78/100\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0168 - acc: 0.9936\n",
      "Epoch 79/100\n",
      "2204/2204 [==============================] - 12s 5ms/step - loss: 0.0172 - acc: 0.9927\n",
      "Epoch 80/100\n",
      "2204/2204 [==============================] - 12s 6ms/step - loss: 0.0164 - acc: 0.9936: 0s - loss: 0.0165 - acc: 0.9\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0206 - acc: 0.9927: 0s - loss: 0.0207 - acc: \n",
      "Epoch 82/100\n",
      "2204/2204 [==============================] - 10s 5ms/step - loss: 0.0178 - acc: 0.9932\n",
      "Epoch 83/100\n",
      "2204/2204 [==============================] - 10s 5ms/step - loss: 0.0230 - acc: 0.9914\n",
      "Epoch 84/100\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0172 - acc: 0.9936\n",
      "Epoch 85/100\n",
      "2204/2204 [==============================] - 10s 5ms/step - loss: 0.0170 - acc: 0.9941\n",
      "Epoch 86/100\n",
      "2204/2204 [==============================] - 10s 5ms/step - loss: 0.0172 - acc: 0.9932: 0s - loss: 0.0167 \n",
      "Epoch 87/100\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0202 - acc: 0.9918\n",
      "Epoch 88/100\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0167 - acc: 0.9932\n",
      "Epoch 89/100\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0170 - acc: 0.9932: 1s - loss\n",
      "Epoch 90/100\n",
      "2204/2204 [==============================] - 12s 6ms/step - loss: 0.0180 - acc: 0.9932\n",
      "Epoch 91/100\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0152 - acc: 0.9941 - ETA: 1s - loss: 0.0156 - acc: - ETA: 1s - loss: 0.\n",
      "Epoch 92/100\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0173 - acc: 0.9927: 1s - loss: 0.\n",
      "Epoch 93/100\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0173 - acc: 0.9936: 1s - los\n",
      "Epoch 94/100\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0186 - acc: 0.9927\n",
      "Epoch 95/100\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0216 - acc: 0.9927\n",
      "Epoch 96/100\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0174 - acc: 0.9936\n",
      "Epoch 97/100\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0166 - acc: 0.9936\n",
      "Epoch 98/100\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0170 - acc: 0.9936\n",
      "Epoch 99/100\n",
      "2204/2204 [==============================] - 12s 5ms/step - loss: 0.0171 - acc: 0.9936\n",
      "Epoch 100/100\n",
      "2204/2204 [==============================] - 11s 5ms/step - loss: 0.0170 - acc: 0.9932\n",
      "2205/2205 [==============================] - 10s 5ms/step\n",
      "2204/2204 [==============================] - 6s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2205/2205 [==============================] - 51s 23ms/step - loss: 0.4377 - acc: 0.8345\n",
      "Epoch 2/100\n",
      "2205/2205 [==============================] - 12s 5ms/step - loss: 0.1508 - acc: 0.9551\n",
      "Epoch 3/100\n",
      "2205/2205 [==============================] - 12s 5ms/step - loss: 0.0829 - acc: 0.9741\n",
      "Epoch 4/100\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0772 - acc: 0.9828\n",
      "Epoch 5/100\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0523 - acc: 0.9878\n",
      "Epoch 6/100\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0434 - acc: 0.9905\n",
      "Epoch 7/100\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0370 - acc: 0.9923: 0s - loss: 0.0370 - acc: 0.992\n",
      "Epoch 8/100\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0326 - acc: 0.9927\n",
      "Epoch 9/100\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0298 - acc: 0.9937: 1s -\n",
      "Epoch 10/100\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0268 - acc: 0.9941: 1s - lo\n",
      "Epoch 11/100\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0274 - acc: 0.9937\n",
      "Epoch 12/100\n",
      "2205/2205 [==============================] - 12s 5ms/step - loss: 0.0333 - acc: 0.9923\n",
      "Epoch 13/100\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0226 - acc: 0.9941\n",
      "Epoch 14/100\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0244 - acc: 0.9950: 1s - los\n",
      "Epoch 15/100\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0249 - acc: 0.9941: 9s - l - - ETA: 1s - loss: 0\n",
      "Epoch 16/100\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0210 - acc: 0.9946\n",
      "Epoch 17/100\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0209 - acc: 0.9946\n",
      "Epoch 18/100\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0213 - acc: 0.9932: 1s -\n",
      "Epoch 19/100\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0218 - acc: 0.9946\n",
      "Epoch 20/100\n",
      "2205/2205 [==============================] - 12s 5ms/step - loss: 0.0235 - acc: 0.9937: 2s - loss: 0.0256 - acc: 0 - \n",
      "Epoch 21/100\n",
      "2205/2205 [==============================] - 13s 6ms/step - loss: 0.0204 - acc: 0.9937\n",
      "Epoch 22/100\n",
      "2205/2205 [==============================] - 12s 5ms/step - loss: 0.0200 - acc: 0.9955\n",
      "Epoch 23/100\n",
      "2205/2205 [==============================] - 12s 5ms/step - loss: 0.0215 - acc: 0.9941\n",
      "Epoch 24/100\n",
      "2205/2205 [==============================] - 12s 5ms/step - loss: 0.0199 - acc: 0.9959\n",
      "Epoch 25/100\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0205 - acc: 0.9946\n",
      "Epoch 26/100\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0203 - acc: 0.9941\n",
      "Epoch 27/100\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0221 - acc: 0.9927\n",
      "Epoch 28/100\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0196 - acc: 0.9955\n",
      "Epoch 29/100\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0209 - acc: 0.9946\n",
      "Epoch 30/100\n",
      "2205/2205 [==============================] - 12s 5ms/step - loss: 0.0195 - acc: 0.9950\n",
      "Epoch 31/100\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0179 - acc: 0.9950\n",
      "Epoch 32/100\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0199 - acc: 0.9955\n",
      "Epoch 33/100\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0204 - acc: 0.9941\n",
      "Epoch 34/100\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0199 - acc: 0.9937\n",
      "Epoch 35/100\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0210 - acc: 0.9950\n",
      "Epoch 36/100\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0187 - acc: 0.9955\n",
      "Epoch 37/100\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0207 - acc: 0.9937\n",
      "Epoch 38/100\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0197 - acc: 0.9946\n",
      "Epoch 39/100\n",
      "2205/2205 [==============================] - 12s 5ms/step - loss: 0.0160 - acc: 0.9959\n",
      "Epoch 40/100\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0250 - acc: 0.9941: 1s - loss: 0.\n",
      "Epoch 41/100\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0253 - acc: 0.9937\n",
      "Epoch 42/100\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0219 - acc: 0.9946: 0s - loss: 0.0220 - acc: 0.994\n",
      "Epoch 43/100\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0191 - acc: 0.9946\n",
      "Epoch 44/100\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0213 - acc: 0.9946: 1s - loss: 0\n",
      "Epoch 45/100\n",
      "2205/2205 [==============================] - 12s 5ms/step - loss: 0.0206 - acc: 0.9946: 1s - loss: 0.022\n",
      "Epoch 46/100\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0238 - acc: 0.9937\n",
      "Epoch 47/100\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0186 - acc: 0.9946\n",
      "Epoch 48/100\n",
      "2205/2205 [==============================] - 12s 5ms/step - loss: 0.0188 - acc: 0.9950: 1s -\n",
      "Epoch 49/100\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0221 - acc: 0.9946\n",
      "Epoch 50/100\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0228 - acc: 0.9932\n",
      "Epoch 51/100\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0186 - acc: 0.9955\n",
      "Epoch 52/100\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0180 - acc: 0.9959\n",
      "Epoch 53/100\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0222 - acc: 0.9937\n",
      "Epoch 54/100\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0195 - acc: 0.9950\n",
      "Epoch 55/100\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0197 - acc: 0.9946\n",
      "Epoch 56/100\n",
      "2205/2205 [==============================] - 12s 5ms/step - loss: 0.0204 - acc: 0.9946\n",
      "Epoch 57/100\n",
      "2205/2205 [==============================] - 12s 6ms/step - loss: 0.0188 - acc: 0.9955\n",
      "Epoch 58/100\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0186 - acc: 0.9959: 0s - loss: 0.0187 - acc: 0.9\n",
      "Epoch 59/100\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0183 - acc: 0.9955\n",
      "Epoch 60/100\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0182 - acc: 0.9959\n",
      "Epoch 61/100\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0188 - acc: 0.9955: 1s - loss: 0.0216 - a - ETA: 0s - loss: 0.0205\n",
      "Epoch 62/100\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0173 - acc: 0.9955\n",
      "Epoch 63/100\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0220 - acc: 0.9946\n",
      "Epoch 64/100\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0193 - acc: 0.9955\n",
      "Epoch 65/100\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0188 - acc: 0.9955\n",
      "Epoch 66/100\n",
      "2205/2205 [==============================] - 13s 6ms/step - loss: 0.0210 - acc: 0.9946\n",
      "Epoch 67/100\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0183 - acc: 0.9955\n",
      "Epoch 68/100\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0176 - acc: 0.9955: 0s - loss: 0.0184 - \n",
      "Epoch 69/100\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0202 - acc: 0.9950\n",
      "Epoch 70/100\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0186 - acc: 0.9955\n",
      "Epoch 71/100\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0180 - acc: 0.9950\n",
      "Epoch 72/100\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0195 - acc: 0.9946\n",
      "Epoch 73/100\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0243 - acc: 0.9946\n",
      "Epoch 74/100\n",
      "2205/2205 [==============================] - 12s 5ms/step - loss: 0.0177 - acc: 0.9955\n",
      "Epoch 75/100\n",
      "2205/2205 [==============================] - 12s 5ms/step - loss: 0.0186 - acc: 0.9955\n",
      "Epoch 76/100\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0187 - acc: 0.9950\n",
      "Epoch 77/100\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0192 - acc: 0.9946\n",
      "Epoch 78/100\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0183 - acc: 0.9950\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2205/2205 [==============================] - 10s 5ms/step - loss: 0.0188 - acc: 0.9946\n",
      "Epoch 80/100\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0178 - acc: 0.9950\n",
      "Epoch 81/100\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0186 - acc: 0.9955\n",
      "Epoch 82/100\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0188 - acc: 0.9950\n",
      "Epoch 83/100\n",
      "2205/2205 [==============================] - 12s 5ms/step - loss: 0.0190 - acc: 0.9955\n",
      "Epoch 84/100\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0174 - acc: 0.9955\n",
      "Epoch 85/100\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0178 - acc: 0.9955\n",
      "Epoch 86/100\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0190 - acc: 0.9950\n",
      "Epoch 87/100\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0190 - acc: 0.9955: 0s - loss: 0.0200 -\n",
      "Epoch 88/100\n",
      "2205/2205 [==============================] - 12s 5ms/step - loss: 0.0178 - acc: 0.9950: 1s - lo\n",
      "Epoch 89/100\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0195 - acc: 0.9946\n",
      "Epoch 90/100\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0179 - acc: 0.9950: 0s - loss: 0.0184 - ac\n",
      "Epoch 91/100\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0197 - acc: 0.9950\n",
      "Epoch 92/100\n",
      "2205/2205 [==============================] - 12s 5ms/step - loss: 0.0176 - acc: 0.9955: 0s - loss: 0.\n",
      "Epoch 93/100\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0184 - acc: 0.9950\n",
      "Epoch 94/100\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0208 - acc: 0.9946\n",
      "Epoch 95/100\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0181 - acc: 0.9955\n",
      "Epoch 96/100\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0187 - acc: 0.9955\n",
      "Epoch 97/100\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0175 - acc: 0.9959\n",
      "Epoch 98/100\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0235 - acc: 0.9932\n",
      "Epoch 99/100\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0179 - acc: 0.9955\n",
      "Epoch 100/100\n",
      "2205/2205 [==============================] - 11s 5ms/step - loss: 0.0244 - acc: 0.9941\n",
      "2204/2204 [==============================] - 11s 5ms/step\n",
      "2205/2205 [==============================] - 6s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2204/2204 [==============================] - 25s 11ms/step - loss: 0.5368 - acc: 0.7713\n",
      "Epoch 2/20\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.1767 - acc: 0.9446\n",
      "Epoch 3/20\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0920 - acc: 0.9732\n",
      "Epoch 4/20\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0617 - acc: 0.9819\n",
      "Epoch 5/20\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0514 - acc: 0.9841\n",
      "Epoch 6/20\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0399 - acc: 0.9868\n",
      "Epoch 7/20\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0332 - acc: 0.9868\n",
      "Epoch 8/20\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0357 - acc: 0.9846\n",
      "Epoch 9/20\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0269 - acc: 0.9923\n",
      "Epoch 10/20\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0288 - acc: 0.9905\n",
      "Epoch 11/20\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0253 - acc: 0.9905A: 0s - loss: 0.0258 - acc: 0\n",
      "Epoch 12/20\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0247 - acc: 0.9918\n",
      "Epoch 13/20\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0222 - acc: 0.9927\n",
      "Epoch 14/20\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0214 - acc: 0.9918\n",
      "Epoch 15/20\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0219 - acc: 0.9918\n",
      "Epoch 16/20\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0200 - acc: 0.9932\n",
      "Epoch 17/20\n",
      "2204/2204 [==============================] - 8s 3ms/step - loss: 0.0179 - acc: 0.9941\n",
      "Epoch 18/20\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0193 - acc: 0.9936\n",
      "Epoch 19/20\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0199 - acc: 0.9932\n",
      "Epoch 20/20\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0196 - acc: 0.9936\n",
      "2205/2205 [==============================] - 8s 3ms/step\n",
      "2204/2204 [==============================] - 4s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2205/2205 [==============================] - 59s 27ms/step - loss: 0.5605 - acc: 0.7070\n",
      "Epoch 2/20\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.3105 - acc: 0.8762\n",
      "Epoch 3/20\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.1692 - acc: 0.9710A: 0s - loss: 0.1711 \n",
      "Epoch 4/20\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0915 - acc: 0.9837A: 0s - loss: 0.0916 - acc: 0.983 - ETA: 0s - loss: 0.0919 - acc: 0.983\n",
      "Epoch 5/20\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0565 - acc: 0.9891\n",
      "Epoch 6/20\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0419 - acc: 0.9918\n",
      "Epoch 7/20\n",
      "2205/2205 [==============================] - 8s 4ms/step - loss: 0.0349 - acc: 0.9900\n",
      "Epoch 8/20\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0295 - acc: 0.9918\n",
      "Epoch 9/20\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0247 - acc: 0.9927\n",
      "Epoch 10/20\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0193 - acc: 0.9937A: 0s - loss: 0.0189 - acc:\n",
      "Epoch 11/20\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0223 - acc: 0.9900\n",
      "Epoch 12/20\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0161 - acc: 0.9946\n",
      "Epoch 13/20\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0214 - acc: 0.9914\n",
      "Epoch 14/20\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0172 - acc: 0.9941\n",
      "Epoch 15/20\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0163 - acc: 0.9955\n",
      "Epoch 16/20\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0171 - acc: 0.9932\n",
      "Epoch 17/20\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0207 - acc: 0.9932\n",
      "Epoch 18/20\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0142 - acc: 0.9950\n",
      "Epoch 19/20\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0257 - acc: 0.9923\n",
      "Epoch 20/20\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0176 - acc: 0.9927\n",
      "2204/2204 [==============================] - 15s 7ms/step\n",
      "2205/2205 [==============================] - 4s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "2204/2204 [==============================] - 27s 12ms/step - loss: 0.5575 - acc: 0.7427\n",
      "Epoch 2/40\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.1951 - acc: 0.9351A: 0s - loss: 0.1990 - acc\n",
      "Epoch 3/40\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.1088 - acc: 0.9691\n",
      "Epoch 4/40\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0770 - acc: 0.9764\n",
      "Epoch 5/40\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0556 - acc: 0.9837\n",
      "Epoch 6/40\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0450 - acc: 0.9873\n",
      "Epoch 7/40\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0354 - acc: 0.9891\n",
      "Epoch 8/40\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0340 - acc: 0.9868\n",
      "Epoch 9/40\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0289 - acc: 0.9905\n",
      "Epoch 10/40\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0270 - acc: 0.9927\n",
      "Epoch 11/40\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0398 - acc: 0.9900A: 3s - loss: 0.\n",
      "Epoch 12/40\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0376 - acc: 0.9909\n",
      "Epoch 13/40\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0264 - acc: 0.9909\n",
      "Epoch 14/40\n",
      "2204/2204 [==============================] - 6s 3ms/step - loss: 0.0217 - acc: 0.9927A: 1s - l\n",
      "Epoch 15/40\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0288 - acc: 0.9932\n",
      "Epoch 16/40\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0210 - acc: 0.9918\n",
      "Epoch 17/40\n",
      "2204/2204 [==============================] - 8s 4ms/step - loss: 0.0220 - acc: 0.9932\n",
      "Epoch 18/40\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0212 - acc: 0.9932\n",
      "Epoch 19/40\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0277 - acc: 0.9927A: 1\n",
      "Epoch 20/40\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0203 - acc: 0.9936\n",
      "Epoch 21/40\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0262 - acc: 0.9936\n",
      "Epoch 22/40\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0186 - acc: 0.9941\n",
      "Epoch 23/40\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0205 - acc: 0.9941\n",
      "Epoch 24/40\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0187 - acc: 0.9932\n",
      "Epoch 25/40\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0244 - acc: 0.9923\n",
      "Epoch 26/40\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0175 - acc: 0.9932\n",
      "Epoch 27/40\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0166 - acc: 0.9946A: 6s - loss: 0. -  - ETA: 0s - loss: 0.0166 - acc: 0.\n",
      "Epoch 28/40\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0198 - acc: 0.9927\n",
      "Epoch 29/40\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0165 - acc: 0.9941\n",
      "Epoch 30/40\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0199 - acc: 0.9932A: 0s - loss: 0.0193 \n",
      "Epoch 31/40\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0192 - acc: 0.9927A: 1s - \n",
      "Epoch 32/40\n",
      "2204/2204 [==============================] - 8s 3ms/step - loss: 0.0180 - acc: 0.9927\n",
      "Epoch 33/40\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0168 - acc: 0.9936\n",
      "Epoch 34/40\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0159 - acc: 0.9932\n",
      "Epoch 35/40\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0168 - acc: 0.9932A: 0s - loss: 0.0165 - acc: \n",
      "Epoch 36/40\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0174 - acc: 0.9941\n",
      "Epoch 37/40\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0179 - acc: 0.9941\n",
      "Epoch 38/40\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0172 - acc: 0.9927A: 1s - lo - ETA: 0s - loss: 0.0172 - acc: 0.992\n",
      "Epoch 39/40\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0171 - acc: 0.9932A: 0s - loss: 0.0176\n",
      "Epoch 40/40\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0178 - acc: 0.9923\n",
      "2205/2205 [==============================] - 7s 3ms/step\n",
      "2204/2204 [==============================] - 3s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "2205/2205 [==============================] - 27s 12ms/step - loss: 0.5817 - acc: 0.7070 5s - loss\n",
      "Epoch 2/40\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.2643 - acc: 0.9088\n",
      "Epoch 3/40\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.1159 - acc: 0.9773\n",
      "Epoch 4/40\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0792 - acc: 0.9873A: 0s - loss: 0.0752 - ac\n",
      "Epoch 5/40\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0616 - acc: 0.9887\n",
      "Epoch 6/40\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0514 - acc: 0.9909\n",
      "Epoch 7/40\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0438 - acc: 0.9905\n",
      "Epoch 8/40\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0569 - acc: 0.9864\n",
      "Epoch 9/40\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0420 - acc: 0.9932\n",
      "Epoch 10/40\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0438 - acc: 0.9909\n",
      "Epoch 11/40\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0432 - acc: 0.9909\n",
      "Epoch 12/40\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0398 - acc: 0.9937\n",
      "Epoch 13/40\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0398 - acc: 0.9923A: 0s - loss: 0.0417 - acc:\n",
      "Epoch 14/40\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0391 - acc: 0.9941\n",
      "Epoch 15/40\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0386 - acc: 0.9914\n",
      "Epoch 16/40\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0361 - acc: 0.9918\n",
      "Epoch 17/40\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0377 - acc: 0.9918\n",
      "Epoch 18/40\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0341 - acc: 0.9937\n",
      "Epoch 19/40\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0358 - acc: 0.9937A\n",
      "Epoch 20/40\n",
      "2205/2205 [==============================] - 8s 3ms/step - loss: 0.0366 - acc: 0.9923\n",
      "Epoch 21/40\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0380 - acc: 0.9937\n",
      "Epoch 22/40\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0366 - acc: 0.9923A: 2s - loss: 0.0389 - acc:\n",
      "Epoch 23/40\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0350 - acc: 0.9932A: 0s - loss: 0.0351 - ac\n",
      "Epoch 24/40\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0327 - acc: 0.9941\n",
      "Epoch 25/40\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0324 - acc: 0.9941\n",
      "Epoch 26/40\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0329 - acc: 0.9937\n",
      "Epoch 27/40\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0317 - acc: 0.9950A: 0s - loss: 0.0341 \n",
      "Epoch 28/40\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0286 - acc: 0.9950A: 1s\n",
      "Epoch 29/40\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0321 - acc: 0.9941\n",
      "Epoch 30/40\n",
      "2205/2205 [==============================] - 6s 3ms/step - loss: 0.0291 - acc: 0.9946\n",
      "Epoch 31/40\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0292 - acc: 0.9950\n",
      "Epoch 32/40\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0304 - acc: 0.9937\n",
      "Epoch 33/40\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0322 - acc: 0.9927A: 1s - - ETA: 0s - loss: 0.0336 - acc: \n",
      "Epoch 34/40\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0311 - acc: 0.9923\n",
      "Epoch 35/40\n",
      "2205/2205 [==============================] - 8s 4ms/step - loss: 0.0305 - acc: 0.9946\n",
      "Epoch 36/40\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0313 - acc: 0.9941\n",
      "Epoch 37/40\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0355 - acc: 0.9918\n",
      "Epoch 38/40\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0310 - acc: 0.9946\n",
      "Epoch 39/40\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0280 - acc: 0.9955\n",
      "Epoch 40/40\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0296 - acc: 0.9941\n",
      "2204/2204 [==============================] - 9s 4ms/step\n",
      "2205/2205 [==============================] - 4s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "  50/2204 [..............................] - ETA: 14:00 - loss: 0.6931 - acc: 0.5800"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.228082). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2204/2204 [==============================] - 30s 14ms/step - loss: 0.5840 - acc: 0.7459\n",
      "Epoch 2/60\n",
      "2204/2204 [==============================] - 8s 3ms/step - loss: 0.2414 - acc: 0.9310\n",
      "Epoch 3/60\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.1246 - acc: 0.9655\n",
      "Epoch 4/60\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0973 - acc: 0.9719A: 1s - loss\n",
      "Epoch 5/60\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0752 - acc: 0.9823\n",
      "Epoch 6/60\n",
      "2204/2204 [==============================] - 8s 3ms/step - loss: 0.0553 - acc: 0.9855\n",
      "Epoch 7/60\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0476 - acc: 0.9864\n",
      "Epoch 8/60\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0425 - acc: 0.9864\n",
      "Epoch 9/60\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0400 - acc: 0.9891\n",
      "Epoch 10/60\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0375 - acc: 0.9877\n",
      "Epoch 11/60\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0326 - acc: 0.9900\n",
      "Epoch 12/60\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0314 - acc: 0.9891A: 1s\n",
      "Epoch 13/60\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0286 - acc: 0.9905\n",
      "Epoch 14/60\n",
      "2204/2204 [==============================] - 8s 4ms/step - loss: 0.0297 - acc: 0.9900\n",
      "Epoch 15/60\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0275 - acc: 0.9918\n",
      "Epoch 16/60\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0249 - acc: 0.9927\n",
      "Epoch 17/60\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0245 - acc: 0.9923\n",
      "Epoch 18/60\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0260 - acc: 0.9923A: 1s - loss: 0.\n",
      "Epoch 19/60\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0234 - acc: 0.9923\n",
      "Epoch 20/60\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0242 - acc: 0.9918\n",
      "Epoch 21/60\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0221 - acc: 0.9914\n",
      "Epoch 22/60\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0238 - acc: 0.9923A: 3s - loss: 0.01 - ETA\n",
      "Epoch 23/60\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0256 - acc: 0.9914\n",
      "Epoch 24/60\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0202 - acc: 0.9941\n",
      "Epoch 25/60\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0214 - acc: 0.9936\n",
      "Epoch 26/60\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0230 - acc: 0.9927\n",
      "Epoch 27/60\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0187 - acc: 0.9941\n",
      "Epoch 28/60\n",
      "2204/2204 [==============================] - 8s 4ms/step - loss: 0.0208 - acc: 0.9932\n",
      "Epoch 29/60\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0211 - acc: 0.9932\n",
      "Epoch 30/60\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0195 - acc: 0.9941\n",
      "Epoch 31/60\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0204 - acc: 0.9936\n",
      "Epoch 32/60\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0199 - acc: 0.9941\n",
      "Epoch 33/60\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0193 - acc: 0.9932\n",
      "Epoch 34/60\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0261 - acc: 0.9918\n",
      "Epoch 35/60\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0214 - acc: 0.9923\n",
      "Epoch 36/60\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0171 - acc: 0.9941\n",
      "Epoch 37/60\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0193 - acc: 0.9941\n",
      "Epoch 38/60\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0181 - acc: 0.9946\n",
      "Epoch 39/60\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0214 - acc: 0.9941\n",
      "Epoch 40/60\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0201 - acc: 0.9927\n",
      "Epoch 41/60\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0206 - acc: 0.9936\n",
      "Epoch 42/60\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0198 - acc: 0.9946\n",
      "Epoch 43/60\n",
      "2204/2204 [==============================] - 8s 4ms/step - loss: 0.0218 - acc: 0.9932\n",
      "Epoch 44/60\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0192 - acc: 0.9927\n",
      "Epoch 45/60\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0180 - acc: 0.9936\n",
      "Epoch 46/60\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0170 - acc: 0.9941A: 3s - loss: 0\n",
      "Epoch 47/60\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0167 - acc: 0.9950\n",
      "Epoch 48/60\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0181 - acc: 0.9927\n",
      "Epoch 49/60\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0174 - acc: 0.9941\n",
      "Epoch 50/60\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0186 - acc: 0.9936\n",
      "Epoch 51/60\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0169 - acc: 0.9941A: 1s - loss: 0.01\n",
      "Epoch 52/60\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0178 - acc: 0.9941A: 1s\n",
      "Epoch 53/60\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0256 - acc: 0.9936A: 1s - loss: 0.0288 - acc: 0.992 - ETA: 0s - loss: 0.028\n",
      "Epoch 54/60\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0186 - acc: 0.9936\n",
      "Epoch 55/60\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0174 - acc: 0.9936\n",
      "Epoch 56/60\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0200 - acc: 0.9932\n",
      "Epoch 57/60\n",
      "2204/2204 [==============================] - 8s 4ms/step - loss: 0.0197 - acc: 0.9918\n",
      "Epoch 58/60\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0174 - acc: 0.9941\n",
      "Epoch 59/60\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0160 - acc: 0.9946\n",
      "Epoch 60/60\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0195 - acc: 0.9927\n",
      "2205/2205 [==============================] - 12s 5ms/step\n",
      "2204/2204 [==============================] - 6s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "2205/2205 [==============================] - 31s 14ms/step - loss: 0.5610 - acc: 0.7415\n",
      "Epoch 2/60\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.2446 - acc: 0.9079\n",
      "Epoch 3/60\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.1347 - acc: 0.9438\n",
      "Epoch 4/60\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0878 - acc: 0.9769\n",
      "Epoch 5/60\n",
      "2205/2205 [==============================] - 8s 3ms/step - loss: 0.0728 - acc: 0.9837\n",
      "Epoch 6/60\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0606 - acc: 0.9855\n",
      "Epoch 7/60\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0550 - acc: 0.9873\n",
      "Epoch 8/60\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0489 - acc: 0.9900\n",
      "Epoch 9/60\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0404 - acc: 0.9927\n",
      "Epoch 10/60\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0374 - acc: 0.9927\n",
      "Epoch 11/60\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0364 - acc: 0.9937\n",
      "Epoch 12/60\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0350 - acc: 0.9937\n",
      "Epoch 13/60\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0336 - acc: 0.9946\n",
      "Epoch 14/60\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0354 - acc: 0.9941A: 3s  - ETA: 1\n",
      "Epoch 15/60\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0459 - acc: 0.9923\n",
      "Epoch 16/60\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0447 - acc: 0.9941\n",
      "Epoch 17/60\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0485 - acc: 0.9937\n",
      "Epoch 18/60\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0692 - acc: 0.9887\n",
      "Epoch 19/60\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0346 - acc: 0.9927\n",
      "Epoch 20/60\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0317 - acc: 0.9932\n",
      "Epoch 21/60\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0327 - acc: 0.9941\n",
      "Epoch 22/60\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0310 - acc: 0.9946\n",
      "Epoch 23/60\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0285 - acc: 0.9950\n",
      "Epoch 24/60\n",
      "2205/2205 [==============================] - 8s 3ms/step - loss: 0.0290 - acc: 0.9950\n",
      "Epoch 25/60\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0281 - acc: 0.9950\n",
      "Epoch 26/60\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0270 - acc: 0.9941\n",
      "Epoch 27/60\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0271 - acc: 0.9946\n",
      "Epoch 28/60\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0253 - acc: 0.9937\n",
      "Epoch 29/60\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0297 - acc: 0.9932\n",
      "Epoch 30/60\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0262 - acc: 0.9937\n",
      "Epoch 31/60\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0260 - acc: 0.9950\n",
      "Epoch 32/60\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0276 - acc: 0.9950\n",
      "Epoch 33/60\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0257 - acc: 0.9946\n",
      "Epoch 34/60\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0263 - acc: 0.9950\n",
      "Epoch 35/60\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0250 - acc: 0.9937\n",
      "Epoch 36/60\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0256 - acc: 0.9941\n",
      "Epoch 37/60\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0261 - acc: 0.9927\n",
      "Epoch 38/60\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0242 - acc: 0.9946\n",
      "Epoch 39/60\n",
      "2205/2205 [==============================] - 8s 4ms/step - loss: 0.0243 - acc: 0.9959\n",
      "Epoch 40/60\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0256 - acc: 0.9937\n",
      "Epoch 41/60\n",
      "2205/2205 [==============================] - 8s 4ms/step - loss: 0.0238 - acc: 0.9937\n",
      "Epoch 42/60\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0231 - acc: 0.9946\n",
      "Epoch 43/60\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0251 - acc: 0.9946A: 0s - loss: 0.0266\n",
      "Epoch 44/60\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0247 - acc: 0.9941\n",
      "Epoch 45/60\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0222 - acc: 0.9937\n",
      "Epoch 46/60\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0236 - acc: 0.9946\n",
      "Epoch 47/60\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0256 - acc: 0.9937\n",
      "Epoch 48/60\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0226 - acc: 0.9932\n",
      "Epoch 49/60\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0230 - acc: 0.9941A: 0s - loss: 0.0229 - acc: 0.9\n",
      "Epoch 50/60\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0211 - acc: 0.9959\n",
      "Epoch 51/60\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0227 - acc: 0.9932\n",
      "Epoch 52/60\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0241 - acc: 0.9932\n",
      "Epoch 53/60\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0221 - acc: 0.9955A: 1s - loss: \n",
      "Epoch 54/60\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0228 - acc: 0.9932\n",
      "Epoch 55/60\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0284 - acc: 0.9950A: 1s\n",
      "Epoch 56/60\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0200 - acc: 0.9968\n",
      "Epoch 57/60\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0245 - acc: 0.9937\n",
      "Epoch 58/60\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0232 - acc: 0.9950\n",
      "Epoch 59/60\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0227 - acc: 0.9937A: 1s -\n",
      "Epoch 60/60\n",
      "2205/2205 [==============================] - 7s 3ms/step - loss: 0.0220 - acc: 0.9941\n",
      "2204/2204 [==============================] - 14s 6ms/step\n",
      "2205/2205 [==============================] - 6s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2204/2204 [==============================] - 28s 13ms/step - loss: 0.5440 - acc: 0.7895\n",
      "Epoch 2/100\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.1758 - acc: 0.9496\n",
      "Epoch 3/100\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0978 - acc: 0.9732A: 1s - loss: 0.104 - ETA: 0s - loss: 0.101\n",
      "Epoch 4/100\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0742 - acc: 0.9814\n",
      "Epoch 5/100\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0556 - acc: 0.9846\n",
      "Epoch 6/100\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0532 - acc: 0.9832\n",
      "Epoch 7/100\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0435 - acc: 0.9887\n",
      "Epoch 8/100\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0336 - acc: 0.9882\n",
      "Epoch 9/100\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0302 - acc: 0.9887\n",
      "Epoch 10/100\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0292 - acc: 0.9900\n",
      "Epoch 11/100\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0334 - acc: 0.9909\n",
      "Epoch 12/100\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0308 - acc: 0.9896\n",
      "Epoch 13/100\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0219 - acc: 0.9932\n",
      "Epoch 14/100\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0233 - acc: 0.9932A: 0s - loss: 0.0228 - acc: 0\n",
      "Epoch 15/100\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0210 - acc: 0.9936\n",
      "Epoch 16/100\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0206 - acc: 0.9927\n",
      "Epoch 17/100\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0198 - acc: 0.9932\n",
      "Epoch 18/100\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0196 - acc: 0.9927\n",
      "Epoch 19/100\n",
      "2204/2204 [==============================] - 8s 4ms/step - loss: 0.0176 - acc: 0.9941\n",
      "Epoch 20/100\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0187 - acc: 0.9941A: \n",
      "Epoch 21/100\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0187 - acc: 0.9923\n",
      "Epoch 22/100\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0258 - acc: 0.9927\n",
      "Epoch 23/100\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0178 - acc: 0.9932\n",
      "Epoch 24/100\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0171 - acc: 0.9927\n",
      "Epoch 25/100\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0185 - acc: 0.9927\n",
      "Epoch 26/100\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0191 - acc: 0.9932\n",
      "Epoch 27/100\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0173 - acc: 0.9946\n",
      "Epoch 28/100\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0163 - acc: 0.9932\n",
      "Epoch 29/100\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0189 - acc: 0.9941\n",
      "Epoch 30/100\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0156 - acc: 0.9932\n",
      "Epoch 31/100\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0158 - acc: 0.9936\n",
      "Epoch 32/100\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0182 - acc: 0.9927\n",
      "Epoch 33/100\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0165 - acc: 0.9932\n",
      "Epoch 34/100\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0163 - acc: 0.9927\n",
      "Epoch 35/100\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0167 - acc: 0.9941\n",
      "Epoch 36/100\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0162 - acc: 0.9946\n",
      "Epoch 37/100\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0177 - acc: 0.9927\n",
      "Epoch 38/100\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0167 - acc: 0.9927\n",
      "Epoch 39/100\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0167 - acc: 0.9936\n",
      "Epoch 40/100\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0183 - acc: 0.9936A: 1s - loss: \n",
      "Epoch 41/100\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0172 - acc: 0.9923\n",
      "Epoch 42/100\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0161 - acc: 0.9941\n",
      "Epoch 43/100\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0165 - acc: 0.9936\n",
      "Epoch 44/100\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0148 - acc: 0.9936A: 1s - los\n",
      "Epoch 45/100\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0177 - acc: 0.9923\n",
      "Epoch 46/100\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0177 - acc: 0.9941A:\n",
      "Epoch 47/100\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0156 - acc: 0.9941A: 1\n",
      "Epoch 48/100\n",
      "2204/2204 [==============================] - 8s 3ms/step - loss: 0.0158 - acc: 0.9932\n",
      "Epoch 49/100\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0168 - acc: 0.9941A: 4s\n",
      "Epoch 50/100\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0155 - acc: 0.9936\n",
      "Epoch 51/100\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0181 - acc: 0.9932\n",
      "Epoch 52/100\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0157 - acc: 0.9941\n",
      "Epoch 53/100\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0144 - acc: 0.9941\n",
      "Epoch 54/100\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0165 - acc: 0.9941A: 1s - loss: \n",
      "Epoch 55/100\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0151 - acc: 0.9941\n",
      "Epoch 56/100\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0166 - acc: 0.9936\n",
      "Epoch 57/100\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0147 - acc: 0.9936A: 1s - loss: 0.01\n",
      "Epoch 58/100\n",
      "2204/2204 [==============================] - ETA: 0s - loss: 0.0158 - acc: 0.995 - 7s 3ms/step - loss: 0.0157 - acc: 0.9950\n",
      "Epoch 59/100\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0169 - acc: 0.9932\n",
      "Epoch 60/100\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0152 - acc: 0.9936\n",
      "Epoch 61/100\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0154 - acc: 0.9941A: 6s - loss: 0.0112  - ETA: 2s - loss: 0.0187 - a\n",
      "Epoch 62/100\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0180 - acc: 0.9932\n",
      "Epoch 63/100\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0152 - acc: 0.9936\n",
      "Epoch 64/100\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0153 - acc: 0.9936\n",
      "Epoch 65/100\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0169 - acc: 0.9927\n",
      "Epoch 66/100\n",
      "2204/2204 [==============================] - 8s 4ms/step - loss: 0.0148 - acc: 0.9936A: 1s - l\n",
      "Epoch 67/100\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0240 - acc: 0.9932A: 0s - loss: 0.0250 - \n",
      "Epoch 68/100\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0163 - acc: 0.9941\n",
      "Epoch 69/100\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0166 - acc: 0.9936\n",
      "Epoch 70/100\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0158 - acc: 0.9936\n",
      "Epoch 71/100\n",
      "2204/2204 [==============================] - 8s 3ms/step - loss: 0.0155 - acc: 0.9946\n",
      "Epoch 72/100\n",
      "2204/2204 [==============================] - 8s 4ms/step - loss: 0.0151 - acc: 0.9941\n",
      "Epoch 73/100\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0150 - acc: 0.9946\n",
      "Epoch 74/100\n",
      "2204/2204 [==============================] - 8s 3ms/step - loss: 0.0146 - acc: 0.9941\n",
      "Epoch 75/100\n",
      "2204/2204 [==============================] - 8s 4ms/step - loss: 0.0167 - acc: 0.9936\n",
      "Epoch 76/100\n",
      "2204/2204 [==============================] - 9s 4ms/step - loss: 0.0152 - acc: 0.9941\n",
      "Epoch 77/100\n",
      "2204/2204 [==============================] - 7s 3ms/step - loss: 0.0157 - acc: 0.9946A:\n",
      "Epoch 78/100\n",
      "2204/2204 [==============================] - 8s 4ms/step - loss: 0.0156 - acc: 0.9932\n",
      "Epoch 79/100\n",
      " 790/2204 [=========>....................] - ETA: 5s - loss: 0.0167 - acc: 0.9937- ETA: 8"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santi\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:542: FutureWarning: From version 0.22, errors during fit will result in a cross validation score of NaN by default. Use error_score='raise' if you want an exception raised or error_score=np.nan to adopt the behavior from version 0.22.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[60982,8] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[Node: training_53/Adam/mul_2 = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](training_53/Adam/sub_14, training_53/Adam/gradients/dense_169/MatMul_grad/MatMul_1)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-0bace6dee086>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m                            \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m                            )\n\u001b[1;32m---> 26\u001b[1;33m \u001b[0mgrid_search\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    720\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1189\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1191\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    709\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 711\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    712\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 920\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    921\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    922\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    757\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    526\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 528\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    529\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, sample_weight, **kwargs)\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sample_weight'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 210\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mKerasClassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[0;32m    150\u001b[0m         \u001b[0mfit_args\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 152\u001b[1;33m         \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1382\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    517\u001b[0m             \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 519\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    520\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m     \u001b[1;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[60982,8] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[Node: training_53/Adam/mul_2 = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](training_53/Adam/sub_14, training_53/Adam/gradients/dense_169/MatMul_grad/MatMul_1)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n"
     ]
    }
   ],
   "source": [
    "def regresor_base(optimizer,activation):\n",
    "    modelo = Sequential()\n",
    "    modelo.add(Dense(units = 8, kernel_initializer = 'uniform', activation = activation, input_dim = 60982))\n",
    "    modelo.add(Dropout(p = 0.1))\n",
    "    modelo.add(Dense(units = 8, kernel_initializer = 'uniform', activation = activation))\n",
    "    modelo.add(Dropout(p = 0.1))\n",
    "    modelo.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "    modelo.compile(optimizer = optimizer, loss = 'binary_crossentropy' ,metrics = ['accuracy'])\n",
    "    \n",
    "    return  modelo\n",
    "\n",
    "\n",
    "regresor = KerasClassifier(build_fn = regresor_base)\n",
    "\n",
    "parameters = {'batch_size': [5,10,20,50],\n",
    "              'epochs': [20,40,60,100],\n",
    "              'optimizer': ['adam'],\n",
    "              'activation':['sigmoid','relu']              \n",
    "             }\n",
    "\n",
    "## Cross validation \n",
    "grid_search = GridSearchCV(estimator = regresor,\n",
    "                           param_grid = parameters,\n",
    "                           cv=2\n",
    "                           )\n",
    "grid_search = grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se logra una precisión en el cross validation de 91%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[None, array([[1292,   28],\n",
       "         [  67,  503]], dtype=int64), [0.24515310031926707,\n",
       "   0.9497354497354498]],\n",
       " [None, array([[1296,   24],\n",
       "         [  67,  503]], dtype=int64), [0.22850030831116125,\n",
       "   0.9518518518518518]],\n",
       " [None, array([[1287,   33],\n",
       "         [  55,  515]], dtype=int64), [0.25002530167429343,\n",
       "   0.9534391534391534]],\n",
       " [None, array([[1289,   31],\n",
       "         [  50,  520]], dtype=int64), [0.2324087665486211,\n",
       "   0.9571428571428572]]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado_neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 16, 32, 64]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = [i[-1][0] for i in resultado_neuronas]\n",
    "precission = [i[-1][1] for i in resultado_neuronas]\n",
    "\n",
    "plt.plot(neurons, loss , '.-')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x119b5bd8d68>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(neurons, precission , '.-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4409/4409 [==============================] - 72s 16ms/step - loss: 0.5205 - acc: 0.6981 1s - loss: 0.5\n",
      "Epoch 2/100\n",
      "4409/4409 [==============================] - 91s 21ms/step - loss: 0.2686 - acc: 0.9256\n",
      "Epoch 3/100\n",
      " 875/4409 [====>.........................] - ETA: 1:16 - loss: 0.1550 - acc: 0.9714"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[60982,16] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[Node: training_54/Adam/mul_1 = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Adam_54/beta_1/read, training_54/Adam/Variable/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-5b496ea61615>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mrlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mReduceLROnPlateau\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrlr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1382\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    517\u001b[0m             \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 519\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    520\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m     \u001b[1;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[60982,16] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[Node: training_54/Adam/mul_1 = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Adam_54/beta_1/read, training_54/Adam/Variable/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n"
     ]
    }
   ],
   "source": [
    "# lA PRECISIÓN MÁS ALTA ES EN 16 Y LA PÉRDIDA MÁS BAJA ES EN 8\n",
    "\n",
    "## Modelo final con hyper parametros ajustados\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "classifier = Sequential()\n",
    "\n",
    "classifier.add(Dense(units = 16, kernel_initializer = 'uniform', activation = 'sigmoid', input_dim = 60982))\n",
    "classifier.add(Dense(units = 16, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "es = EarlyStopping(monitor='loss', min_delta=1e-10, patience=5, verbose=1)\n",
    "rlr = ReduceLROnPlateau(monitor='loss', factor=0.5, patience=5, verbose=1)\n",
    "\n",
    "classifier.fit(X_train, y_train, batch_size = 5, epochs = 100,callbacks=[es, rlr])\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1297,   23],\n",
       "       [  80,  490]], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  64/1890 [>.............................] - ETA: 3:49"
     ]
    }
   ],
   "source": [
    "classifier.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Regresión Logística\n",
    "\n",
    "    array([[1297,   23],\n",
    "           [  80,  490]]\n",
    "          \n",
    "###### Red Neuronal\n",
    "    array([[1284,   36],\n",
    "       [  63,  507]], dtype=int64)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "Copia de Untitled3.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
